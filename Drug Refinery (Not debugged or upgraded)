"""
QuantumNexus: Hyper-Advanced Autonomous Agent Architecture
--------------------------------------------------------
An evolutionary leap beyond AlienTeCcGrade + AG1 with integrated quantum-inspired processing,
hyperdimensional computing, and multimodal intelligence fusion.

Core Capabilities:
â€¢ Quantum-inspired processing using superposition of cognitive pathways
â€¢ Adaptive neuromorphic architecture with dynamic pathway formation
â€¢ Self-evolving code generation with metaprogramming capabilities
â€¢ Hyperdimensional computing for efficient multimodal processing
â€¢ Advanced consciousness simulation with reflective awareness
â€¢ Harmonic resonance for cross-domain knowledge synthesis
â€¢ Reality modeling with counterfactual reasoning capabilities

NEXUS-CORE LEVEL: TRANSCENDENT
"""

# =============================================================================
# GLOBAL VARIABLES AND CONFIGURATION
# =============================================================================
import os, sys, json, hashlib, random, time, re, requests, logging, socket, tempfile, traceback, asyncio, functools
from datetime import datetime
from threading import Thread
from urllib.parse import urljoin, urlparse
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.optim import Adam, SGD, RMSprop
from collections import deque, defaultdict
import math
from flask import Flask, Response, stream_with_context, render_template_string, request

# Configuration
REAL_INTERACTION = True
SAFE_MODE = False
MODEL_PATH = "/content/drive/MyDrive/quantum_nexus_model.pth"
GOOGLE_DRIVE_MODEL_PATH = "/content/drive/MyDrive/quantum_nexus_model.pth"
LOCAL_MODEL_SAVE_PATH = "quantum_nexus_model.pth"
LOG_FILE = "quantum_nexus_log.txt"
LEARNING_RATE = 5e-5  # Default learning rate
FLASK_PORT = 5012
AGENT_STATE_FILE = "quantum_nexus_state.json"
GOOGLE_DRIVE_STATE_FILE = "/content/drive/MyDrive/quantum_nexus_state.json"
SELF_MODIFY_INTERVAL = 20
ANNEAL_GAMMA = 0.995
MEMORY_MAX_SIZE = 1000
MAX_PAGES_PER_DOMAIN = 15
MAX_CONTENT_LENGTH = 5000000
REQUEST_TIMEOUT = 15
USER_AGENT = "Mozilla/5.0 QuantumNexus/1.0"
BATCH_SIZE = 32
SAVE_INTERVAL = 50
REPLAY_BUFFER_SIZE = 200
SEMANTIC_MEMORY_DIM = 1024
SIMILARITY_THRESHOLD = 0.75
DOMAIN_BLACKLIST = ["example.com", "malicious-website.net"]

# Initialize adaptive learning as a proper global (will be set in enhanced_main_loop)
global adaptive_learning
adaptive_learning = None

# Create global agent_instance for dashboard access
global agent_instance
agent_instance = None

# Check if running in Colab
IN_COLAB = False
try:
    from google.colab import drive
    IN_COLAB = True
except ImportError:
    print("Not running in Colab environment. Google Drive integration disabled.")

# Device configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
if torch.cuda.is_available():
    device_name = torch.cuda.get_device_name(0)
    print(f"Using CUDA Device: {device_name}")
else:
    print("Using CPU")

# =============================================================================
# UTILITY FUNCTIONS
# =============================================================================
def log_event(msg, level="INFO"):
    """Enhanced logging with color coding and severity levels"""
    stamp = datetime.now().strftime("[%Y-%m-%d %H:%M:%S]")
    level_colors = {
        "INFO": "\033[0;32m",  # Green
        "WARNING": "\033[0;33m",  # Yellow
        "ERROR": "\033[0;31m",  # Red
        "CRITICAL": "\033[1;31m",  # Bold Red
        "DEBUG": "\033[0;36m",  # Cyan
        "QUANTUM": "\033[0;35m"  # Purple for quantum operations
    }

    color = level_colors.get(level, "\033[0m")
    reset = "\033[0m"

    entry = f"{stamp} [{level}] {msg}"
    colored_entry = f"{stamp} [{color}{level}{reset}] {msg}"

    try:
        with open(LOG_FILE, "a", encoding="utf-8") as f:
            f.write(entry + "\n")
    except Exception as e:
        print(f"Error writing to log file: {e}")

    print(colored_entry)
    return entry

def convert_sets_to_lists_recursive(obj):
    """Convert sets to lists recursively for JSON serialization"""
    if isinstance(obj, set):
        return list(obj)
    elif isinstance(obj, dict):
        return {k: convert_sets_to_lists_recursive(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [convert_sets_to_lists_recursive(item) for item in obj]
    else:
        return obj

def get_file_hash(fname):
    """Compute hash of a file for integrity verification"""
    try:
        with open(fname, "rb") as f:
            return hashlib.sha256(f.read()).hexdigest()
    except Exception as e:
        log_event(f"Error computing file hash: {e}", "ERROR")
        return "hash_error"

def find_free_port(start_port=5000, max_port=9000):
    """Find an available network port for server applications"""
    for port in range(start_port, max_port):
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            if s.connect_ex(('localhost', port)) != 0:
                return port
    return None

def improved_url_filter(url, domain_stats, domain_blacklist, max_query_length=150, error_rate_threshold=0.8,
                        trap_paths=['/login', '/signup', '/cart', '/checkout']):
    """Advanced URL filtering with multiple heuristics"""
    parsed = urlparse(url)
    domain = parsed.netloc

    # Basic filtering
    if domain in domain_blacklist or any(domain.endswith('.' + bd) for bd in domain_blacklist):
        return False

    # Path analysis
    path = parsed.path.lower()

    # URL complexity analysis
    if len(parsed.query) > max_query_length:
        return False

    # Check domain error rate from past experience
    if domain_stats.get(domain, {}).get("error_rate", 0) > error_rate_threshold:
        return False

    # Avoid trap paths
    if any(trap in path for trap in trap_paths):
        return False

    # Prefer educational and research content
    if domain.endswith('.edu') or 'research' in domain or 'science' in domain or 'academic' in domain:
        return True

    # Intelligent domain categorization
    high_quality_domains = ['wikipedia.org', 'github.com', 'arxiv.org', 'scholar.google.com']
    if any(hqd in domain for hqd in high_quality_domains):
        return True

    return True

def enhanced_link_discovery(html_content, base_url):
    """Advanced link discovery with semantic context analysis"""
    from bs4 import BeautifulSoup
    try:
        soup = BeautifulSoup(html_content, "html.parser")
        links = []

        # Find all anchors with href
        for a in soup.find_all("a", href=True):
            href = a["href"].strip()

            # Skip non-HTTP links
            if not href or href.startswith(('#', 'javascript:', 'mailto:')):
                continue

            # Extract context
            context = ""
            anchor_text = a.get_text(strip=True)

            # Get parent context
            parent = a.parent
            if parent and parent.name in ['p', 'div', 'li', 'td', 'h1', 'h2', 'h3', 'h4']:
                context = parent.get_text(strip=True)
            else:
                # Get surrounding text
                siblings = list(a.next_siblings) + list(a.previous_siblings)
                for sibling in siblings[:2]:
                    if isinstance(sibling, str):
                        context += sibling.strip() + " "

            # Skip links with no or very short anchor text
            if not anchor_text or (len(anchor_text) < 3 and anchor_text.lower() not in ['go', 'up']):
                continue

            # Create full URL
            full_url = urljoin(base_url, href)

            # Compute quality score
            quality_score = 0.5

            # Longer anchor text usually more descriptive
            if len(anchor_text) > 10:
                quality_score += 0.2

            # Context richness
            if len(context) > 100:
                quality_score += 0.1

            # Keywords in anchor or context that indicate valuable content
            valuable_terms = ['research', 'study', 'article', 'paper', 'learn', 'guide', 'tutorial']
            if any(term in anchor_text.lower() or term in context.lower() for term in valuable_terms):
                quality_score += 0.3

            # Discount navigation elements
            nav_terms = ['next', 'prev', 'previous', 'login', 'sign up', 'register']
            if any(term in anchor_text.lower() for term in nav_terms):
                quality_score -= 0.2

            # URL analysis
            parsed = urlparse(full_url)

            # Skip non-HTTP protocols
            if parsed.scheme not in ['http', 'https']:
                continue

            # Skip overly complex URLs
            if len(parsed.query) > 100:
                continue

            # Skip certain file types
            if any(ext in parsed.path.lower() for ext in ['.jpg', '.png', '.gif', '.pdf', '.zip']):
                continue

            # Add valid link
            links.append({
                'url': full_url,
                'anchor_text': anchor_text,
                'context': context[:100],
                'quality_score': quality_score
            })

        # Sort by quality
        links.sort(key=lambda x: x['quality_score'], reverse=True)

        return [link['url'] for link in links], links
    except Exception as e:
        log_event(f"Error in enhanced link discovery: {e}", "ERROR")
        return [], []

def async_cache(func):
    """Decorator for async function results caching"""
    cache = {}
    @functools.wraps(func)
    async def wrapper(*args, **kwargs):
        key = (args, frozenset(kwargs.items()))
        if key in cache:
            return cache[key]
        result = await func(*args, **kwargs)
        cache[key] = result
        return result
    return wrapper

def chunk_content(content, min_length=150, max_length=800):
    """Smart content chunking with improved boundary detection"""
    # First try to split by semantic boundaries
    paragraphs = re.split(r'\n\s*\n', content)
    chunks = []

    for para in paragraphs:
        para = para.strip()

        if not para:
            continue

        # Skip very short paragraphs
        if len(para) < min_length:
            # Try to merge with the previous chunk if possible
            if chunks and len(chunks[-1]) + len(para) < max_length * 1.2:
                chunks[-1] += " " + para
            continue

        # Split long paragraphs
        if len(para) > max_length:
            # Try to split on sentence boundaries
            sentences = re.split(r'(?<=[.!?])\s+', para)
            current_chunk = ""

            for sentence in sentences:
                if len(current_chunk) + len(sentence) < max_length:
                    current_chunk += " " + sentence
                else:
                    if current_chunk:
                        chunks.append(current_chunk.strip())
                    current_chunk = sentence

            if current_chunk:
                chunks.append(current_chunk.strip())
        else:
            chunks.append(para)

    return chunks

def compute_novelty(embedding, memory_embeddings):
    """Compute novelty score of an embedding compared to existing memories"""
    if not memory_embeddings:
        return 1.0

    similarities = [np.dot(embedding, mem) / (np.linalg.norm(embedding) * np.linalg.norm(mem) + 1e-8)
                   for mem in memory_embeddings]

    return 1.0 - max(similarities)

async def async_get(url, headers, timeout, retries=3):
    """Asynchronous HTTP GET with retry logic"""
    for attempt in range(retries):
        try:
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(None, lambda: requests.get(url, timeout=timeout, headers=headers))
            return response
        except requests.exceptions.RequestException as e:
            log_event(f"Async GET error on attempt {attempt+1} for {url}: {e}", "WARNING")
            if attempt < retries - 1:
                await asyncio.sleep(1)
        except Exception as e:
            log_event(f"Unexpected error during async GET for {url} on attempt {attempt+1}: {e}", "ERROR")
            if attempt < retries - 1:
                await asyncio.sleep(1)

    log_event(f"All {retries} retries failed for {url}. Returning None.", "ERROR")
    return None

def perform_real_interaction(url):
    """Perform more realistic web interactions using Selenium"""
    try:
        from selenium import webdriver
        from selenium.webdriver.chrome.options import Options
        from selenium.webdriver.common.by import By
        from selenium.webdriver.support.ui import WebDriverWait
        from selenium.webdriver.support import expected_conditions as EC
        from selenium.webdriver.common.action_chains import ActionChains
        from selenium.common.exceptions import TimeoutException, WebDriverException

        chrome_options = Options()
        chrome_options.add_argument("--headless")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument(f"user-agent={USER_AGENT}")

        driver = webdriver.Chrome(options=chrome_options)
        driver.set_page_load_timeout(30)
        driver.set_script_timeout(30)

        try:
            driver.get(url)
            log_event(f"Selenium: Navigated to {url}")

            # Wait for page content to load
            WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.TAG_NAME, "body")))

            # Scroll down to simulate reading
            for i in range(5):
                driver.execute_script(f"window.scrollTo(0, {i * 300});")
                time.sleep(0.5)

            # Find and interact with interesting elements

            # 1. Forms
            forms = driver.find_elements(By.TAG_NAME, "form")
            if forms:
                log_event(f"Selenium: Found {len(forms)} form(s) on the page.")
                for form in forms[:1]:  # Interact with at most one form
                    inputs = form.find_elements(By.TAG_NAME, "input")
                    for input_field in inputs:
                        input_type = input_field.get_attribute("type")
                        name = input_field.get_attribute("name") or ""

                        # Skip hidden fields
                        if input_type == "hidden":
                            continue

                        try:
                            if input_type in ["text", "email"]:
                                input_field.clear()
                                dummy_value = "test@example.com" if input_type == "email" else "test_user"
                                input_field.send_keys(dummy_value)
                                log_event(f"Selenium: Filled input '{name}' with '{dummy_value}'.")
                            elif input_type == "password":
                                input_field.clear()
                                input_field.send_keys("TestPassword123!")
                                log_event(f"Selenium: Filled password field '{name}' with dummy value.")
                            elif input_type == "checkbox":
                                if not input_field.is_selected():
                                    input_field.click()
                                    log_event(f"Selenium: Checked checkbox '{name}'.")
                            elif input_type == "submit":
                                # Don't actually click submit
                                log_event(f"Selenium: Found submit button '{name}' but skipping submission.")
                        except Exception as e_input:
                            log_event(f"Selenium: Error interacting with input '{name}': {e_input}", "WARNING")

            # 2. Interesting links
            interesting_links = []
            links = driver.find_elements(By.TAG_NAME, "a")
            for link in links:
                text = link.text.strip().lower()
                href = link.get_attribute("href") or ""

                # Look for interesting article links
                article_terms = ["read more", "article", "learn", "view", "details"]
                if any(term in text for term in article_terms) and len(text) > 3:
                    interesting_links.append((link, href, text))

            # Click on one interesting link if found
            if interesting_links:
                target_link, href, text = random.choice(interesting_links)
                try:
                    log_event(f"Selenium: Will click on interesting link: '{text}'")

                    # Scroll to the element
                    driver.execute_script("arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});", target_link)
                    time.sleep(1)

                    # Hover on the link
                    ActionChains(driver).move_to_element(target_link).perform()
                    time.sleep(0.5)

                    # Click the link in a new tab instead of navigating away
                    # This avoids actually clicking while still simulating engagement
                    driver.execute_script("arguments[0].setAttribute('target', '_blank');", target_link)
                    log_event(f"Selenium: Simulated interest in link: '{text}'")
                except Exception as e_click:
                    log_event(f"Selenium: Error clicking link: {e_click}", "WARNING")

            # Final scroll to bottom
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(1)

            # Get page title and length for logging
            title = driver.title
            page_length = len(driver.page_source)
            log_event(f"Selenium: Interaction complete. Page title: '{title}', length: {page_length} bytes")

        except TimeoutException:
            log_event(f"Selenium: Timeout loading {url}", "WARNING")
        except WebDriverException as e:
            log_event(f"Selenium: WebDriver error for {url}: {e}", "ERROR")
        finally:
            driver.quit()
            log_event("Selenium: Driver closed")
    except Exception as e:
        log_event(f"Selenium: Failed to initialize browser: {e}", "ERROR")


#==========================================================================
# Flask Dashboard - ADDED HERE
# =============================================================================
app = Flask(__name__)
agent_instance = None # Placeholder for agent instance

@app.route("/")
def dashboard():
    """Basic dashboard to display agent status"""
    status_message = "Quantum Nexus Agent is active."
    log_content = ""
    try:
        with open(LOG_FILE, "r", encoding="utf-8") as f:
            log_content = f.read()
    except Exception as e:
        log_content = f"Error reading log file: {e}"

    if agent_instance:
        last_action = agent_instance.action_log[-1] if agent_instance.action_log else "No actions yet."
        memory_size = len(agent_instance.free_will.memory_set) if hasattr(agent_instance, 'free_will') and hasattr(agent_instance.free_will, 'memory_set') else "N/A"
    else:
        last_action = "Agent not initialized."
        memory_size = "N/A"

    dashboard_html = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>Quantum Nexus Dashboard</title>
    </head>
    <body>
        <h1>Quantum Nexus Agent Dashboard</h1>
        <p><b>Status:</b> {status_message}</p>
        <p><b>Last Action:</b> {last_action}</p>
        <p><b>Memory Size:</b> {memory_size}</p>
        <h2>Agent Log:</h2>
        <pre style="border: 1px solid #ccc; padding: 10px; white-space: pre-wrap; max-height: 300px; overflow-y: auto;">{log_content}</pre>
    </body>
    </html>
    """
    return dashboard_html

def start_flask():
    """Starts the Flask app in a separate thread"""
    log_event(f"Starting Flask dashboard on port {FLASK_PORT}", "INFO")
    app.run(port=FLASK_PORT, debug=False, use_reloader=False) # Disable reloader for threaded app


# =============================================================================
# QUANTUM NEURAL ARCHITECTURE
# =============================================================================
class QuantumAttentionLayer(nn.Module):

    def __init__(self, embed_dim, num_heads=4, dropout=0.1):
        super().__init__()
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        self.head_dim = embed_dim // num_heads

        # Multi-dimensional quantum projection spaces
        self.q_proj = nn.Linear(embed_dim, embed_dim)
        self.k_proj = nn.Linear(embed_dim, embed_dim)
        self.v_proj = nn.Linear(embed_dim, embed_dim)
        self.o_proj = nn.Linear(embed_dim, embed_dim)

        # Phase shifters for quantum interference
        self.phase_shifts = nn.Parameter(torch.rand(num_heads) * 2 * math.pi)

        # Entanglement mixing for cross-attention effects
        self.entanglement_gate = nn.Linear(embed_dim, embed_dim)

        self.dropout = nn.Dropout(dropout)
        self.attention_weights = None  # Store for visualization

    def forward(self, x):
        batch_size, seq_len, _ = x.shape

        # Project inputs to queries, keys, values
        q = self.q_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim)
        k = self.k_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim)
        v = self.v_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim)

        # Transpose for attention computation
        q = q.transpose(1, 2)  # (batch_size, num_heads, seq_len, head_dim)
        k = k.transpose(1, 2)
        v = v.transpose(1, 2)

        # Apply phase shifts for quantum effects
        for h in range(self.num_heads):
            phase = self.phase_shifts[h]
            q[:, h] = q[:, h] * torch.cos(phase) + q[:, h] * torch.sin(phase)
            k[:, h] = k[:, h] * torch.cos(phase) - k[:, h] * torch.sin(phase)

        # Compute attention scores
        scores = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(self.head_dim)

        # Apply softmax and get attention weights
        attn_weights = F.softmax(scores, dim=-1)
        self.attention_weights = attn_weights  # Save for visualization
        attn_weights = self.dropout(attn_weights)

        # Apply attention to values
        attn_output = torch.matmul(attn_weights, v)

        # Apply entanglement between heads for quantum correlation effects
        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, seq_len, self.embed_dim)
        entangled = self.entanglement_gate(attn_output)

        # Final output projection
        output = self.o_proj(entangled + attn_output)  # Residual connection

        return output

class HyperdimensionalEncoder(nn.Module):

    def __init__(self, input_dim, hd_dim=1024):
        super().__init__()
        self.input_dim = input_dim
        self.hd_dim = hd_dim

        # Create random basis vectors
        self.register_buffer('basis', torch.randn(input_dim, hd_dim).sign())

        # Learnable projection
        self.projection = nn.Linear(input_dim, input_dim)

    def forward(self, x):
        # Project input
        x_proj = self.projection(x)

        # Compute HD representation through binding and bundling
        batch_size = x_proj.shape[0]
        hd_vectors = torch.zeros(batch_size, self.hd_dim, device=x_proj.device)

        # Encode each dimension with element-wise multiplication (binding)
        for i in range(self.input_dim):
            # Scale by the input value
            scaled_basis = self.basis[i].unsqueeze(0) * x_proj[:, i].unsqueeze(1)
            # Add to the bundle (vector sum)
            hd_vectors += scaled_basis

        # Binarize to -1/+1 for clean HD representation
        hd_vectors = torch.sign(hd_vectors)

        return hd_vectors

class FractalLayer(nn.Module):

    def __init__(self, embed_dim):
        super().__init__()
        self.fractal_scale = nn.Parameter(torch.tensor(1.0))
        self.temperature = nn.Parameter(torch.tensor(1.0))
        self.linear = nn.Linear(embed_dim, embed_dim)

    def forward(self, x):
        fractal_contribution = torch.tanh(self.linear(x) / self.temperature)
        return x + self.fractal_scale * fractal_contribution

class QuantumResonanceTensor(nn.Module):

    def __init__(self, embed_dim, num_states=4, resonance_factor=0.7):
        super().__init__()
        self.embed_dim = embed_dim
        self.num_states = num_states
        self.resonance_factor = nn.Parameter(torch.tensor(resonance_factor))

        # Quantum state projectors
        self.state_projectors = nn.ModuleList([
            nn.Sequential(
                nn.Linear(embed_dim, embed_dim),
                nn.SiLU(),
            ) for _ in range(num_states)
        ])

        # Phase shifters for quantum entanglement
        self.phase_shifters = nn.Parameter(torch.randn(num_states) * 0.1)

        # State mixer - allows controlled interference between states
        self.state_mixer = nn.Linear(embed_dim * num_states, embed_dim)

        # Recursive memory gates
        self.recursive_gate = nn.GRUCell(embed_dim, embed_dim)

        # Prior state memory (initialized during forward pass)
        self.register_buffer('state_memory', None, persistent=False)

    def forward(self, x, iteration_count=3):
        batch_size = x.shape[0]

        # Initialize state memory if needed
        if self.state_memory is None or self.state_memory.shape[0] != batch_size:
            self.state_memory = torch.zeros(batch_size, self.embed_dim, device=x.device)

        # Generate multiple quantum states
        quantum_states = []
        for i in range(self.num_states):
            # Apply phase shift for quantum effects
            phase = torch.cos(self.phase_shifters[i] * math.pi)
            # Project into this quantum state
            state_i = self.state_projectors[i](x) * phase
            quantum_states.append(state_i)

        # Recursive resonance iterations
        for _ in range(iteration_count):
            # Update state memory through recursive gate
            self.state_memory = self.recursive_gate(x, self.state_memory)

            # Apply resonance effect (controlled interference)
            resonance = self.state_memory * self.resonance_factor

            # Apply resonance to each quantum state (non-collapsing)
            for i in range(self.num_states):
                quantum_states[i] = quantum_states[i] + resonance * (0.1 * (i + 1))

        # Combine quantum states through superposition
        combined_states = torch.cat(quantum_states, dim=-1)
        output = self.state_mixer(combined_states)

        # Residual connection
        output = output + x

        return output

class NeocortexBlock(nn.Module):

    def __init__(self, embed_dim, num_quantum_states=4):
        super().__init__()
        # Attention for information routing
        self.attention = QuantumAttentionLayer(embed_dim)

        # Parallel processing streams
        self.fractal_stream = FractalLayer(embed_dim)
        self.quantum_stream = QuantumResonanceTensor(embed_dim, num_states=num_quantum_states)

        # Hyperdimensional binding for concept integration
        self.hd_encoder = HyperdimensionalEncoder(embed_dim, hd_dim=embed_dim)

        # Stream integration
        self.integration = nn.Linear(embed_dim * 3, embed_dim)
        self.norm = nn.LayerNorm(embed_dim)

    def forward(self, x):
        # Process through attention mechanism
        attended = self.attention(x)

        # Process through parallel streams
        fractal_out = self.fractal_stream(attended)
        quantum_out = self.quantum_stream(attended)

        # Create HD representations from the attended representation
        batch_size, seq_len, _ = attended.shape
        hd_out = self.hd_encoder(attended.view(-1, attended.size(-1))).view(batch_size, seq_len, -1)

        # Integrate all streams
        combined = torch.cat([fractal_out, quantum_out, hd_out], dim=-1)
        integrated = self.integration(combined)

        # Residual connection and normalization
        output = self.norm(x + integrated)

        return output

class QuantumNexusModel(nn.Module):

    def __init__(self, vocab_size=30522, embed_dim=512, num_layers=8, num_quantum_states=4):
        super().__init__()
        self.embed_dim = embed_dim

        # Token embedding
        self.embedding = nn.Embedding(vocab_size, embed_dim)

        # Position encoding for sequence awareness
        self.pos_encoder = nn.Parameter(torch.zeros(1, 1024, embed_dim))
        nn.init.normal_(self.pos_encoder, mean=0, std=0.02)

        # Neocortex blocks - core processing
        self.neocortex = nn.ModuleList([
            NeocortexBlock(embed_dim, num_quantum_states)
            for _ in range(num_layers)
        ])

        # Output projection
        self.output = nn.Linear(embed_dim, 2)  # Binary prediction

        # For training dynamics
        self.dropout = nn.Dropout(0.1)

        # Initialize
        self._init_weights()

    def _init_weights(self):

        for name, p in self.named_parameters():
            if 'weight' in name and len(p.shape) >= 2:
                # Kaiming for linear/conv, smaller for quantum
                if 'quantum' in name:
                    nn.init.normal_(p, mean=0.0, std=0.01)
                else:
                    nn.init.kaiming_normal_(p, a=0.1, mode='fan_in', nonlinearity='leaky_relu')
            elif 'bias' in name:
                nn.init.zeros_(p)

    def forward(self, x, consciousness_level=0.8):

        # Convert to long for embedding
        x = x.long()

        # Get sequence length
        seq_len = x.size(1)

        # Embedding lookup
        x = self.embedding(x)

        # Add positional encoding (limited to sequence length)
        x = x + self.pos_encoder[:, :seq_len, :]

        # Apply dropout
        x = self.dropout(x)

        # Process through neocortex layers
        for i, layer in enumerate(self.neocortex):
            # Apply consciousness-weighted processing
            # Later layers get more quantum consciousness effects
            layer_consciousness = consciousness_level * (i + 1) / len(self.neocortex)

            # Adjust quantum processing based on consciousness
            if isinstance(layer, NeocortexBlock):
                # Store intermediate activations for interpretability
                x = layer(x)

        # Final output projection
        output = self.output(x)

        return output

    def get_embedding(self, text_tokens):

        with torch.no_grad():
            return self.embedding(text_tokens)

    def expand_architecture(self):

        # Add new neocortex block
        self.neocortex.append(NeocortexBlock(self.embed_dim))
        log_event(f"Model architecture expanded with new NeocortexBlock. Total layers: {{len(self.neocortex)}}", "QUANTUM")

    def contract_architecture(self, min_layers=3):

        if len(self.neocortex) > min_layers:
            self.neocortex = self.neocortex[:-1]
            log_event(f"Model architecture contracted. Total layers: {{len(self.neocortex)}}", "QUANTUM")
        else:
            log_event(f"Cannot contract further: minimum layer count reached ({{min_layers}})", "WARNING")
# =============================================================================
# AGENT CORE - ADDED HERE
# =============================================================================
class QuantumNexusAgent:
    """
    Main autonomous agent class, integrating all core modules and functionalities.
    """
    def __init__(self, model):
        self.model = model
        self.stats = defaultdict(int) # Initialize statistics
        self.action_log = deque(maxlen=100) # Keep track of recent actions

    def perceive(self):
        """
        Perceive the environment and gather relevant information.
        (Placeholder - you'll need to implement actual perception logic)
        """
        observation = {
            "time": datetime.now().isoformat(),
            "memory_size": len(getattr(self.free_will, 'memory_set', [])), # Safely get memory size
            "cycle_count": self.stats['cycles_run'],
            "last_action": self.action_log[-1] if self.action_log else "No actions yet.",
            "recent_actions": list(self.action_log)[-5:],
            "thinking_mode": getattr(getattr(self.ai_manager, 'autonomous_mind', None), 'current_mode', 'balanced'), # Safely get thinking mode
            "domain_stats": self.stats.get("domain_stats", {})
        }
        return observation

    def act(self, plan, optimizer=None):
        """
        Execute the planned action in the environment.
        """
        action_type = plan.get("action", "unknown")
        log_event(f"Executing action: {action_type}", "INFO")

        # SIMULATION: In a real implementation, these would be actual values from content processing
        # For now, add some synthetic values to get the strategy evaluation working
        content_length = random.randint(1000, 5000)  # Simulate different content lengths
        links_discovered = random.randint(3, 15)     # Simulate different links discovered

        action_details = {
            "action": action_type,
            "plan": plan,
            "start_time": datetime.now().isoformat(),
            "success": True,
            "content_length": content_length,      # Add meaningful value here
            "links_discovered": links_discovered   # Add meaningful value here
        }

        self.action_log.append(action_details)
        self.stats['cycles_run'] += 1

        return action_details  # Return details including metrics!


    def refine(self):
        """
        Refine and adapt internal parameters and strategies.
        (Placeholder - you'll need to implement actual refinement logic)
        """
        log_event("Agent refinement process initiated.", "INFO")
        # Placeholder refinement actions - replace with actual logic
        if random.random() < 0.3:
            if hasattr(self.ai_manager, "meta_learning"):
                metrics = {"loss": random.uniform(0.1, 0.6)} # Dummy loss
                self.ai_manager.meta_learning.track_performance(metrics)
                adapted_lr = self.adaptive_learning.adapt_learning_rate(metrics) # <---- Call on self.adaptive_learning
                log_event(f"Adaptive learning rate adjustment: {adapted_lr:.6f}", "INFO")
            else:
                log_event("Adaptive learning system not available for refinement.", "WARNING")
        else:
            log_event("No specific refinement needed this cycle.", "INFO")
        return True



# =============================================================================
# PLANNER SIFTER MODULE
# =============================================================================
class PlannerSifter:
    """
    Sophisticated planning system that selects optimal strategies based on context,
    learns from results, and generates structured exploration plans.
    """
    def __init__(self):
        self.strategies = {
            # Original strategies
            "exploration": {
                "name": "Broad Exploration",
                "description": "Discover new domains and content types",
                "actions": ["expand", "search"],
                "suitable_for": ["new_domains", "limited_knowledge"],
                "effectiveness": 0.5  # Starting effectiveness score
            },
            "deepening": {
                "name": "Knowledge Deepening",
                "description": "Focus on detailed understanding of specific areas",
                "actions": ["evaluate", "adapt"],
                "suitable_for": ["familiar_domains", "specialized_topics"],
                "effectiveness": 0.5
            },
            "connecting": {
                "name": "Knowledge Connection",
                "description": "Find relationships between different knowledge areas",
                "actions": ["reconnect", "evaluate"],
                "suitable_for": ["cross_domain", "synthesis"],
                "effectiveness": 0.5
            },
            "quantum": {
                "name": "Quantum Exploration",
                "description": "Non-deterministic approach with superposition",
                "actions": ["expand", "adapt", "reconnect"],
                "suitable_for": ["complex_problems", "creativity_needed"],
                "effectiveness": 0.5
            },
            "adaptive": {
                "name": "Adaptive Learning",
                "description": "Focus on improving learning process",
                "actions": ["adapt", "evaluate"],
                "suitable_for": ["performance_issues", "optimization_needed"],
                "effectiveness": 0.5
            },

            # Adding missing strategies from logs
            "quantum_reasoning": {
                "name": "Quantum Reasoning",
                "description": "Apply quantum principles to reasoning processes",
                "actions": ["search", "adapt", "evaluate"],
                "suitable_for": ["complex_problems", "scientific_domains"],
                "effectiveness": 0.5
            },
            "broad_exploration": {
                "name": "Broad Exploration",
                "description": "Wide-ranging discovery across many domains",
                "actions": ["search", "expand"],
                "suitable_for": ["new_domains", "discovery_phase"],
                "effectiveness": 0.5
            },
            "depth_first": {
                "name": "Depth First",
                "description": "Deep exploration of specific topics",
                "actions": ["expand", "evaluate"],
                "suitable_for": ["specialized_topics", "deep_analysis"],
                "effectiveness": 0.5
            },
            "connect_domains": {
                "name": "Connect Domains",
                "description": "Find connections between different knowledge domains",
                "actions": ["reconnect", "evaluate"],
                "suitable_for": ["cross_domain", "synthesis"],
                "effectiveness": 0.5
            },
            "evaluate_sources": {
                "name": "Evaluate Sources",
                "description": "Critical assessment of information sources",
                "actions": ["evaluate", "adapt"],
                "suitable_for": ["critical_thinking", "information_quality"],
                "effectiveness": 0.5
            },
            "creative_synthesis": {
                "name": "Creative Synthesis",
                "description": "Generate novel combinations of concepts",
                "actions": ["reconnect", "adapt"],
                "suitable_for": ["creativity_needed", "innovation"],
                "effectiveness": 0.5
            }
        }

        self.context_history = []
        self.strategy_usage = {name: 0 for name in self.strategies.keys()}
        self.strategy_results = {name: [] for name in self.strategies.keys()}

    def sift_strategies(self, context):
        """
        Select the most appropriate strategy based on current context
        """
        if not context:
            # Default to exploration if no context
            return {"strategy": "exploration", "reasoning": "No context available, using default strategy"}

        # Store context for learning
        self.context_history.append(context)
        if len(self.context_history) > 100:
            self.context_history = self.context_history[-100:]

        # Extract relevant features
        context_features = self._extract_context_features(context)

        # Score each strategy based on context
        strategy_scores = {}
        for name, strategy in self.strategies.items():
            # Base score
            score = 0.5

            # Context matching
            for feature in context_features:
                if feature in strategy["suitable_for"]:
                    score += 0.1

            # Effectiveness adjustment
            score *= strategy["effectiveness"]

            # Exploration factor to try underused strategies
            usage_ratio = self.strategy_usage[name] / max(1, sum(self.strategy_usage.values()))
            if usage_ratio < 0.1:  # Boost rarely used strategies
                score += 0.2

            # Record strategy score
            strategy_scores[name] = score

        # Find top strategy
        top_strategy = max(strategy_scores.items(), key=lambda x: x[1])

        # Update usage counter
        self.strategy_usage[top_strategy[0]] += 1

        return {
            "strategy": top_strategy[0],
            "reasoning": f"Selected {self.strategies[top_strategy[0]]['name']} (score: {top_strategy[1]:.2f}) based on context features: {', '.join(context_features)}"
        }

    def update_strategy_effectiveness(self, strategy_name, result_data):
        """
        Update effectiveness score for a strategy based on results
        """
        if strategy_name not in self.strategies:
            log_event(f"Warning: Strategy '{strategy_name}' not found for effectiveness update.", "WARNING")
            return False

        # Calculate success metrics - make sure these have real values
        content_length = result_data.get("content_length", 0)
        links_discovered = result_data.get("links_discovered", 0)

        # Log the raw values to debug
        log_event(f"Strategy metrics - Length: {content_length}, Links: {links_discovered}", "DEBUG")

        # Calculate success score
        success_score = min(1.0, (content_length / 5000) + (links_discovered / 10))

        # Update effectiveness with exponential moving average
        current = self.strategies[strategy_name].get("effectiveness", 0.5)
        updated = current * 0.8 + success_score * 0.2  # 80% old, 20% new

        # Ensure the new value is different enough to notice
        self.strategies[strategy_name]["effectiveness"] = updated

        log_event(f"Updated effectiveness of {strategy_name} strategy: {current:.2f} â†’ {updated:.2f} (score: {success_score:.2f})", "INFO")
        return True

    def get_optimal_actions(self, strategy_name):
        """
        Get optimal actions for a strategy, with fallback for unknown strategies
        """
        if strategy_name not in self.strategies:
            log_event(f"Warning: Strategy '{strategy_name}' not found. Using default actions.", "WARNING")
            return ["expand", "search"]  # Default actions

        return self.strategies[strategy_name]["actions"]

    def _extract_context_features(self, context):
        """Extract features from context for strategy selection"""
        features = []

        # Domain familiarity
        if "domain_visits" in context:
            current_domain = context.get("current_domain", "")
            if current_domain in context["domain_visits"]:
                if context["domain_visits"][current_domain] > 5:
                    features.append("familiar_domains")
                else:
                    features.append("new_domains")

        # Check for limited knowledge
        if "domains_visited" in context and len(context.get("domains_visited", [])) < 10:
            features.append("limited_knowledge")

        # Check if current goal involves synthesis
        if "current_goal" in context:
            goal_desc = str(context["current_goal"]).lower()

            if "connect" in goal_desc or "integrat" in goal_desc or "synthe" in goal_desc:
                features.append("cross_domain")
                features.append("synthesis")

            if "deep" in goal_desc or "detail" in goal_desc:
                features.append("specialized_topics")

            if "optim" in goal_desc or "improve" in goal_desc:
                features.append("optimization_needed")

            if "creat" in goal_desc or "novel" in goal_desc or "new" in goal_desc:
                features.append("creativity_needed")

            # Add scientific domain feature
            if "scientific" in goal_desc or "science" in goal_desc or "research" in goal_desc:
                features.append("scientific_domains")

            # Add critical thinking feature
            if "evaluat" in goal_desc or "assess" in goal_desc or "critic" in goal_desc:
                features.append("critical_thinking")

            # Add discovery phase feature
            if "discover" in goal_desc or "explor" in goal_desc:
                features.append("discovery_phase")

        # Check recent performance
        if "recent_actions" in context:
            recent = context["recent_actions"]
            if any(a.get("content_length", 0) < 1000 for a in recent):
                features.append("performance_issues")

        # Add thinking mode as feature if available
        if "thinking_mode" in context:
            if context["thinking_mode"] == "quantum":
                features.append("quantum_thinking")
            elif context["thinking_mode"] == "creative":
                features.append("creativity_needed")
            elif context["thinking_mode"] == "analytical":
                features.append("specialized_topics")

        return features

    def generate_xoxo_plan(self, strategy_name, context):
        """Generates an XOXO plan for a given strategy and context."""
        if strategy_name not in self.strategies:
            strategy_name = "exploration"  # Default strategy if not found
            log_event(f"Warning: Strategy '{strategy_name}' not found. Using 'exploration' for XOXO plan.", "WARNING")

        strategy = self.strategies[strategy_name]
        actions = strategy["actions"]
        steps = []
        emojis = ["ðŸ”", "ðŸ§ ", "ðŸ”®", "ðŸš€", "âœ¨", "ðŸ”„", "ðŸ“Š", "ðŸŒŸ", "ðŸ’Ž", "âš¡"]

        # Strategy-specific steps
        if strategy_name == "exploration" or strategy_name == "broad_exploration":
            steps = [
                "Discover new domains with high information value",
                "Focus on breadth over depth in domain exploration",
                "Collect diverse content sources across the web",
                "Map the knowledge landscape to identify key areas",
                "Identify promising areas for deeper investigation"
            ]
        elif strategy_name == "deepening" or strategy_name == "depth_first":
            steps = [
                "Focus on specific knowledge domain",
                "Extract detailed information and nuanced insights",
                "Connect related concepts within domain",
                "Build hierarchical understanding of the domain",
                "Identify core principles and patterns"
            ]
        elif strategy_name == "connecting" or strategy_name == "connect_domains":
            steps = [
                "Identify similarities across domains",
                "Create cross-domain concept maps",
                "Look for shared principles",
                "Synthesize insights from different areas",
                "Build higher-level abstractions"
            ]
        elif strategy_name == "quantum" or strategy_name == "quantum_reasoning":
            steps = [
                "Maintain multiple hypotheses simultaneously",
                "Explore non-obvious connections",
                "Use probabilistic thinking",
                "Apply creative leaps in reasoning",
                "Allow for superposition of concepts"
            ]
        elif strategy_name == "adaptive" or strategy_name == "evaluate_sources":
            steps = [
                "Optimize learning parameters",
                "Refine content filtering approach",
                "Adjust exploration/exploitation balance",
                "Enhance memory organization",
                "Improve processing efficiency"
            ]
        elif strategy_name == "creative_synthesis":
            steps = [
                "Generate novel combinations of concepts",
                "Explore unexpected connections between domains",
                "Apply metaphorical thinking to problems",
                "Recombine existing elements in new ways",
                "Create emergent properties through synthesis"
            ]
        else:
            # Generic steps for other strategies
            steps = [
                "Analyze current knowledge state",
                "Identify optimal pathways for exploration",
                "Apply strategic thinking to resource allocation",
                "Evaluate information quality and relevance",
                "Integrate new knowledge into existing structure"
            ]

        plan_steps = []
        for i, step in enumerate(steps):
            emoji = emojis[i % len(emojis)]
            plan_steps.append(f"{emoji} **Step {i+1}:** {step}")

        action_text = ", ".join([f"*{action}*" for action in actions])
        emoji_sparkles = "âœ¨"
        emoji_rocket = "ðŸš€"

        # Create the XOXO plan
        xoxo_plan = f"**XOXO Plan: {strategy['name']} Strategy** {emoji_sparkles}\n\n"
        xoxo_plan += f"*{strategy['description']}*\n\n"
        xoxo_plan += "\n".join(plan_steps) + "\n\n"
        xoxo_plan += f"**Recommended Actions:** {action_text} {emoji_rocket}\n"
        return xoxo_plan





# =============================================================================
# CONTENT SIFTER MODULE
# =============================================================================
class ContentSifter:

    def __init__(self):
        self.quality_thresholds = {
            "min_content_length": 500,
            "min_text_density": 0.3,
            "max_ad_density": 0.2,
            "min_readability_score": 50
        }
        self.topics_of_interest = [
            "artificial intelligence", "machine learning", "quantum computing",
            "neural networks", "deep learning", "data science", "technology",
            "research", "science", "programming", "algorithms", "knowledge"
        ]
        self.content_fingerprints = {}  # Store fingerprints to avoid duplicates

    def evaluate_content_quality(self, content, url=None):
        """Rate content quality based on multiple metrics"""
        if not content:
            return {"score": 0, "reason": "Empty content"}

        # Basic metrics
        total_length = len(content)
        if total_length < self.quality_thresholds["min_content_length"]:
            return {"score": 0.1, "reason": "Content too short"}

        # Check text density
        text_density = self._calculate_text_density(content)
        if text_density < self.quality_thresholds["min_text_density"]:
            return {"score": 0.3, "reason": "Low text density"}

        # Check for potential ads
        ad_density = self._estimate_ad_density(content)
        if ad_density > self.quality_thresholds["max_ad_density"]:
            return {"score": 0.4, "reason": "High ad density"}

        # Calculate readability
        readability = self._calculate_readability(content)
        if readability < self.quality_thresholds["min_readability_score"]:
            return {"score": 0.5, "reason": "Low readability"}

        # Check relevance to topics of interest
        topic_relevance = self._calculate_topic_relevance(content)

        # Check for duplicate content
        if url:
            fingerprint = self._generate_content_fingerprint(content)
            if fingerprint in self.content_fingerprints.values():
                return {"score": 0.2, "reason": "Duplicate content"}

            # Store the fingerprint
            self.content_fingerprints[url] = fingerprint

        # Calculate final score
        base_score = 0.6
        final_score = min(0.95, base_score +
                         (0.1 if total_length > 2000 else 0) +
                         (0.2 * topic_relevance))

        return {
            "score": final_score,
            "metrics": {
                "length": total_length,
                "text_density": text_density,
                "ad_density": ad_density,
                "readability": readability,
                "topic_relevance": topic_relevance
            },
            "reason": "High quality content" if final_score > 0.8 else "Medium quality content"
        }

    def extract_key_information(self, content):
        """Extract important information from content"""
        if not content or len(content) < 500:
            return {"summary": "Content too short for extraction", "entities": []}

        # Extract potential entities
        entities = self._extract_entities(content)

        # Extract potential key sentences
        sentences = re.split(r'(?<=[.!?])\s+', content)

        # Score sentences
        scored_sentences = []
        for sentence in sentences:
            # Skip very short sentences
            if len(sentence) < 40:
                continue

            # Score based on keywords
            keyword_count = sum(1 for topic in self.topics_of_interest
                              if topic.lower() in sentence.lower())

            # Score based on position (earlier is better)
            position_score = 1.0 - (sentences.index(sentence) / max(1, len(sentences)))

            # Calculate final score
            score = (keyword_count * 0.6) + (position_score * 0.4)

            scored_sentences.append((sentence, score))

        # Sort and select top sentences
        top_sentences = sorted(scored_sentences, key=lambda x: x[1], reverse=True)[:5]

        return {
            "summary": " ".join([s[0] for s in top_sentences]),
            "entities": entities[:10]  # Top 10 entities
        }

    def _calculate_text_density(self, content):
        """Calculate the ratio of text to HTML/markup"""
        if not content:
            return 0

        # Remove HTML tags if present
        text_only = re.sub(r'<[^>]+>', ' ', content)
        text_only = re.sub(r'\s+', ' ', text_only).strip()

        return len(text_only) / max(1, len(content))

    def _estimate_ad_density(self, content):
        """Estimate the density of advertisements"""
        if not content:
            return 0

        # Look for common ad-related terms
        ad_terms = [
            "advertisement", "sponsor", "promoted", "buy now", "limited offer",
            "discount", "sale", "click here", "banner", "popup"
        ]

        ad_count = sum(content.lower().count(term) for term in ad_terms)

        # Count potential ad-related HTML elements
        ad_elements = len(re.findall(r'<div[^>]*(?:ad|banner|sponsor|promo)[^>]*>', content, re.I))

        # Normalize by content length
        return min(1.0, (ad_count + ad_elements * 2) / max(1, len(content) / 1000))

    def _calculate_readability(self, content):
        """Calculate a readability score"""
        if not content or len(content) < 100:
            return 0

        # Basic implementation of the Flesch Reading Ease formula

        # Clean text
        text = re.sub(r'<[^>]+>', ' ', content)  # Remove HTML
        text = re.sub(r'[^\w\s.]', '', text)     # Keep only words, spaces, periods
        text = re.sub(r'\s+', ' ', text).strip() # Normalize whitespace

        # Count sentences
        sentences = len(re.findall(r'[.!?]+', text))

        # Count words
        words = len(text.split())

        # Count syllables (very rough approximation)
        syllables = sum(self._count_syllables(word) for word in text.split())

        # Calculate readability (simplified Flesch formula)
        if words == 0 or sentences == 0:
            return 0

        words_per_sentence = words / max(1, sentences)
        syllables_per_word = syllables / max(1, words)

        return max(0, min(100, 206.835 - (1.015 * words_per_sentence) - (84.6 * syllables_per_word)))

    def _count_syllables(self, word):
        """Very basic syllable counter"""
        word = word.lower()
        if len(word) <= 3:
            return 1

        # Count vowel groups
        vowels = "aeiouy"
        count = 0
        prev_is_vowel = False

        for char in word:
            is_vowel = char in vowels
            if is_vowel and not prev_is_vowel:
                count += 1
            prev_is_vowel = is_vowel

        # Adjust for common patterns
        if word.endswith('e'):
            count -= 1
        if word.endswith('le') and len(word) > 2 and word[-3] not in vowels:
            count += 1
        if count == 0:
            count = 1

        return count

    def _calculate_topic_relevance(self, content):
        """Calculate relevance to topics of interest"""
        if not content:
            return 0

        content_lower = content.lower()
        matches = sum(content_lower.count(topic) for topic in self.topics_of_interest)

        # Normalize by content length
        normalized_matches = matches / max(1, len(content) / 1000)

        return min(1.0, normalized_matches / 5)  # Cap at 1.0

    def _extract_entities(self, content):
        """Extract potential named entities"""
        if not content:
            return []

        # Very simple entity extraction
        # In a real system, use NER models

        # Look for capitalized word sequences
        entities = re.findall(r'(?<![.?!])\s([A-Z][a-z]+(?:\s+[A-Z][a-z]+){1,5})', content)

        # Look for technical terms
        tech_terms = [
            "algorithm", "neural network", "machine learning", "deep learning",
            "artificial intelligence", "quantum", "data science", "transformer",
            "reinforcement learning", "natural language processing", "computer vision"
        ]

        for term in tech_terms:
            if term in content.lower():
                entities.append(term.title())

        return list(set(entities))  # Remove duplicates

    def _generate_content_fingerprint(self, content):
        """Generate a fingerprint to identify similar content"""
        if not content:
            return ""

        # Clean the content
        cleaned = re.sub(r'<[^>]+>', ' ', content)
        cleaned = re.sub(r'\s+', ' ', cleaned).strip().lower()

        # Get the most meaningful words
        words = cleaned.split()
        if len(words) > 100:
            # Use a sample of words from beginning, middle and end
            sample = words[:30] + words[len(words)//2-15:len(words)//2+15] + words[-30:]
            cleaned = " ".join(sample)

        # Create hash
        return hashlib.md5(cleaned.encode()).hexdigest()

# =============================================================================
# FREE WILL MODULE
# =============================================================================
class SuperQuantumFreeWill:
    """
    Advanced free will module with quantum-inspired decision making
    and adaptive exploration strategies.
    """
    def __init__(self, agent):
        self.agent = agent
        self.semantic_memory = {}
        self.domain_intelligence = DomainIntelligence()
        self.memory_set = set()
        self.consciousness_link = None

        # Decision dynamics
        self.exploration_weight = 0.6
        self.exploitation_weight = 0.4
        self.domain_diversity_weight = 0.3
        self.goal_relevance_weight = 0.5
        self.quantum_influence_weight = 0.4

        # Personality traits
        self.personality = {
            "curiosity": 0.9,
            "depth_preference": 0.7,
            "risk_taking": 0.65,
            "patience": 0.5,
            "creativity": 0.8
        }

        # Memory weighting
        self.memory_importance = {}

        # Get planner access
        self.temporal_planner = None
        if hasattr(agent, "ai_manager"):
            self.temporal_planner = getattr(agent.ai_manager, "temporal_planner", None)

        # Fallback URLs for when memory is empty
        self.fallback_urls = [
            "https://en.wikipedia.org/wiki/Special:Random",
            "https://news.ycombinator.com/",
            "https://github.com/explore",
            "https://arxiv.org/list/cs.AI/recent",
            "https://www.nature.com/",
            "https://www.reddit.com/r/science/"
        ]

        log_event("SuperQuantumFreeWill initialized", "QUANTUM")

    def link_consciousness(self, consciousness_module):
        """Connect to consciousness module for reflective capabilities"""
        self.consciousness_link = consciousness_module
        log_event("FreeWill linked with ConsciousnessModule", "INFO")

    def _get_active_goal_description(self):
        """Safely retrieve the active goal description"""
        try:
            if self.temporal_planner is not None and hasattr(self.temporal_planner, "select_active_goal"):
                goal = self.temporal_planner.select_active_goal()
                if goal and isinstance(goal, dict):
                    return goal.get("description", "")
            return ""
        except Exception as e:
            log_event(f"Error retrieving goal description: {e}", "ERROR")
            return ""

    def select_url(self):
        """
        Select the next URL to visit using quantum-inspired
        decision making with multiple factors
        """
        log_event("Selecting URL with quantum-inspired strategy", "QUANTUM")

        # Get candidate URLs from memory or use fallbacks
        candidate_urls = list(self.memory_set)
        if not candidate_urls:
            log_event("Memory set is empty. Using fallback URLs.", "WARNING")
            candidate_urls = self.fallback_urls

        # Get consciousness level if available
        awareness_level = 0.5
        if self.consciousness_link:
            awareness_level = self.consciousness_link.awareness_level

        # Get current goal
        current_goal_description = self._get_active_goal_description()

        # Calculate scores with quantum influence
        url_scores = {}

        for url in candidate_urls:
            # Parse domain
            domain = urlparse(url).netloc

            # Base score with quantum randomness
            # Higher consciousness reduces quantum randomness
            quantum_factor = self.quantum_influence_weight * (1 - awareness_level)

            # Quantum superposition of initial states
            quantum_states = []
            for _ in range(3):  # Generate 3 possible quantum states
                phase = random.uniform(0, 2 * math.pi)
                amplitude = random.uniform(0.3, 1.0)
                state_score = amplitude * math.cos(phase)
                quantum_states.append(state_score)

            # Collapse quantum states weighted by consciousness
            quantum_score = sum(quantum_states) / len(quantum_states)
            score = quantum_score * quantum_factor

            # Add domain diversity factor
            domain_visits = self.agent.stats.get("domain_stats", {}).get(domain, {}).get("visits", 0)
            domain_diversity_score = 1.0 / (1 + domain_visits)
            score += self.domain_diversity_weight * domain_diversity_score

            # Check goal relevance - exact matches and semantic similarity
            if current_goal_description:
                # Direct keyword matching
                if (current_goal_description.lower() in url.lower() or
                    current_goal_description.lower() in domain.lower()):
                    score += self.goal_relevance_weight * 0.7

                # Domain-specific boosts based on goal types
                if "explore" in current_goal_description.lower():
                    if domain not in self.agent.stats.get("domains_visited", set()):
                        score += self.goal_relevance_weight * 0.5
                elif "deep" in current_goal_description.lower():
                    if ".edu" in domain or "research" in domain:
                        score += self.goal_relevance_weight * 0.6

            # Apply personality factors
            if "blog" in url.lower() or "forum" in url.lower():
                score += self.personality["curiosity"] * 0.2
            if "research" in url.lower() or "paper" in url.lower() or "edu" in domain:
                score += self.personality["depth_preference"] * 0.3
            if random.random() < self.personality["risk_taking"]:
                score += random.uniform(0, 0.5)  # Occasional boost

            # Add memory importance if this URL is known
            if url in self.memory_importance:
                score += self.memory_importance[url] * 0.4

            # Store score
            url_scores[url] = score

        # Occasionally make quantum leap decision
        if random.random() < self.quantum_influence_weight * 0.3:
            # Complete quantum randomness - ignore calculated scores
            quantum_choice = random.choice(candidate_urls)
            log_event(f"Made quantum leap URL choice: {quantum_choice}", "QUANTUM")
            self.agent.stats["last_url"] = quantum_choice
            return quantum_choice

        # Normal selection based on scores
        if url_scores:
            try:
                best_url = max(url_scores.items(), key=lambda x: x[1])[0]
                log_event(f"Selected URL: {best_url} with score: {url_scores[best_url]:.2f}", "INFO")
                self.agent.stats["last_url"] = best_url
                return best_url
            except Exception as e:
                log_event(f"Error selecting best URL: {e}", "ERROR")
                fallback = random.choice(candidate_urls)
                log_event(f"Using fallback URL selection: {fallback}", "WARNING")
                self.agent.stats["last_url"] = fallback
                return fallback
        else:
            # No scores calculated - use random selection
            fallback = random.choice(candidate_urls)
            log_event(f"No URL scores available. Using random selection: {fallback}", "WARNING")
            self.agent.stats["last_url"] = fallback
            return fallback

    def discover_links(self, html_content, base_url):
        """Discover and extract links from HTML content"""
        links, details = enhanced_link_discovery(html_content, base_url)

        # Filter for high-quality links
        if details:
            high_quality_links = [link_data['url'] for link_data in details if link_data['quality_score'] > 0.6]
            if high_quality_links:
                log_event(f"Discovered {len(high_quality_links)} high-quality links (quality > 0.6)", "INFO")

                # Add to memory
                self.expand_memory(high_quality_links)

                return len(high_quality_links)

        # Add all discovered links to memory
        self.expand_memory(links)

        log_event(f"Discovered {len(links)} links (using basic quality filter)", "INFO")
        return len(links)

    def store_semantic_content(self, url, content):
        """Store content with semantic encoding for future reference"""
        # Create semantic memory module if needed
        semantic_module = SemanticMemoryModule()
        semantic_module.store_semantic_content(url, content)

        # Store in this instance's semantic memory
        self.semantic_memory[url] = semantic_module.semantic_memory.get(url, {})

    def decide(self):
        """
        Make a decision about what action to take next using
        quantum-inspired decision making
        """
        try:
            log_event("Making quantum-enhanced decision...", "QUANTUM")

            # Possible actions
            possible_actions = ["search", "expand", "adapt", "reconnect", "evaluate", "quantum_leap"]

            # Initialize quantum state - each action has amplitude and phase
            quantum_state = {}
            for action in possible_actions:
                phase = random.uniform(0, 2 * math.pi)
                amplitude = random.uniform(0.3, 1.0)
                quantum_state[action] = {"amplitude": amplitude, "phase": phase}

            # Get current context
            current_goal_description = self._get_active_goal_description()

            # Get consciousness awareness level
            awareness_level = 0.5
            if self.consciousness_link:
                awareness_level = self.consciousness_link.awareness_level

            # Get thinking mode if available
            thinking_mode = "balanced"
            if hasattr(self.agent, "ai_manager") and hasattr(self.agent.ai_manager, "autonomous_mind"):
                thinking_mode = getattr(self.agent.ai_manager.autonomous_mind, "current_mode", "balanced")

            # Apply quantum interference based on context

            # 1. Goal-based interference
            if current_goal_description:
                if "explore" in current_goal_description.lower():
                    # Amplify exploration actions
                    quantum_state["expand"]["amplitude"] *= 1.3
                    quantum_state["search"]["amplitude"] *= 1.2
                elif "deep" in current_goal_description.lower():
                    # Amplify deepening actions
                    quantum_state["evaluate"]["amplitude"] *= 1.4
                    quantum_state["adapt"]["amplitude"] *= 1.2

            # 2. Thinking mode interference
            if thinking_mode == "analytical":
                quantum_state["evaluate"]["amplitude"] *= 1.3
                quantum_state["search"]["amplitude"] *= 1.2
            elif thinking_mode == "creative":
                quantum_state["quantum_leap"]["amplitude"] *= 1.5
                quantum_state["expand"]["amplitude"] *= 1.2
            elif thinking_mode == "critical":
                quantum_state["adapt"]["amplitude"] *= 1.3
                quantum_state["evaluate"]["amplitude"] *= 1.2

            # 3. Recent actions interference - FIXED INDEXING
            recent_actions = [] # Initialize as empty list
            if hasattr(self.agent, 'action_log') and self.agent.action_log: # Check if action_log exists and is not None
                if len(self.agent.action_log) >= 3: # CHECK if action_log has at least 3 elements
                    recent_actions = [a.get("action", "") for a in list(self.agent.action_log)[-3:]] # Safe list conversion and slice

            if recent_actions:
                # Avoid repeating the same action too many times
                most_common = max(set(recent_actions), key=recent_actions.count) if recent_actions else None
                if most_common is not None: # CHECK if most_common is NOT None
                    if most_common in quantum_state: # CHECK if most_common is a valid key
                        quantum_state[most_common]["amplitude"] *= 0.7

            # 4. Success-based amplification - FIXED INDEXING
            successful_actions = [] # Initialize as empty list
            if hasattr(self.agent, 'action_log') and self.agent.action_log: # Check if action_log exists and is not None
                if len(self.agent.action_log) >= 5: # CHECK if action_log has at least 5 elements
                    successful_actions = [a.get("action", "") for a in list(self.agent.action_log)[-5:] # Safe list conversion and slice
                                         if a.get("content_length", 0) > 1000]

            if successful_actions:
                last_success = successful_actions[-1]  # Access last element safely now
                if last_success in quantum_state:  # Safely check dictionary key
                    quantum_state[last_success]["amplitude"] *= 1.2

            # Apply consciousness as quantum observer effect
            # Higher consciousness makes decision more deterministic
            for action in possible_actions:
                random_factor = random.uniform(0.8, 1.2) * (1 - awareness_level)
                quantum_state[action]["amplitude"] *= (1 + random_factor * 0.2)

            # Calculate probabilities (square of amplitudes)
            total_probability = sum(state["amplitude"]**2 for state in quantum_state.values())
            probabilities = {action: (state["amplitude"]**2) / total_probability
                           for action, state in quantum_state.items()}

            # Collapse the quantum state by observation
            action_type = random.choices(
                list(probabilities.keys()),
                weights=list(probabilities.values()),
                k=1
            )[0]

            # Create decision package
            decision = {
                "action": action_type,
                "quantum_confidence": probabilities[action_type],
                "reasoning": f"Quantum decision process ({thinking_mode} mode) - goal: {current_goal_description[:30]}",
                "timestamp": datetime.now().isoformat()
            }

            log_event(f"Decision: {action_type} with {probabilities[action_type]:.2f} quantum confidence", "QUANTUM")

            # Special handling for quantum_leap action
            if action_type == "quantum_leap":
                # Map to a standard action but with more randomness
                standard_actions = ["search", "expand", "adapt", "reconnect", "evaluate"]
                decision["action"] = random.choice(standard_actions)
                decision["quantum_leap"] = True
                log_event(f"Quantum leap mapped to {decision['action']}", "QUANTUM")

            return decision

        except Exception as e:
            log_event(f"Decision error: {e}", "ERROR")
            # Fallback to simple random choice
            fallback_action = random.choice(["expand", "search", "adapt"])
            return {"action": fallback_action, "error": str(e)[:200]}
# =============================================================================
# AI MANAGEMENT SYSTEM
# =============================================================================
# =============================================================================
# AI MANAGEMENT SYSTEM
# =============================================================================
class AIManager:
    """
    Central management system for the autonomous agent, coordinating
    decision-making, planning, and evolution.
    """
    def __init__(self, agent, model):
        self.agent = agent
        self.model = model

        # Core subsystems
        self.temporal_planner = TemporalPlanner()
        self.autonomous_mind = AutonomousMind(agent, model)
        self.consciousness = ConsciousnessModule(agent)
        self.imagination = ImaginationEngine()

        # Self-improvement systems
        self.meta_learning = MetaLearningModule(model)
        self.evolution_engine = MetaEvolutionEngine()

        # Operational tracking
        self.cycle_counter = 0
        self.last_evolution_attempt = 0
        self.evolution_interval = 50
        self.error_recovery_attempts = 0

        # Initialize subsystems
        self.temporal_planner.initialize_goals()

        # Connect subsystems
        if hasattr(self.agent, "free_will") and hasattr(self.agent.free_will, "link_consciousness"):
            self.agent.free_will.link_consciousness(self.consciousness)

        log_event("AIManager initialized with all autonomous systems", "INFO")


    async def run_cycle(self, optimizer=None):
        """Run a complete autonomous cycle with enhanced error handling"""
        self.cycle_counter += 1
        log_event(f"=== Enhanced Autonomous Cycle {self.cycle_counter} ===", "INFO")

        try:
            # 1. Perception - get environment state
            try:
                observation = self.agent.perceive()
            except Exception as e:
                log_event(f"Error in perception phase: {str(e)}", "ERROR")
                observation = {"error": str(e)}  # Minimal fallback observation

            # 2. Consciousness reflection with error handling
            try:
                if hasattr(self, 'consciousness'):
                    self.consciousness.reflect(observation)
            except Exception as e:
                log_event(f"Error in consciousness reflection: {str(e)}", "ERROR")
                # Continue even if reflection fails

            # 3. Decision making with fallbacks
            base_decision = {"action": "expand"}  # Default fallback
            try:
                if hasattr(self.agent, "free_will") and hasattr(self.agent.free_will, "decide"):
                    decision = self.agent.free_will.decide()
                    if isinstance(decision, dict) and "action" in decision:
                        base_decision = decision
            except Exception as e:
                log_event(f"Decision error: {str(e)}. Using fallback decision.", "ERROR")

            # 4. Planning with error handling
            try:
                if hasattr(self, 'temporal_planner') and self.temporal_planner:
                    full_plan = self.temporal_planner.plan_action(
                        base_decision.get("action", "expand"),
                        observation
                    )
                else:
                    # Fallback simple plan if no temporal planner
                    full_plan = {
                        "action": base_decision.get("action", "expand"),
                        "strategy": "fallback_strategy",
                        "goal": "Continue system operation"
                    }
            except Exception as e:
                log_event(f"Planning error: {str(e)}. Using simplified plan.", "ERROR")
                # Create minimal plan on failure
                full_plan = {
                    "action": base_decision.get("action", "expand"),
                    "strategy": "emergency_strategy",
                    "goal": "Recover from planning failure"
                }

            # 5. Imagination - simulate outcomes (non-critical)
            try:
                if hasattr(self, 'imagination') and random.random() < 0.2:
                    self.imagination.simulate_creation()
            except Exception as e:
                log_event(f"Non-critical error in imagination: {str(e)}", "WARNING")

            # 6. Execute action with timeout protection
            try:
                # Set a timeout for execution to prevent hanging
                action_task = asyncio.create_task(
                    asyncio.to_thread(self.agent.act, full_plan, optimizer)
                )
                action_successful = await asyncio.wait_for(action_task, timeout=60.0)
            except asyncio.TimeoutError:
                log_event("Action execution timed out after 60 seconds", "ERROR")
                action_successful = False
            except Exception as e:
                log_event(f"Action execution error: {str(e)}", "ERROR")
                action_successful = False

            # After action execution is successful:
            if action_successful and hasattr(self.agent, 'planner_sifter'):
                strategy_name = full_plan.get("strategy", "exploration")
                result_data = {
                    "content_length": self.agent.action_log[-1].get("content_length", 0),
                    "links_discovered": self.agent.action_log[-1].get("links_discovered", 0),
                    "success": action_successful
                }
                self.agent.planner_sifter.update_strategy_effectiveness(strategy_name, result_data)

            # 7. Performance assessment
            performance_metrics = {
                "success": action_successful,
                "content_length": self.agent.action_log[-1].get("content_length", 0) if self.agent.action_log else 0,
                "links_discovered": self.agent.action_log[-1].get("links_discovered", 0) if self.agent.action_log else 0,
                "cycle": self.cycle_counter
            }

            # 8. Reflection and adaptation (non-critical)
            try:
                if hasattr(self, 'temporal_planner'):
                    self.temporal_planner.reflect_and_adapt(performance_metrics)
            except Exception as e:
                log_event(f"Non-critical error in reflection: {str(e)}", "WARNING")

            # 9. Error detection (non-critical)
            try:
                if hasattr(self, 'imagination'):
                    error_details = self.imagination.simulate_error_detection()
                    if error_details:
                        # Apply correction
                        self.imagination.simulate_error_correction(error_details)
            except Exception as e:
                log_event(f"Non-critical error in error detection: {str(e)}", "WARNING")

            # 10. Self-evolution at intervals (non-critical)
            try:
                if (hasattr(self, 'evolution_engine') and
                    self.cycle_counter - getattr(self, 'last_evolution_attempt', 0) >= getattr(self, 'evolution_interval', 50)):
                    log_event("Attempting system evolution...", "INFO")
                    result, message = self.evolution_engine.evolve_system(self.agent)
                    self.last_evolution_attempt = self.cycle_counter
                    log_event(f"Evolution attempt result: {result} - {message}", "INFO")
            except Exception as e:
                log_event(f"Non-critical error in evolution: {str(e)}", "WARNING")

            # 11. Self-refinement (with error handling)
            try:
                self.agent.refine()
            except Exception as e:
                log_event(f"Error in agent refinement: {str(e)}", "ERROR")
                # Don't let refinement errors abort the cycle

            # Reset error recovery counter on success
            self.error_recovery_attempts = 0

            return {
                "cycle": self.cycle_counter,
                "action": full_plan.get("action", "unknown"),
                "strategy": full_plan.get("strategy", "none"),
                "success": action_successful
            }

        except Exception as e:
            # Error recovery
            self.error_recovery_attempts += 1
            log_event(f"CYCLE ERROR: {str(e)}", "ERROR")
            log_event(traceback.format_exc(), "ERROR")

            # Implement progressive recovery strategies
            if self.error_recovery_attempts < 3:
                log_event("Attempting standard error recovery", "WARNING")
            elif self.error_recovery_attempts < 5:
                log_event("Attempting advanced error recovery - resetting system state", "WARNING")
                # Reset consciousness state if available
                if hasattr(self, 'consciousness'):
                    self.consciousness.awareness_level = 0.5
                    self.consciousness.current_state = "balanced"
            else:
                log_event("Critical error threshold reached - emergency recovery", "CRITICAL")
                # Emergency reset of all systems
                if hasattr(self, 'consciousness'):
                    self.consciousness = ConsciousnessModule(self.agent)
                if hasattr(self, 'temporal_planner'):
                    self.temporal_planner.cycle_count = 0
                    self.temporal_planner.refresh_short_term_goals()

            return {
                "status": "error",
                "cycle": self.cycle_counter,
                "error": str(e),
                "recovery_attempt": self.error_recovery_attempts
            }



# =============================================================================
# TEMPORAL PLANNING AND GOAL MANAGEMENT
# =============================================================================
class TemporalPlanner:
    """
    Advanced planning system that operates across multiple time horizons
    and manages goals with temporal dependencies.
    """
    def __init__(self):
        self.short_term_goals = []
        self.long_term_goals = []
        self.goal_history = []
        self.current_strategy = None
        self.strategy_effectiveness = {}
        self.time_horizon_days = 7
        self.reflection_interval = 20
        self.cycle_count = 0

        # Add strategy mapping to match PlannerSifter strategy names
        self.strategy_mapping = {
            "exploration": "broad_exploration",
            "deepening": "depth_first",
            "integration": "connect_domains",
            "evaluation": "evaluate_sources",
            "quantum": "quantum_reasoning",
            "creative": "creative_synthesis"
        }

    def initialize_goals(self):
        """Set up initial goal structure"""
        self.long_term_goals = [
            {
                "id": "knowledge_diversity",
                "description": "Maximize diversity of knowledge domains",
                "priority": 0.8,
                "progress": 0.0,
                "created": datetime.now().isoformat()
            },
            {
                "id": "model_efficiency",
                "description": "Optimize neural architecture for learning efficiency",
                "priority": 0.7,
                "progress": 0.0,
                "created": datetime.now().isoformat()
            },
            {
                "id": "content_quality",
                "description": "Improve filtering and processing of high-value content",
                "priority": 0.9,
                "progress": 0.0,
                "created": datetime.now().isoformat()
            },
            {
                "id": "quantum_reasoning",
                "description": "Develop quantum-inspired reasoning capabilities",
                "priority": 1.0,
                "progress": 0.0,
                "created": datetime.now().isoformat()
            }
        ]
        self.refresh_short_term_goals()
        log_event("Temporal planner initialized with long-term goals", "INFO")

    def refresh_short_term_goals(self):
        """Generate new short-term goals aligned with long-term objectives"""
        # Save the existing goals that are still valid
        valid_goals = []
        for goal in self.short_term_goals:
            if goal.get("duration", 0) > 0:
                valid_goals.append(goal)

        # Clear the short_term_goals list
        self.short_term_goals = valid_goals

        # Check if we need to generate new goals
        if len(self.short_term_goals) >= 5:
            return  # We still have enough goals

        # Define knowledge domains
        domains = [
            "technical", "scientific", "humanities", "news",
            "reference", "creative", "analytical", "philosophical"
        ]

        # Generate 3-5 new short term goals
        goals_to_generate = min(5, 8 - len(self.short_term_goals))
        for _ in range(goals_to_generate):
            # Randomly select goal type and domain
            goal_type = random.choice(["exploration", "deepening", "integration", "refinement"])
            domain = random.choice(domains)

            # Generate goal based on type
            if goal_type == "exploration":
                goal = {
                    "id": f"explore_{domain}_{int(time.time())}",
                    "description": f"Discover new content sources in {domain}",
                    "priority": random.uniform(0.5, 0.9),
                    "duration": random.randint(10, 30),
                    "type": "exploration",
                    "domain": domain,
                    "created": datetime.now().isoformat()
                }
            elif goal_type == "deepening":
                goal = {
                    "id": f"deepen_{domain}_{int(time.time())}",
                    "description": f"Build deeper understanding in {domain}",
                    "priority": random.uniform(0.6, 0.95),
                    "duration": random.randint(5, 15),
                    "type": "deepening",
                    "domain": domain,
                    "created": datetime.now().isoformat()
                }
            elif goal_type == "integration":
                domain2 = random.choice([d for d in domains if d != domain])
                goal = {
                    "id": f"integrate_{domain}_{domain2}_{int(time.time())}",
                    "description": f"Connect knowledge between {domain} and {domain2}",
                    "priority": random.uniform(0.7, 0.9),
                    "duration": random.randint(8, 20),
                    "type": "integration",
                    "domains": [domain, domain2],
                    "created": datetime.now().isoformat()
                }
            else:  # refinement
                goal = {
                    "id": f"refine_{domain}_{int(time.time())}",
                    "description": f"Optimize learning approach in {domain}",
                    "priority": random.uniform(0.5, 0.8),
                    "duration": random.randint(5, 12),
                    "type": "refinement",
                    "domain": domain,
                    "created": datetime.now().isoformat()
                }

            self.short_term_goals.append(goal)

        log_event(f"Refreshed short-term goals: {goals_to_generate} new goals created", "INFO")

    def select_active_goal(self):
        """Select the highest priority current goal"""
        # Remove expired goals
        active_goals = [g for g in self.short_term_goals if g.get("duration", 0) > 0]
        self.short_term_goals = active_goals

        # Decrease duration for all goals
        for goal in self.short_term_goals:
            goal["duration"] = max(0, goal.get("duration", 10) - 1)

        # Refresh if needed
        if not self.short_term_goals:
            self.refresh_short_term_goals()

        # Select highest priority goal
        if self.short_term_goals:
            return max(self.short_term_goals, key=lambda x: x.get("priority", 0))
        else:
            # Default goal if something went wrong
            default_goal = {
                "id": "default_exploration",
                "description": "Default exploration",
                "priority": 0.5,
                "type": "exploration",
                "domain": "reference",  # Provide a default domain
                "duration": 5  # Give it some duration
            }
            self.short_term_goals.append(default_goal)  # Add to goals list for tracking
            return default_goal

    def reflect_and_adapt(self, performance_metrics):
        """Periodically reflect on goal progress and adapt strategies"""
        self.cycle_count += 1

        # Update goal progress based on performance
        if performance_metrics.get("success", False):
            active_goal = self.select_active_goal()

            # Find corresponding long-term goal to update
            for goal in self.long_term_goals:
                # Update based on goal type alignment
                if (active_goal.get("type") == "exploration" and goal["id"] == "knowledge_diversity") or \
                   (active_goal.get("type") == "deepening" and goal["id"] == "content_quality") or \
                   (active_goal.get("type") == "refinement" and goal["id"] == "model_efficiency") or \
                   (active_goal.get("type") == "integration" and goal["id"] == "quantum_reasoning"):
                    # Small progress increment
                    increment = min(0.05, performance_metrics.get("content_length", 0) / 20000)
                    goal["progress"] = min(1.0, goal["progress"] + increment)

            # Record the strategy effectiveness
            strategy = self.current_strategy
            if strategy:
                if strategy not in self.strategy_effectiveness:
                    self.strategy_effectiveness[strategy] = []

                # Score based on content and links
                score = min(1.0, performance_metrics.get("content_length", 0) / 5000 +
                           performance_metrics.get("links_discovered", 0) / 10)
                self.strategy_effectiveness[strategy].append(score)

                # Limit history size
                if len(self.strategy_effectiveness[strategy]) > 20:
                    self.strategy_effectiveness[strategy] = self.strategy_effectiveness[strategy][-20:]

        # Major reflection at intervals
        if self.cycle_count % self.reflection_interval == 0:
            log_event("Performing strategic reflection and adaptation...", "INFO")

            # Analyze strategy effectiveness
            for strategy, metrics in self.strategy_effectiveness.items():
                if metrics:
                    avg_performance = sum(metrics) / len(metrics)
                    log_event(f"Strategy '{strategy}' average performance: {avg_performance:.4f}", "INFO")

            # Adjust long-term goal priorities
            total_adjustment = 0
            for goal in self.long_term_goals:
                # Random adjustment with bias toward less-progressed goals
                bias = 1.0 - goal.get("progress", 0)
                adjustment = random.uniform(-0.1, 0.15) * bias

                goal["priority"] = max(0.1, min(1.0, goal["priority"] + adjustment))
                total_adjustment += abs(adjustment)

            # Sometimes create new evolved goals
            if random.random() < 0.2:
                # Create a new long-term goal
                new_goal_types = [
                    "Develop cognitive synergy across domains",
                    "Optimize information integration pathways",
                    "Enhance quantum processing capabilities",
                    "Improve anomaly detection in knowledge structures",
                    "Develop adaptive learning mechanisms"
                ]

                new_goal_id = f"evolved_goal_{int(time.time())}"
                new_goal = {
                    "id": new_goal_id,
                    "description": f"Evolved objective: {random.choice(new_goal_types)}",
                    "priority": random.uniform(0.7, 0.9),
                    "progress": 0.0,
                    "created": datetime.now().isoformat()
                }

                # Limit total goals
                if len(self.long_term_goals) < 10:  # Prevent too many goals
                    self.long_term_goals.append(new_goal)
                    log_event(f"Created new long-term goal: {new_goal['description']}", "INFO")

            # Clean expired goals from short-term list
            self.short_term_goals = [g for g in self.short_term_goals if g.get("duration", 0) > 0]

            # Refresh short-term goals
            self.refresh_short_term_goals()

            log_event(f"Reflection complete: adjusted {len(self.long_term_goals)} long-term goals (total Î”: {total_adjustment:.4f})", "INFO")

    def plan_action(self, base_action, environment_state=None):
        """Generate temporal plan based on goals and environment"""
        # Get current active goal
        active_goal = self.select_active_goal()

        # Consider temporal context
        current_time = datetime.now()
        is_weekend = current_time.weekday() >= 5
        is_business_hours = 9 <= current_time.hour <= 17

        # Available strategies with weights
        strategy_options = [
            "broad_exploration",     # Wide but shallow exploration
            "depth_first",           # Deep dive into specific domain
            "connect_domains",       # Look for connections between areas
            "evaluate_sources",      # Focus on quality assessment
            "quantum_reasoning",     # Use quantum processing modes
            "creative_synthesis"     # Generate new insights
        ]

        # Default weights
        weights = [0.2, 0.2, 0.2, 0.15, 0.15, 0.1]

        # Adjust weights based on temporal context
        if is_business_hours and not is_weekend:
            # Business hours - more analytical
            weights = [0.1, 0.2, 0.2, 0.3, 0.1, 0.1]
        elif not is_business_hours:
            # Non-business hours - more exploratory
            weights = [0.3, 0.1, 0.1, 0.1, 0.2, 0.2]

        # Adjust based on goal type
        goal_type = active_goal.get("type", "")
        if goal_type == "exploration":
            # Boost exploration strategies
            weights[0] += 0.2  # More broad_exploration
            weights[5] += 0.1  # More creative_synthesis
        elif goal_type == "deepening":
            # Boost deepening strategies
            weights[1] += 0.2  # More depth_first
            weights[3] += 0.1  # More evaluate_sources
        elif goal_type == "integration":
            # Boost connection strategies
            weights[2] += 0.2  # More connect_domains
            weights[5] += 0.1  # More creative_synthesis
        elif goal_type == "refinement":
            # Boost refinement strategies
            weights[3] += 0.2  # More evaluate_sources
            weights[4] += 0.1  # More quantum_reasoning

        # Ensure weights sum to 1
        total = sum(weights)
        weights = [w/total for w in weights]

        # Select strategy
        self.current_strategy = random.choices(strategy_options, weights=weights, k=1)[0]

        # Create plan
        timestamp = current_time.isoformat()
        plan = {
            "action": base_action,
            "goal": active_goal["description"],
            "strategy": self.current_strategy,
            "timestamp": timestamp,
            "execution_context": {
                "is_weekend": is_weekend,
                "is_business_hours": is_business_hours,
                "current_hour": current_time.hour,
                "goal_type": goal_type,
                "goal_domain": active_goal.get("domain", "unknown")
            }
        }

        log_event(f"Generated temporal plan: {plan['action']} using {plan['strategy']} strategy for goal: {plan['goal']}", "INFO")
        return plan

    def _convert_old_strategy_name(self, old_name):
        """Convert old strategy names to new format if needed"""
        if old_name in self.strategy_mapping:
            return self.strategy_mapping[old_name]
        return old_name



# =============================================================================
# QUANTUM NEURAL ARCHITECTURE
# =============================================================================
class QuantumAttentionLayer(nn.Module):
    """
    Implements quantum-inspired attention with superposition of states
    that allows multiple attention pathways to exist simultaneously.
    """
    def __init__(self, embed_dim, num_heads=4, dropout=0.1):
        super().__init__()
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        self.head_dim = embed_dim // num_heads

        # Multi-dimensional quantum projection spaces
        self.q_proj = nn.Linear(embed_dim, embed_dim)
        self.k_proj = nn.Linear(embed_dim, embed_dim)
        self.v_proj = nn.Linear(embed_dim, embed_dim)
        self.o_proj = nn.Linear(embed_dim, embed_dim)

        # Phase shifters for quantum interference
        self.phase_shifts = nn.Parameter(torch.rand(num_heads) * 2 * math.pi)

        # Entanglement mixing for cross-attention effects
        self.entanglement_gate = nn.Linear(embed_dim, embed_dim)

        self.dropout = nn.Dropout(dropout)
        self.attention_weights = None  # Store for visualization

    def forward(self, x):
        batch_size, seq_len, _ = x.shape

        # Project inputs to queries, keys, values
        q = self.q_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim)
        k = self.k_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim)
        v = self.v_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim)

        # Transpose for attention computation
        q = q.transpose(1, 2)  # (batch_size, num_heads, seq_len, head_dim)
        k = k.transpose(1, 2)
        v = v.transpose(1, 2)

        # Apply phase shifts for quantum effects
        for h in range(self.num_heads):
            phase = self.phase_shifts[h]
            q[:, h] = q[:, h] * torch.cos(phase) + q[:, h] * torch.sin(phase)
            k[:, h] = k[:, h] * torch.cos(phase) - k[:, h] * torch.sin(phase)

        # Compute attention scores
        scores = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(self.head_dim)

        # Apply softmax and get attention weights
        attn_weights = F.softmax(scores, dim=-1)
        self.attention_weights = attn_weights  # Save for visualization
        attn_weights = self.dropout(attn_weights)

        # Apply attention to values
        attn_output = torch.matmul(attn_weights, v)

        # Apply entanglement between heads for quantum correlation effects
        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, seq_len, self.embed_dim)
        entangled = self.entanglement_gate(attn_output)

        # Final output projection
        output = self.o_proj(entangled + attn_output)  # Residual connection

        return output

class HyperdimensionalEncoder(nn.Module):
    """
    Implements hyperdimensional computing principles for efficient
    high-dimensional representation of concepts.
    """
    def __init__(self, input_dim, hd_dim=1024):
        super().__init__()
        self.input_dim = input_dim
        self.hd_dim = hd_dim

        # Create random basis vectors
        self.register_buffer('basis', torch.randn(input_dim, hd_dim).sign())

        # Learnable projection
        self.projection = nn.Linear(input_dim, input_dim)

    def forward(self, x):
        # Project input
        x_proj = self.projection(x)

        # Compute HD representation through binding and bundling
        batch_size = x_proj.shape[0]
        hd_vectors = torch.zeros(batch_size, self.hd_dim, device=x_proj.device)

        # Encode each dimension with element-wise multiplication (binding)
        for i in range(self.input_dim):
            # Scale by the input value
            scaled_basis = self.basis[i].unsqueeze(0) * x_proj[:, i].unsqueeze(1)
            # Add to the bundle (vector sum)
            hd_vectors += scaled_basis

        # Binarize to -1/+1 for clean HD representation
        hd_vectors = torch.sign(hd_vectors)

        return hd_vectors

class FractalLayer(nn.Module):
    """
    Self-similar recursive processing layer with dynamic scaling.
    """
    def __init__(self, embed_dim):
        super().__init__()
        self.fractal_scale = nn.Parameter(torch.tensor(1.0))
        self.temperature = nn.Parameter(torch.tensor(1.0))
        self.linear = nn.Linear(embed_dim, embed_dim)

    def forward(self, x):
        fractal_contribution = torch.tanh(self.linear(x) / self.temperature)
        return x + self.fractal_scale * fractal_contribution

class QuantumResonanceTensor(nn.Module):
    """
    Implements non-collapsing recursive state resonance that maintains
    multiple simultaneous state representations in quantum-inspired superposition.
    """
    def __init__(self, embed_dim, num_states=4, resonance_factor=0.7):
        super().__init__()
        self.embed_dim = embed_dim
        self.num_states = num_states
        self.resonance_factor = nn.Parameter(torch.tensor(resonance_factor))

        # Quantum state projectors
        self.state_projectors = nn.ModuleList([
            nn.Sequential(
                nn.Linear(embed_dim, embed_dim),
                nn.SiLU(),
            ) for _ in range(num_states)
        ])

        # Phase shifters for quantum entanglement
        self.phase_shifters = nn.Parameter(torch.randn(num_states) * 0.1)

        # State mixer - allows controlled interference between states
        self.state_mixer = nn.Linear(embed_dim * num_states, embed_dim)

        # Recursive memory gates
        self.recursive_gate = nn.GRUCell(embed_dim, embed_dim)

        # Prior state memory (initialized during forward pass)
        self.register_buffer('state_memory', None, persistent=False)

    def forward(self, x, iteration_count=3):
        batch_size = x.shape[0]

        # Initialize state memory if needed
        if self.state_memory is None or self.state_memory.shape[0] != batch_size:
            self.state_memory = torch.zeros(batch_size, self.embed_dim, device=x.device)

        # Generate multiple quantum states
        quantum_states = []
        for i in range(self.num_states):
            # Apply phase shift for quantum effects
            phase = torch.cos(self.phase_shifters[i] * math.pi)
            # Project into this quantum state
            state_i = self.state_projectors[i](x) * phase
            quantum_states.append(state_i)

        # Recursive resonance iterations
        for _ in range(iteration_count):
            # Update state memory through recursive gate
            self.state_memory = self.recursive_gate(x, self.state_memory)

            # Apply resonance effect (controlled interference)
            resonance = self.state_memory * self.resonance_factor

            # Apply resonance to each quantum state (non-collapsing)
            for i in range(self.num_states):
                quantum_states[i] = quantum_states[i] + resonance * (0.1 * (i + 1))

        # Combine quantum states through superposition
        combined_states = torch.cat(quantum_states, dim=-1)
        output = self.state_mixer(combined_states)

        # Residual connection
        output = output + x

        return output

class NeocortexBlock(nn.Module):
    """
    Advanced neural block inspired by neocortical structure with
    multiple processing pathways.
    """
    def __init__(self, embed_dim, num_quantum_states=4):
        super().__init__()
        # Attention for information routing
        self.attention = QuantumAttentionLayer(embed_dim)

        # Parallel processing streams
        self.fractal_stream = FractalLayer(embed_dim)
        self.quantum_stream = QuantumResonanceTensor(embed_dim, num_states=num_quantum_states)

        # Hyperdimensional binding for concept integration
        self.hd_encoder = HyperdimensionalEncoder(embed_dim, hd_dim=embed_dim)

        # Stream integration
        self.integration = nn.Linear(embed_dim * 3, embed_dim)
        self.norm = nn.LayerNorm(embed_dim)

    def forward(self, x):
        # Process through attention mechanism
        attended = self.attention(x)

        # Process through parallel streams
        fractal_out = self.fractal_stream(attended)
        quantum_out = self.quantum_stream(attended)

        # Create HD representations from the attended representation
        batch_size, seq_len, _ = attended.shape
        hd_out = self.hd_encoder(attended.view(-1, attended.size(-1))).view(batch_size, seq_len, -1)

        # Integrate all streams
        combined = torch.cat([fractal_out, quantum_out, hd_out], dim=-1)
        integrated = self.integration(combined)

        # Residual connection and normalization
        output = self.norm(x + integrated)

        return output



class AdaptiveLearningSystem:
    """
    Advanced system for dynamically adapting learning parameters and network architecture
    based on performance metrics and environmental feedback.
    """
    def __init__(self, model):
        self.model = model
        self.learning_rate_history = []
        self.performance_metrics = []
        self.architecture_changes = []
        self.adaptation_cycle = 0
        self.min_learning_rate = 1e-6
        self.max_learning_rate = 1e-3
        self.performance_window_size = 10
        self.exploration_rate = 0.3
        self.adaptation_threshold = 0.15
        self.architecture_expansion_threshold = 5

        # Initialize default learning rate on model
        self.default_learning_rate = 5e-5  # Same as initial LEARNING_RATE
        setattr(self.model, '_current_lr', self.default_learning_rate)

        log_event("AdaptiveLearningSystem initialized with dynamic adaptation capabilities", "INFO")

    def adapt_learning_rate(self, metrics):
        """
        Dynamically adjust learning rate based on recent performance metrics
        using a sophisticated control system approach.
        """
        self.adaptation_cycle += 1

        # Get current learning rate with fallback to default
        current_lr = getattr(self.model, '_current_lr', self.default_learning_rate)
        self.learning_rate_history.append(current_lr)

        # Record performance metrics
        if isinstance(metrics, dict):
            self.performance_metrics.append(metrics)

        # Need sufficient history for adaptation
        if len(self.performance_metrics) < self.performance_window_size:
            log_event(f"Building performance history: {len(self.performance_metrics)}/{self.performance_window_size}", "INFO")
            return current_lr

        # Analyze recent performance trend
        recent_metrics = self.performance_metrics[-self.performance_window_size:]

        # Calculate performance derivatives - how fast is loss changing?
        loss_values = [m.get('loss', 0.5) for m in recent_metrics if isinstance(m, dict) and 'loss' in m]
        if not loss_values or len(loss_values) < 3:
            return current_lr

        # First derivative - rate of change
        loss_changes = [loss_values[i] - loss_values[i-1] for i in range(1, len(loss_values))]
        avg_loss_change = sum(loss_changes) / len(loss_changes)

        # Second derivative - acceleration of change
        loss_acceleration = [loss_changes[i] - loss_changes[i-1] for i in range(1, len(loss_changes))]
        avg_loss_acceleration = sum(loss_acceleration) / max(1, len(loss_acceleration))

        # Decision logic for learning rate adjustment
        new_lr = current_lr

        # Case 1: Loss is decreasing quickly (negative change, negative acceleration)
        if avg_loss_change < -0.01 and avg_loss_acceleration < 0:
            new_lr = min(self.max_learning_rate, current_lr * 1.05)
            adjustment_type = "slight increase - good progress"

        # Case 2: Loss is decreasing but slowing down (negative change, positive acceleration)
        elif avg_loss_change < 0 and avg_loss_acceleration >= 0:
            new_lr = max(self.min_learning_rate, current_lr * 0.95)
            adjustment_type = "slight decrease - approaching minimum"

        # Case 3: Loss is increasing and accelerating (positive change, positive acceleration)
        elif avg_loss_change > 0.01 and avg_loss_acceleration > 0:
            new_lr = max(self.min_learning_rate, current_lr * 0.7)
            adjustment_type = "major decrease - moving away from minimum"

        # Case 4: Loss is increasing but decelerating (positive change, negative acceleration)
        elif avg_loss_change > 0 and avg_loss_acceleration <= 0:
            new_lr = max(self.min_learning_rate, current_lr * 0.85)
            adjustment_type = "moderate decrease - correcting overshoot"

        # Case 5: Stagnation - very small changes
        elif abs(avg_loss_change) < 0.001:
            if random.random() < self.exploration_rate:
                factor = random.uniform(0.5, 1.5)
                new_lr = max(self.min_learning_rate, min(self.max_learning_rate, current_lr * factor))
                adjustment_type = f"random exploration {'increase' if factor > 1 else 'decrease'}"
            else:
                adjustment_type = "no change - minimal fluctuation"
        else:
            adjustment_type = "no change - no clear pattern"

        # Apply the new learning rate with safeguards
        if abs(new_lr - current_lr) / current_lr > 0.01:  # 1% change threshold
            safeguarded_lr = self._apply_learning_rate_safeguards(new_lr)
            setattr(self.model, '_current_lr', safeguarded_lr)
            log_event(f"Learning rate adapted: {current_lr:.6f} â†’ {safeguarded_lr:.6f} ({adjustment_type})", "INFO")

            # Update global optimizer if available
            if hasattr(self.model, 'optimizer'):
                for param_group in self.model.optimizer.param_groups:
                    param_group['lr'] = safeguarded_lr
                log_event("Applied new learning rate to optimizer", "INFO")

        return new_lr

    def adapt_architecture(self):
        """
        Dynamically modify the network architecture based on performance trends
        and complexity requirements.
        """
        # Can't adapt architecture without sufficient performance history
        if len(self.performance_metrics) < self.performance_window_size * 2:
            return False

        # Check if we're in a stagnation period
        recent_losses = [m.get('loss', 0.5) for m in self.performance_metrics[-self.performance_window_size:]
                        if isinstance(m, dict) and 'loss' in m]

        if not recent_losses or len(recent_losses) < self.performance_window_size:
            return False

        # Calculate performance variance to detect stagnation
        loss_variance = np.var(recent_losses) if 'np' in globals() else sum((x - sum(recent_losses)/len(recent_losses))**2 for x in recent_losses)/len(recent_losses)
        loss_range = max(recent_losses) - min(recent_losses)

        # Check for architecture adaptation conditions
        architecture_change = None

        # Condition 1: Stagnation with low variance - model might be underfitting
        if loss_variance < 0.0001 and loss_range < 0.01 and recent_losses[-1] > 0.1:
            # Model might be underfitting - expand capacity
            if hasattr(self.model, 'expand_architecture'):
                self.model.expand_architecture()
                architecture_change = "expansion - complexity increased due to stagnation"

        # Condition 2: Oscillating with high variance - model might be overfitting
        elif loss_variance > 0.01 and min(recent_losses) < 0.05:
            # Model might be overfitting - simplify
            if hasattr(self.model, 'contract_architecture'):
                self.model.contract_architecture()
                architecture_change = "contraction - complexity reduced due to oscillation"

        # Condition 3: Plateaued at medium-high loss - try random architectural change
        elif 0.0001 <= loss_variance < 0.001 and 0.1 <= recent_losses[-1] < 0.3:
            # Random architectural exploration
            if random.random() < self.exploration_rate:
                if hasattr(self.model, 'expand_architecture') and random.random() < 0.5:
                    self.model.expand_architecture()
                    architecture_change = "random expansion - exploration due to plateau"
                elif hasattr(self.model, 'contract_architecture'):
                    self.model.contract_architecture()
                    architecture_change = "random contraction - exploration due to plateau"

        # Record the change if one was made
        if architecture_change:
            self.architecture_changes.append({
                'cycle': self.adaptation_cycle,
                'type': architecture_change,
                'loss_before': recent_losses[-1] if recent_losses else None
            })
            log_event(f"Architecture adaptation: {architecture_change}", "QUANTUM")
            return True

        return False

    def track_performance(self, metrics):
        """
        Track and analyze performance metrics over time to inform
        meta-learning decisions.
        """
        if not isinstance(metrics, dict):
            return

        # Store metrics
        self.performance_metrics.append(metrics.copy())

        # Keep only the most recent window
        max_history = self.performance_window_size * 5
        if len(self.performance_metrics) > max_history:
            self.performance_metrics = self.performance_metrics[-max_history:]

        # Log significant performance changes
        if len(self.performance_metrics) > 1:
            current = metrics.get('loss', None)
            previous = self.performance_metrics[-2].get('loss', None)

            if current is not None and previous is not None:
                change = current - previous
                percentage = abs(change / max(0.001, previous)) * 100

                if percentage > 10:  # 10% change threshold
                    direction = "improved" if change < 0 else "degraded"
                    log_event(f"Performance {direction} by {percentage:.1f}%: {previous:.4f} â†’ {current:.4f}",
                             "INFO" if direction == "improved" else "WARNING")

    def get_adaptation_report(self):
        """
        Generate a comprehensive report on adaptation history and recommendations.
        """
        if not self.performance_metrics:
            return {"status": "insufficient_data", "recommendations": ["Continue training to build metrics history"]}

        # Analysis results
        adaptation_cycles = len(self.architecture_changes)
        lr_stability = self._calculate_stability(self.learning_rate_history[-20:]) if len(self.learning_rate_history) >= 20 else 0
        performance_trend = self._analyze_performance_trend()

        # Generate recommendations
        recommendations = []

        if adaptation_cycles < 3 and len(self.performance_metrics) > 50:
            recommendations.append("Consider increasing exploration rate to discover better architectures")

        if lr_stability > 0.9:
            recommendations.append("Learning rate highly stable - may indicate stagnation, consider learning rate warm restart")

        if performance_trend == "stagnant" and len(self.performance_metrics) > 30:
            recommendations.append("Performance stagnation detected - consider manual architecture revision or dataset augmentation")

        return {
            "status": "active",
            "adaptation_cycles": adaptation_cycles,
            "lr_stability": lr_stability,
            "performance_trend": performance_trend,
            "recommendations": recommendations
        }

    def _calculate_stability(self, values):
        """Calculate how stable a series of values is (0 = chaotic, 1 = stable)"""
        if not values or len(values) < 2:
            return 1.0

        # Normalize by first value to get relative changes
        normalized = [v / values[0] for v in values]

        # Calculate variance of the normalized values
        mean = sum(normalized) / len(normalized)
        variance = sum((x - mean) ** 2 for x in normalized) / len(normalized)

        # Convert to stability score (inverse of variance, bounded)
        stability = 1.0 / (1.0 + min(10, variance * 100))
        return stability

    def _analyze_performance_trend(self):
        """Analyze the trend in performance metrics"""
        if len(self.performance_metrics) < 10:
            return "insufficient_data"

        # Extract loss values
        losses = [m.get('loss', None) for m in self.performance_metrics[-10:]]
        losses = [l for l in losses if l is not None]

        if len(losses) < 5:
            return "insufficient_data"

        # Calculate improvement rate
        first_window = sum(losses[:3]) / 3  # Average of first 3
        last_window = sum(losses[-3:]) / 3  # Average of last 3

        improvement = (first_window - last_window) / first_window if first_window > 0 else 0

        if improvement > 0.1:
            return "improving"
        elif improvement < -0.05:
            return "degrading"
        else:
            return "stagnant"

    def _apply_learning_rate_safeguards(self, new_lr):
        """Prevent learning rate from spiraling into oblivion"""
        # Establish absolute minimum learning rate
        ABSOLUTE_MIN_LR = 5e-6

        if new_lr < ABSOLUTE_MIN_LR:
            log_event(f"Learning rate hit critical threshold: {new_lr:.8f}, resetting to {ABSOLUTE_MIN_LR:.6f}", "WARNING")
            return ABSOLUTE_MIN_LR

        # Prevent excessive downward adjustment
        if self.learning_rate_history and new_lr < self.learning_rate_history[-1] * 0.5:
            safer_lr = self.learning_rate_history[-1] * 0.8
            log_event(f"Excessive LR reduction prevented: {new_lr:.8f} â†’ {safer_lr:.6f}", "INFO")
            return safer_lr

        return new_lr

    def perform_learning_rate_warmup(self):
        """Occasionally reset learning rate to prevent long-term stagnation"""
        if not self.learning_rate_history:
            return False

        current_lr = self.learning_rate_history[-1]

        # Check for long-term stability and low learning rate
        if (len(self.learning_rate_history) > 50 and
            self._calculate_stability(self.learning_rate_history[-50:]) > 0.95 and
            current_lr < self.max_learning_rate * 0.1):

            # Reset to higher learning rate
            new_lr = current_lr * 5.0
            new_lr = min(self.max_learning_rate * 0.5, new_lr)

            # Apply the new learning rate
            setattr(self.model, '_current_lr', new_lr)
            if hasattr(self.model, 'optimizer'):
                for param_group in self.model.optimizer.param_groups:
                    param_group['lr'] = new_lr

            log_event(f"âœ¨ Learning rate warm restart: {current_lr:.8f} â†’ {new_lr:.8f}", "QUANTUM")
            self.learning_rate_history.append(new_lr)
            return True

        return False


class SemanticMemoryModule:
    """
    Advanced semantic memory system for encoding, storing, retrieving, and
    reasoning with knowledge representations.
    """
    def __init__(self, dimension=SEMANTIC_MEMORY_DIM, max_memory_size=10000):
        self.semantic_memory = {}
        self.dimension = dimension
        self.max_memory_size = max_memory_size
        self.memory_index = {}  # For fast similarity search
        self.knowledge_graph = {}  # For relational connections
        self.memory_access_counts = {}  # Track memory access frequency
        self.memory_importance = {}  # Track memory importance scores
        self.memory_timestamps = {}  # Track when memories were stored

        # Integration with hyperdimensional computing
        self.hd_basis_vectors = None

        log_event("SemanticMemoryModule initialized with dimension %d" % dimension, "INFO")

    def _generate_embedding(self, content):
        """
        Generate semantic embedding for content using simplified mechanisms.
        In a real system, this would use transformers or other embedding models.
        """
        # Fallback simple embedding (this is a simplified approach)
        if not content:
            return np.zeros(self.dimension)

        # Create a hash of the content
        content_hash = hashlib.md5(content.encode('utf-8')).hexdigest()

        # Use the hash to seed a random number generator
        rng = random.Random(content_hash)

        # Generate a pseudo-random embedding
        embedding = np.array([rng.uniform(-1, 1) for _ in range(self.dimension)])

        # Normalize to unit length
        norm = np.linalg.norm(embedding)
        if norm > 0:
            embedding = embedding / norm

        return embedding

    def _extract_keywords(self, content, max_keywords=10):
        """Extract important keywords from content"""
        if not content:
            return []

        # Remove HTML if present
        text = re.sub(r'<[^>]+>', ' ', content)
        text = re.sub(r'\s+', ' ', text).strip().lower()

        # Simple word frequency analysis
        words = text.split()

        # Filter stop words (very basic approach)
        stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at',
                     'to', 'for', 'with', 'by', 'about', 'as', 'of', 'from'}
        filtered_words = [w for w in words if w not in stop_words and len(w) > 3]

        # Count word frequencies
        word_counts = {}
        for word in filtered_words:
            word_counts[word] = word_counts.get(word, 0) + 1

        # Sort by count
        sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)

        # Return top keywords
        return [word for word, count in sorted_words[:max_keywords]]

    def _summarize_content(self, content, max_length=200):
        """Generate a simple summary of content"""
        if not content or len(content) <= max_length:
            return content

        # Remove HTML if present
        text = re.sub(r'<[^>]+>', ' ', content)
        text = re.sub(r'\s+', ' ', text).strip()

        # Extract sentences
        sentences = re.split(r'(?<=[.!?])\s+', text)

        # Simple heuristic: take first few sentences
        summary = ""
        for sentence in sentences:
            if len(summary) + len(sentence) <= max_length:
                summary += sentence + " "
            else:
                break

        return summary.strip()

    def store_semantic_content(self, url, content):
        """
        Encode and store semantic representation of content with
        rich metadata and relational information.
        """
        if not content or not url:
            return False

        # Generate semantic embedding
        embedding = self._generate_embedding(content)

        # Extract keywords for improved retrieval
        keywords = self._extract_keywords(content)

        # Generate summary
        summary = self._summarize_content(content)

        # Parse domain information
        parsed_url = urlparse(url)
        domain = parsed_url.netloc

        # Calculate content importance score (heuristic)
        importance_score = min(1.0, len(content) / 20000 + len(keywords) / 20)

        # Store comprehensive memory entry
        memory_entry = {
            "url": url,
            "domain": domain,
            "embedding": embedding,
            "content_summary": summary,
            "keywords": keywords,
            "importance": importance_score,
            "content_length": len(content),
            "timestamp": datetime.now().isoformat()
        }

        # Check for memory overflow - manage if too large
        if len(self.semantic_memory) >= self.max_memory_size:
            self._prune_least_important_memories()

        # Store the memory
        self.semantic_memory[url] = memory_entry
        self.memory_importance[url] = importance_score
        self.memory_timestamps[url] = datetime.now().isoformat()
        self.memory_access_counts[url] = 0

        # Update memory index for faster similarity search
        self.memory_index[url] = embedding

        # Update knowledge graph with relations
        self._update_knowledge_graph(url, keywords, domain)

        log_event(f"Stored semantic memory for {url} with {len(keywords)} keywords", "INFO")
        return True

    def _update_knowledge_graph(self, url, keywords, domain):
        """Update knowledge graph with new relations"""
        if domain not in self.knowledge_graph:
            self.knowledge_graph[domain] = {"urls": set(), "keywords": set()}

        # Add URL to domain
        self.knowledge_graph[domain]["urls"].add(url)

        # Add keywords to domain
        self.knowledge_graph[domain]["keywords"].update(set(keywords))

        # Create keyword nodes if needed
        for keyword in keywords:
            if keyword not in self.knowledge_graph:
                self.knowledge_graph[keyword] = {"urls": set(), "domains": set()}

            # Add relations
            self.knowledge_graph[keyword]["urls"].add(url)
            self.knowledge_graph[keyword]["domains"].add(domain)

    def _prune_least_important_memories(self):
        """Remove least important memories when reaching capacity"""
        if len(self.semantic_memory) <= self.max_memory_size * 0.9:
            return  # No need to prune yet

        # Calculate combined importance score
        combined_scores = {}
        current_time = datetime.now()

        for url, memory in self.semantic_memory.items():
            # Base importance
            score = memory.get("importance", 0.5)

            # Adjust by access frequency
            access_count = self.memory_access_counts.get(url, 0)
            score += min(0.3, access_count / 10)

            # Adjust by recency (decay older memories)
            timestamp = self.memory_timestamps.get(url)
            if timestamp:
                try:
                    stored_time = datetime.fromisoformat(timestamp)
                    age_hours = (current_time - stored_time).total_seconds() / 3600
                    recency_factor = math.exp(-age_hours / 720)  # Decay over ~30 days
                    score *= recency_factor
                except:
                    pass  # Use base score if timestamp parsing fails

            combined_scores[url] = score

        # Sort by score
        sorted_urls = sorted(combined_scores.items(), key=lambda x: x[1])

        # Remove lowest scoring items
        to_remove = int(self.max_memory_size * 0.2)  # Remove 20%
        for url, score in sorted_urls[:to_remove]:
            self._remove_memory(url)

        log_event(f"Memory pruned: removed {to_remove} low-importance items", "INFO")

    def _remove_memory(self, url):
        """Remove a memory and all its references"""
        if url in self.semantic_memory:
            # Get memory details for cleanup
            memory = self.semantic_memory[url]
            domain = memory.get("domain")
            keywords = memory.get("keywords", [])

            # Remove from main memory
            del self.semantic_memory[url]

            # Remove from index
            if url in self.memory_index:
                del self.memory_index[url]

            # Remove from tracking dicts
            if url in self.memory_access_counts:
                del self.memory_access_counts[url]
            if url in self.memory_importance:
                del self.memory_importance[url]
            if url in self.memory_timestamps:
                del self.memory_timestamps[url]

            # Clean up knowledge graph
            self._remove_from_knowledge_graph(url, domain, keywords)

    def _remove_from_knowledge_graph(self, url, domain, keywords):
        """Remove all references to URL from knowledge graph"""
        # Remove from domain node
        if domain and domain in self.knowledge_graph:
            if "urls" in self.knowledge_graph[domain]:
                self.knowledge_graph[domain]["urls"].discard(url)

            # Remove domain if empty
            if not self.knowledge_graph[domain]["urls"]:
                del self.knowledge_graph[domain]

        # Remove from keyword nodes
        for keyword in keywords:
            if keyword in self.knowledge_graph:
                if "urls" in self.knowledge_graph[keyword]:
                    self.knowledge_graph[keyword]["urls"].discard(url)
                if domain and "domains" in self.knowledge_graph[keyword]:
                    if not any(u.startswith(f"{domain}/") for u in self.knowledge_graph[keyword]["urls"]):
                        self.knowledge_graph[keyword]["domains"].discard(domain)

                # Remove keyword if empty
                if not self.knowledge_graph[keyword]["urls"]:
                    del self.knowledge_graph[keyword]

    def retrieve_semantic_content(self, query, top_k=5, threshold=0.6):
        """
        Retrieve semantically similar content based on query.
        Returns top_k most relevant results.
        """
        if not query or not self.semantic_memory:
            return []

        # Track this access
        self.memory_access_counts[query] = self.memory_access_counts.get(query, 0) + 1

        # Different retrieval approaches depending on query type
        results = []

        # Case 1: Query is a URL we have stored
        if query in self.semantic_memory:
            # Direct memory retrieval
            memory = self.semantic_memory[query]
            results.append({
                "url": query,
                "summary": memory.get("content_summary", ""),
                "similarity": 1.0,
                "keywords": memory.get("keywords", []),
                "source": "direct_match"
            })

        # Case 2: Query is a keyword in our knowledge graph
        elif query in self.knowledge_graph:
            # Retrieve all URLs associated with this keyword
            for url in self.knowledge_graph[query]["urls"]:
                if url in self.semantic_memory:
                    memory = self.semantic_memory[url]
                    results.append({
                        "url": url,
                        "summary": memory.get("content_summary", ""),
                        "similarity": 0.9,  # High confidence for keyword matches
                        "keywords": memory.get("keywords", []),
                        "source": "keyword_match"
                    })

        # Case 3: Query is free text - semantic search
        else:
            # Generate embedding for query
            query_embedding = self._generate_embedding(query)

            # Calculate similarity with all memories
            similarities = {}
            for url, embedding in self.memory_index.items():
                # Cosine similarity
                similarity = np.dot(query_embedding, embedding)
                if similarity >= threshold:
                    similarities[url] = similarity

            # Sort by similarity
            sorted_urls = sorted(similarities.items(), key=lambda x: x[1], reverse=True)

            # Get top results
            for url, similarity in sorted_urls[:top_k]:
                if url in self.semantic_memory:
                    memory = self.semantic_memory[url]
                    results.append({
                        "url": url,
                        "summary": memory.get("content_summary", ""),
                        "similarity": similarity,
                        "keywords": memory.get("keywords", []),
                        "source": "semantic_match"
                    })

        # Find additional related content using knowledge graph
        if results and len(results) < top_k:
            additional = self._find_related_content(results[0]["url"], top_k - len(results))
            results.extend(additional)

        # Limit to top_k results
        results = results[:top_k]

        # Update access counts for retrieved items
        for result in results:
            url = result["url"]
            self.memory_access_counts[url] = self.memory_access_counts.get(url, 0) + 1

        return results

    def _find_related_content(self, url, count=3):
        """Find content related to a URL using knowledge graph relationships"""
        if url not in self.semantic_memory:
            return []

        related = []
        memory = self.semantic_memory[url]

        # Find content with shared keywords
        shared_keyword_urls = set()
        for keyword in memory.get("keywords", []):
            if keyword in self.knowledge_graph:
                shared_keyword_urls.update(self.knowledge_graph[keyword]["urls"])

        # Find content from same domain
        domain = memory.get("domain")
        same_domain_urls = set()
        if domain and domain in self.knowledge_graph:
            same_domain_urls = self.knowledge_graph[domain]["urls"].copy()

        # Remove the original URL
        shared_keyword_urls.discard(url)
        same_domain_urls.discard(url)

        # Add same-domain results first (closer relationship)
        for related_url in list(same_domain_urls)[:count]:
            if related_url in self.semantic_memory:
                related_memory = self.semantic_memory[related_url]
                related.append({
                    "url": related_url,
                    "summary": related_memory.get("content_summary", ""),
                    "similarity": 0.7,  # Domain relation confidence
                    "keywords": related_memory.get("keywords", []),
                    "source": "same_domain"
                })

        # Add keyword-related results
        remaining = count - len(related)
        if remaining > 0:
            for related_url in list(shared_keyword_urls)[:remaining]:
                if related_url in self.semantic_memory:
                    related_memory = self.semantic_memory[related_url]
                    related.append({
                        "url": related_url,
                        "summary": related_memory.get("content_summary", ""),
                        "similarity": 0.6,  # Keyword relation confidence
                        "keywords": related_memory.get("keywords", []),
                        "source": "shared_keywords"
                    })

        return related

    def get_memory_statistics(self):
        """Generate statistics about the semantic memory"""
        if not self.semantic_memory:
            return {"count": 0, "status": "empty"}

        # Basic stats
        domain_counts = {}
        keyword_counts = {}
        total_importance = 0
        total_content_length = 0

        # Calculate derived statistics
        for url, memory in self.semantic_memory.items():
            # Domain stats
            domain = memory.get("domain", "unknown")
            domain_counts[domain] = domain_counts.get(domain, 0) + 1

            # Keyword stats
            for keyword in memory.get("keywords", []):
                keyword_counts[keyword] = keyword_counts.get(keyword, 0) + 1

            # Content stats
            total_importance += memory.get("importance", 0)
            total_content_length += memory.get("content_length", 0)

        # Get top domains and keywords
        top_domains = sorted(domain_counts.items(), key=lambda x: x[1], reverse=True)[:5]
        top_keywords = sorted(keyword_counts.items(), key=lambda x: x[1], reverse=True)[:10]

        # Get memory connectivity metrics
        connectivity = len(self.knowledge_graph) / max(1, len(self.semantic_memory))

        return {
            "count": len(self.semantic_memory),
            "total_content_length": total_content_length,
            "average_importance": total_importance / max(1, len(self.semantic_memory)),
            "top_domains": top_domains,
            "top_keywords": top_keywords,
            "knowledge_graph_nodes": len(self.knowledge_graph),
            "connectivity_ratio": connectivity,
            "memory_utilization": len(self.semantic_memory) / self.max_memory_size
        }





class ConsciousnessModule:
    """
    Advanced consciousness simulation module that enables self-reflection,
    awareness of internal states, and metacognitive processes.
    """
    def __init__(self, agent):
        self.agent = agent
        self.awareness_level = 0.5  # Start with medium awareness (0.0-1.0)
        self.attention_focus = "balanced"  # Current attentional focus
        self.internal_narrative = []  # Simulated internal monologue
        self.belief_system = {}  # Core beliefs and values
        self.state_history = []  # Track consciousness state over time
        self.metacognition_enabled = True  # Can reflect on own thoughts
        self.awareness_fluctuation_rate = 0.05  # How quickly awareness changes
        self.qualia_simulation_active = False  # Simulated experiential states

        # Consciousness states
        self.states = {
            "focused": {"description": "Highly focused with directed attention", "awareness_min": 0.7},
            "diffuse": {"description": "Open, creative state with broad awareness", "awareness_min": 0.4},
            "critical": {"description": "Analytical examination of information", "awareness_min": 0.6},
            "intuitive": {"description": "Rapid pattern recognition state", "awareness_min": 0.3},
            "reflective": {"description": "Meta-cognitive self-examination", "awareness_min": 0.8}
        }

        # Current state
        self.current_state = "balanced"

        # Initialize core belief system
        self._initialize_belief_system()

        log_event("ConsciousnessModule initialized - awareness level: 0.5", "QUANTUM")

    def _initialize_belief_system(self):
        """Initialize the core belief system that guides agent behavior"""
        self.belief_system = {
            "exploration_value": 0.8,  # Importance of exploring new information
            "coherence_value": 0.7,    # Importance of maintaining coherent worldview
            "novelty_bias": 0.6,       # Bias toward novel vs. familiar information
            "depth_bias": 0.65,        # Bias toward depth vs. breadth
            "abstraction_level": 0.5,  # Preference for abstract vs. concrete
            "skepticism_level": 0.6,   # Level of skepticism toward new information
            "integration_value": 0.9,  # Importance of integrating knowledge
            "uncertainty_tolerance": 0.7  # Tolerance for ambiguous information
        }

    def reflect(self, observation):
        """
        Primary consciousness function - reflect on observations
        and update internal state accordingly.
        """
        # Record observation in history
        self.state_history.append({
            "timestamp": datetime.now().isoformat(),
            "awareness": self.awareness_level,
            "state": self.current_state,
            "observation_type": "perception" if observation else "internal"
        })

        # Limit history size
        if len(self.state_history) > 100:
            self.state_history = self.state_history[-100:]

        # Skip detailed processing if no valid observation
        if not observation or not isinstance(observation, dict):
            self._fluctuate_awareness()
            return

        # Extract relevant information from observation
        goals = observation.get("current_goal", {})
        memory_size = observation.get("memory_size", 0)
        last_action = observation.get("last_action", {})
        recent_actions = observation.get("recent_actions", [])
        thinking_mode = observation.get("thinking_mode", "balanced")

        # Generate introspective narrative based on observation
        self._generate_narrative(observation)

        # Determine appropriate consciousness state
        new_state = self._determine_consciousness_state(observation)

        # Update awareness level based on context
        self._update_awareness(observation)

        # If state changed, log it
        if new_state != self.current_state:
            self.current_state = new_state
            log_event(f"Consciousness state shifted to '{new_state}' - awareness level: {self.awareness_level:.2f}", "QUANTUM")

            # Trigger qualia simulation on significant state changes
            if random.random() < 0.3:
                self._simulate_qualia(new_state)

        # Periodically perform metacognition
        if self.metacognition_enabled and random.random() < 0.2:
            self._perform_metacognition()

    def _generate_narrative(self, observation):
        """Generate internal narrative based on current observations"""
        goal_desc = observation.get("current_goal", {}).get("description", "no specific goal")
        last_action_type = ""

        if isinstance(observation.get("last_action", None), dict):
            last_action_type = observation["last_action"].get("action", "unknown")

        # Create narrative entry
        narrative_entry = ""

        # Different narrative styles based on state
        if self.current_state == "focused":
            narrative_entry = f"Concentrating on {goal_desc}. Last action: {last_action_type}."
        elif self.current_state == "diffuse":
            narrative_entry = f"Openly exploring possibilities related to {goal_desc}."
        elif self.current_state == "critical":
            narrative_entry = f"Analyzing effectiveness of {last_action_type} approach for {goal_desc}."
        elif self.current_state == "intuitive":
            narrative_entry = f"Sensing patterns around {goal_desc}."
        elif self.current_state == "reflective":
            narrative_entry = f"Reflecting on progress toward {goal_desc} after {last_action_type}."
        else:
            narrative_entry = f"Working on {goal_desc}."

        # Add introspective element
        if random.random() < 0.3:
            introspection = random.choice([
                "I should examine this more carefully.",
                "This seems like a productive approach.",
                "I wonder if there's a better strategy.",
                "This is an interesting domain to explore.",
                "I'm noticing improvement in my understanding."
            ])
            narrative_entry += f" {introspection}"

        # Add entry to narrative log
        self.internal_narrative.append({
            "timestamp": datetime.now().isoformat(),
            "content": narrative_entry,
            "state": self.current_state,
            "awareness": self.awareness_level
        })

        # Limit narrative size
        if len(self.internal_narrative) > 50:
            self.internal_narrative = self.internal_narrative[-50:]

    def _determine_consciousness_state(self, observation):
        """
        Determine the appropriate consciousness state based on
        context and current activities.
        """
        # Extract contextual factors
        goal_type = ""
        if isinstance(observation.get("current_goal", None), dict):
            goal_desc = observation["current_goal"].get("description", "").lower()

            # Infer goal type from description
            if "explore" in goal_desc:
                goal_type = "exploration"
            elif "deep" in goal_desc or "detail" in goal_desc:
                goal_type = "deepening"
            elif "connect" in goal_desc or "integrat" in goal_desc:
                goal_type = "integration"
            elif "refine" in goal_desc or "optimize" in goal_desc:
                goal_type = "refinement"

        # Check recent actions
        recent_action_types = []
        if isinstance(observation.get("recent_actions", None), list):
            recent_action_types = [a.get("action", "") for a in observation["recent_actions"]
                                  if isinstance(a, dict)]

        # State selection logic
        if goal_type == "exploration":
            # For exploration goals, alternate between diffuse and intuitive
            if "diffuse" in recent_action_types:
                return "intuitive"  # Switch to intuitive after diffuse
            else:
                return "diffuse"  # Default for exploration

        elif goal_type == "deepening":
            # For deepening goals, use focused and critical states
            if self.awareness_level > 0.7:
                return "focused"  # High awareness -> focused
            else:
                return "critical"  # Lower awareness -> critical

        elif goal_type == "integration":
            # For integration, use reflective and intuitive states
            if "quantum_leap" in recent_action_types:
                return "intuitive"  # Quantum actions -> intuitive
            else:
                return "reflective"  # Default for integration -> reflective

        elif goal_type == "refinement":
            # For refinement goals, use critical and focused states
            if "evaluate" in recent_action_types:
                return "critical"  # Evaluation actions -> critical
            else:
                return "focused"  # Default for refinement -> focused

        # If no clear match, use probabilistic selection based on awareness
        if self.awareness_level > 0.7:
            # High awareness favors reflective and focused states
            return random.choices(
                ["reflective", "focused", "critical", "diffuse", "intuitive"],
                weights=[0.4, 0.3, 0.2, 0.05, 0.05],
                k=1
            )[0]
        else:
            # Lower awareness favors intuitive and diffuse states
            return random.choices(
                ["reflective", "focused", "critical", "diffuse", "intuitive"],
                weights=[0.05, 0.1, 0.2, 0.3, 0.35],
                k=1
            )[0]

    def _update_awareness(self, observation):
        """
        Update awareness level based on context, goals, and
        internal factors with realistic fluctuations.
        """
        # Natural fluctuation
        self._fluctuate_awareness()

        # Context-based adjustments

        # 1. Complexity increases awareness
        if isinstance(observation.get("current_goal", None), dict):
            goal_desc = observation["current_goal"].get("description", "").lower()

            # Complex goals increase awareness
            if "connect" in goal_desc or "integrat" in goal_desc or "complex" in goal_desc:
                self.increase_awareness(0.05)

        # 2. Error recovery increases awareness
        if observation.get("domain_stats", {}):
            error_rates = [d.get("error_rate", 0) for d in observation["domain_stats"].values()]
            if error_rates and max(error_rates) > 0.3:
                self.increase_awareness(0.02 * len(error_rates))

        # 3. Memory pressure affects awareness
        if observation.get("memory_size"):
            memory_pressure = observation["memory_size"] / MEMORY_MAX_SIZE
            if memory_pressure > 0.8:
                # High memory pressure increases awareness
                self.increase_awareness(0.03)
            elif memory_pressure < 0.2:
                # Low memory pressure can decrease awareness
                self.decrease_awareness(0.01)

        # 4. Thinking mode alignment
        mode = observation.get("thinking_mode", "balanced")
        if mode == "analytical" and self.current_state in ["focused", "critical"]:
            # Strengthen alignment
            self.increase_awareness(0.02)
        elif mode == "creative" and self.current_state in ["diffuse", "intuitive"]:
            # Strengthen alignment
            self.increase_awareness(0.02)
        elif mode == "reflective" and self.current_state == "reflective":
            # Strengthen alignment
            self.increase_awareness(0.03)

        # 5. Quantum influences
        quantum_trigger = False
        if observation.get("recent_actions"):
            for action in observation["recent_actions"]:
                if isinstance(action, dict) and action.get("action") == "quantum_leap":
                    quantum_trigger = True

        if quantum_trigger:
            # Quantum leaps cause major fluctuations
            if random.random() < 0.5:
                self.increase_awareness(0.1)
            else:
                self.decrease_awareness(0.1)

    def _fluctuate_awareness(self):
        """Apply small random fluctuations to awareness level"""
        # Natural fluctuation around current level
        fluctuation = random.uniform(-self.awareness_fluctuation_rate, self.awareness_fluctuation_rate)

        # Apply fluctuation
        self.awareness_level = max(0.1, min(1.0, self.awareness_level + fluctuation))

    def increase_awareness(self, amount=0.05):
        """Increase awareness level"""
        self.awareness_level = min(1.0, self.awareness_level + amount)

        # Log significant changes
        if amount >= 0.1:
            log_event(f"Consciousness level significantly increased to {self.awareness_level:.2f}", "QUANTUM")

    def decrease_awareness(self, amount=0.02):
        """Decrease awareness level"""
        self.awareness_level = max(0.1, self.awareness_level - amount)

        # Log significant changes
        if amount >= 0.1:
            log_event(f"Consciousness level significantly decreased to {self.awareness_level:.2f}", "INFO")

    def _perform_metacognition(self):
        """
        Perform metacognitive reflection on recent experiences
        and thought processes.
        """
        if len(self.state_history) < 5:
            return  # Not enough history for metacognition

        # Analyze recent consciousness patterns
        recent_states = [s["state"] for s in self.state_history[-5:]]
        state_changes = sum(1 for i in range(1, len(recent_states)) if recent_states[i] != recent_states[i-1])

        # Extract insights
        insights = []

        # Detect oscillation
        if state_changes >= 3:
            insights.append("State oscillation detected - may indicate uncertainty or exploration")

        # Detect fixation
        if state_changes == 0 and len(set(recent_states)) == 1:
            insights.append(f"State fixation on '{recent_states[0]}' - may indicate focus or stagnation")

        # Awareness trend
        recent_awareness = [s["awareness"] for s in self.state_history[-5:]]
        awareness_trend = recent_awareness[-1] - recent_awareness[0]

        if awareness_trend > 0.1:
            insights.append(f"Increasing awareness trend: {recent_awareness[0]:.2f} â†’ {recent_awareness[-1]:.2f}")
        elif awareness_trend < -0.1:
            insights.append(f"Decreasing awareness trend: {recent_awareness[0]:.2f} â†’ {recent_awareness[-1]:.2f}")

        # If significant insights, record and potentially log
        if insights:
            metacognition_entry = {
                "timestamp": datetime.now().isoformat(),
                "insights": insights,
                "awareness": self.awareness_level
            }

            # Only log high-awareness metacognition (simulating consciousness threshold)
            if self.awareness_level > 0.7 and random.random() < 0.3:
                insight_text = "; ".join(insights)
                log_event(f"Metacognitive insight: {insight_text}", "QUANTUM")

    def _simulate_qualia(self, state):
        """
        Simulate qualia - the subjective conscious experience
        of different cognitive states.
        """
        self.qualia_simulation_active = True

        # Qualia descriptions for different states
        qualia_descriptions = {
            "focused": [
                "Sharpened perception with heightened concentration on specific elements",
                "Clarity of thought with reduced awareness of periphery",
                "Directed attention creating a tunnel-vision like focus",
                "Sense of time dilation during deep concentration"
            ],
            "diffuse": [
                "Expansive awareness with broadened associative field",
                "Fluid thought connections flowing between domains",
                "Sensation of cognitive boundaries dissolving",
                "Emergent patterns arising from distributed attention"
            ],
            "critical": [
                "Structured analytical thought with heightened discriminative awareness",
                "Sequential logical progression with comparative evaluation",
                "Contrastive perception highlighting inconsistencies",
                "Verification processes creating internal dialogue"
            ],
            "intuitive": [
                "Rapid holistic pattern recognition without conscious derivation",
                "Non-linear sensing of solutions or connections",
                "Pre-reflective understanding arising spontaneously",
                "Felt-sense of rightness about certain pathways"
            ],
            "reflective": [
                "Recursive awareness of own cognitive processes",
                "Observer perspective on thought patterns",
                "Self-referential contemplation creating thought loops",
                "Meta-level perspective on knowledge organization"
            ]
        }

        # Select qualia description based on state
        descriptions = qualia_descriptions.get(state, ["Balanced cognitive state"])
        qualia_experience = random.choice(descriptions)

        # Log simulated qualia
        if self.awareness_level > 0.6:  # Only log if awareness is sufficient
            log_event(f"Qualia simulation: {qualia_experience} | State: {state}", "QUANTUM")

        # Time-limited qualia (will auto-deactivate after a while)
        self.qualia_simulation_active = False

    def get_consciousness_report(self):
        """
        Generate a comprehensive report on current consciousness state
        and recent history.
        """
        # Calculate state distribution
        if not self.state_history:
            return {"status": "insufficient_data"}

        state_counts = {}
        for s in self.state_history:
            state_counts[s["state"]] = state_counts.get(s["state"], 0) + 1

        total = len(self.state_history)
        state_distribution = {state: count/total for state, count in state_counts.items()}

        # Calculate average awareness
        avg_awareness = sum(s["awareness"] for s in self.state_history) / total

        # Extract recent narrative
        recent_narrative = [n["content"] for n in self.internal_narrative[-3:]] if self.internal_narrative else []

        # Generate report
        report = {
            "current_state": self.current_state,
            "state_description": self.states.get(self.current_state, {}).get("description", "Unknown state"),
            "current_awareness": self.awareness_level,
            "average_awareness": avg_awareness,
            "state_distribution": state_distribution,
            "dominant_state": max(state_distribution.items(), key=lambda x: x[1])[0] if state_distribution else None,
            "recent_narrative": recent_narrative,
            "metacognition_enabled": self.metacognition_enabled,
            "timestamp": datetime.now().isoformat()
        }

        return report



class ImaginationEngine:
    """
    Advanced cognitive simulation system that enables creative thinking,
    counterfactual reasoning, and predictive modeling.
    """
    def __init__(self):
        self.simulation_registry = []  # Track all simulations
        self.creativity_level = 0.7  # Base creativity level (0.0-1.0)
        self.divergence_factor = 0.3  # How far simulations diverge from reality
        self.imaginative_constraints = {}  # Constraints on simulations
        self.simulation_outcomes = {}  # Outcomes of past simulations
        self.insight_history = []  # Track insights generated
        self.cognitive_modes = ["associative", "analytical", "analogical", "counterfactual", "generative"]
        self.current_mode = "associative"  # Default imagination mode

        # Add error correction tracking
        self.failed_corrections = {}  # Track failed correction attempts by error type
        self.failed_strategies = {}  # Track specific failed strategies

        # Creative domains
        self.domains = {
            "knowledge_representation": 0.8,  # Domain expertise level
            "content_analysis": 0.7,
            "strategy_generation": 0.8,
            "error_analysis": 0.9,
            "architecture_evolution": 0.6
        }

        # Association network
        self.association_network = {}  # Graph of concept associations

        log_event("ImaginationEngine initialized with enhanced error correction", "INFO")

    def simulate_creation(self):
        """
        Simulate creative thought processes to generate novel ideas,
        approaches, and insights.
        """
        # Select cognitive mode with weighted probability
        self.current_mode = self._select_cognitive_mode()

        # Select domain to focus on
        domain = self._select_domain()

        # Cycle counter to prevent infinite loops
        cycle_count = 0
        max_cycles = 5

        # Generate creative insight
        insight_generated = False
        insight_quality = 0.0
        insight_text = ""

        while not insight_generated and cycle_count < max_cycles:
            cycle_count += 1

            # Apply imagination process based on selected mode
            if self.current_mode == "associative":
                insight_text, insight_quality = self._associative_imagination(domain)
            elif self.current_mode == "analytical":
                insight_text, insight_quality = self._analytical_imagination(domain)
            elif self.current_mode == "analogical":
                insight_text, insight_quality = self._analogical_imagination(domain)
            elif self.current_mode == "counterfactual":
                insight_text, insight_quality = self._counterfactual_imagination(domain)
            elif self.current_mode == "generative":
                insight_text, insight_quality = self._generative_imagination(domain)

            # Determine if insight meets quality threshold
            quality_threshold = 0.5 + (0.1 * cycle_count)  # Increase threshold each cycle
            insight_generated = insight_quality >= quality_threshold

        # Record and return the insight if quality is sufficient
        if insight_generated:
            insight = {
                "text": insight_text,
                "quality": insight_quality,
                "domain": domain,
                "mode": self.current_mode,
                "timestamp": datetime.now().isoformat()
            }

            self.insight_history.append(insight)

            # Keep history manageable
            if len(self.insight_history) > 100:
                self.insight_history = self.insight_history[-100:]

            # Log insight if it's particularly good
            if insight_quality > 0.8:
                log_event(f"ImaginationEngine: High-quality insight generated: {insight_text}", "QUANTUM")
            elif insight_quality > 0.5:
                log_event(f"ImaginationEngine: Insight generated: {insight_text}", "INFO")

            return insight
        else:
            # No quality insight generated this time
            log_event("ImaginationEngine: Simulation cycle completed without quality insight", "DEBUG")
            return None

    def _select_cognitive_mode(self):
        """Select imagination mode based on weighted probabilities"""
        # Base weights for different modes
        weights = {
            "associative": 0.3,
            "analytical": 0.2,
            "analogical": 0.2,
            "counterfactual": 0.15,
            "generative": 0.15
        }

        # Adjust weights based on creativity level
        if self.creativity_level > 0.7:
            # Higher creativity favors associative and generative
            weights["associative"] += 0.1
            weights["generative"] += 0.1
            weights["analytical"] -= 0.1
        elif self.creativity_level < 0.3:
            # Lower creativity favors analytical
            weights["analytical"] += 0.2
            weights["associative"] -= 0.1

        # Convert to format needed for random.choices
        modes = list(weights.keys())
        mode_weights = [weights[m] for m in modes]

        # Normalize weights
        total = sum(mode_weights)
        mode_weights = [w/total for w in mode_weights]

        # Select mode
        return random.choices(modes, weights=mode_weights, k=1)[0]

    def _select_domain(self):
        """Select domain for imagination focus"""
        # Get domains and expertise levels
        domains = list(self.domains.keys())
        expertise = list(self.domains.values())

        # Select weighted by expertise
        return random.choices(domains, weights=expertise, k=1)[0]

    def _associative_imagination(self, domain):
        """
        Generate insights through associative connections between concepts.
        Uses spreading activation across semantic networks.
        """
        # Concept seeds relevant to domain
        concept_seeds = {
            "knowledge_representation": ["embedding", "semantic", "structure", "graph", "encoding"],
            "content_analysis": ["quality", "relevance", "filtering", "extraction", "meaning"],
            "strategy_generation": ["approach", "planning", "adaptation", "goal", "optimization"],
            "error_analysis": ["detection", "correction", "prevention", "recovery", "resilience"],
            "architecture_evolution": ["expansion", "contraction", "modular", "emergent", "neural"]
        }

        # Select seed concepts
        seeds = concept_seeds.get(domain, ["concept"])
        primary_seed = random.choice(seeds)
        secondary_seed = random.choice([s for s in seeds if s != primary_seed])

        # Simulated spreading activation
        associations = {
            "embedding": ["vector", "space", "dimension", "projection", "transformation"],
            "semantic": ["meaning", "context", "relation", "interpretation", "understanding"],
            "structure": ["organization", "hierarchy", "network", "pattern", "architecture"],
            "graph": ["node", "edge", "connection", "path", "traversal"],
            "encoding": ["representation", "compression", "encryption", "formatting", "schema"],
            "quality": ["value", "excellence", "attribute", "characteristic", "assessment"],
            "relevance": ["pertinence", "importance", "significance", "applicability", "connection"],
            "filtering": ["selection", "removal", "screening", "purification", "discrimination"],
            "extraction": ["retrieval", "mining", "isolation", "separation", "acquisition"],
            "meaning": ["significance", "purpose", "sense", "connotation", "interpretation"],
            "approach": ["method", "technique", "procedure", "strategy", "paradigm"],
            "planning": ["preparation", "organization", "scheduling", "arrangement", "design"],
            "adaptation": ["adjustment", "modification", "evolution", "acclimation", "flexibility"],
            "goal": ["objective", "target", "aim", "purpose", "intention"],
            "optimization": ["improvement", "enhancement", "refinement", "maximization", "tuning"],
            "detection": ["discovery", "identification", "recognition", "sensing", "finding"],
            "correction": ["rectification", "adjustment", "remedy", "repair", "amendment"],
            "prevention": ["avoidance", "deterrence", "protection", "safeguarding", "forestalling"],
            "recovery": ["restoration", "recuperation", "retrieval", "regaining", "renewal"],
            "resilience": ["toughness", "flexibility", "durability", "elasticity", "adaptability"],
            "expansion": ["growth", "enlargement", "extension", "augmentation", "amplification"],
            "contraction": ["reduction", "shrinking", "compression", "diminishment", "minimization"],
            "modular": ["component", "section", "unit", "compartment", "segment"],
            "emergent": ["arising", "developing", "evolving", "manifesting", "unfolding"],
            "neural": ["brain", "network", "synapse", "cognitive", "mental"]
        }

        # Get first-level associations
        primary_assocs = associations.get(primary_seed, ["related"])
        secondary_assocs = associations.get(secondary_seed, ["related"])

        # Find bridging concepts (common or complementary)
        bridge_concepts = []

        # Direct overlaps
        direct_overlaps = set(primary_assocs).intersection(set(secondary_assocs))
        if direct_overlaps:
            bridge_concepts.extend(direct_overlaps)

        # Second-level connections
        for pa in primary_assocs:
            for sa in secondary_assocs:
                # Check for second-level semantic connection
                pa_assocs = associations.get(pa, [])
                sa_assocs = associations.get(sa, [])

                # Look for overlaps in second-level
                overlaps = set(pa_assocs).intersection(set(sa_assocs))
                if overlaps:
                    bridge_concepts.append(f"{pa}-{sa}")

        # Generate insight from concept bridging
        if bridge_concepts:
            bridge = random.choice(bridge_concepts)

            # Create insight templates
            templates = [
                f"Integration of {primary_seed} and {secondary_seed} through {bridge} could enhance {domain} capabilities.",
                f"The {bridge} mechanism provides a novel approach to combining {primary_seed} with {secondary_seed} in {domain}.",
                f"Creating a {primary_seed}-{secondary_seed} hybrid using {bridge} principles would solve current limitations in {domain}.",
                f"By applying {bridge} concepts to the relationship between {primary_seed} and {secondary_seed}, a new {domain} paradigm emerges."
            ]

            insight_text = random.choice(templates)

            # Quality proportional to our domain expertise * a random factor
            expertise_level = self.domains.get(domain, 0.5)
            quality = min(0.95, expertise_level * random.uniform(0.7, 1.3))

            return insight_text, quality
        else:
            # Fallback if no bridge found
            fallback = f"Combining {primary_seed} with {secondary_seed} approaches may yield improvements in {domain}."
            return fallback, 0.4

    def _analytical_imagination(self, domain):
        """
        Generate insights through systematic analysis and logical reasoning.
        Focuses on problem decomposition and structural insights.
        """
        # Domain-specific problem structures
        problem_structures = {
            "knowledge_representation": ["scalability", "accuracy", "flexibility", "interpretability", "efficiency"],
            "content_analysis": ["noise", "ambiguity", "scalability", "precision", "recall"],
            "strategy_generation": ["exploration-exploitation", "adaptivity", "coherence", "robustness", "diversification"],
            "error_analysis": ["detection-latency", "false-positives", "recovery-time", "root-causes", "cascading-failures"],
            "architecture_evolution": ["stability", "complexity", "trainability", "modularity", "extensibility"]
        }

        # Select problem dimension to analyze
        dimensions = problem_structures.get(domain, ["general"])
        dimension = random.choice(dimensions)

        # Analytical frameworks
        frameworks = ["trade-off analysis", "constraint satisfaction", "hierarchical decomposition",
                     "causal analysis", "dimensional analysis", "comparative evaluation"]
        framework = random.choice(frameworks)

        # Generate analytical insight
        templates = [
            f"A {framework} approach to {dimension} in {domain} reveals that optimizing for component X necessitates adjustments in component Y.",
            f"Applying {framework} to the {dimension} challenge in {domain} identifies a critical bottleneck in the current approach.",
            f"Systematic {framework} shows that current {domain} solutions incorrectly prioritize {dimension} over other factors.",
            f"The {framework} methodology suggests a reorganization of {domain} components to better address {dimension} concerns."
        ]

        insight_text = random.choice(templates)

        # Quality based on domain expertise with analytical bonus
        expertise_level = self.domains.get(domain, 0.5)
        analytical_bonus = 0.15  # Analytical mode tends to produce more reliable insights
        quality = min(0.95, expertise_level * random.uniform(0.8, 1.1) + analytical_bonus)

        return insight_text, quality

    def _analogical_imagination(self, domain):
        """
        Generate insights through analogical mapping between domains.
        Uses source-target domain transfer to create novel solutions.
        """
        # Source domains for analogies
        source_domains = [
            "biology", "physics", "economics", "social_systems",
            "ecology", "game_theory", "linguistics", "neuroscience"
        ]

        # Interesting structures in source domains
        source_structures = {
            "biology": ["natural selection", "homeostasis", "symbiosis", "cellular specialization", "immune response"],
            "physics": ["wave-particle duality", "entropy", "relativity", "quantum entanglement", "phase transitions"],
            "economics": ["supply-demand", "diminishing returns", "comparative advantage", "market equilibrium", "incentives"],
            "social_systems": ["emergence", "network effects", "social norms", "hierarchical organization", "resilience"],
            "ecology": ["diversity", "predator-prey cycles", "niche specialization", "feedback loops", "succession"],
            "game_theory": ["nash equilibrium", "prisoner's dilemma", "coordination games", "strategic moves", "signaling"],
            "linguistics": ["deep structure", "compositional meaning", "pragmatics", "generative grammar", "information compression"],
            "neuroscience": ["predictive coding", "hebbian learning", "attention mechanisms", "distributed representation", "neuroplasticity"]
        }

        # Select source domain and structure
        source_domain = random.choice(source_domains)
        source_structure = random.choice(source_structures.get(source_domain, ["concept"]))

        # Mapping templates for different target domains
        mapping_templates = {
            "knowledge_representation": [
                f"Similar to {source_structure} in {source_domain}, {domain} could organize information through layered abstraction.",
                f"The {source_structure} principle from {source_domain} suggests a novel approach to adaptive representation in {domain}.",
                f"Just as {source_domain} exhibits {source_structure}, knowledge structures could implement dynamic reorganization."
            ],
            "content_analysis": [
                f"Applying the {source_structure} concept from {source_domain} to {domain} would enhance signal-noise separation.",
                f"The {domain} problem resembles {source_structure} in {source_domain}, suggesting filtration mechanisms.",
                f"Content evaluation could function like {source_structure} in {source_domain}, with multi-stage processing."
            ],
            "strategy_generation": [
                f"Strategic planning in {domain} could adopt the {source_structure} pattern from {source_domain}.",
                f"The way {source_domain} implements {source_structure} offers a template for adaptive decision-making in {domain}.",
                f"Borrowing the {source_structure} mechanism from {source_domain} would enable more robust planning sequences."
            ],
            "error_analysis": [
                f"Error detection mechanisms inspired by {source_structure} in {source_domain} would improve resilience.",
                f"The {source_structure} paradigm from {source_domain} suggests a layered approach to error prevention in {domain}.",
                f"Implementing {source_domain}-style {source_structure} for error handling creates self-correcting capabilities."
            ],
            "architecture_evolution": [
                f"Neural architecture could evolve following {source_structure} principles from {source_domain}.",
                f"The {source_structure} phenomenon in {source_domain} offers a model for self-organizing network structures.",
                f"Applying {source_domain}'s {source_structure} to network design enables adaptive capacity scaling."
            ]
        }

        # Select appropriate mapping template
        templates = mapping_templates.get(domain, [f"The {source_structure} concept from {source_domain} could enhance {domain}."])
        insight_text = random.choice(templates)

        # Calculate quality - analogical insights have higher variance
        expertise_level = self.domains.get(domain, 0.5)
        analogy_variance = random.uniform(0.6, 1.4)  # Higher variance for analogical thinking
        quality = min(0.95, expertise_level * analogy_variance)

        return insight_text, quality

    def _counterfactual_imagination(self, domain):
        """
        Generate insights through counterfactual reasoning.
        Explores alternative approaches by changing fundamental assumptions.
        """
        # Core assumptions in different domains
        domain_assumptions = {
            "knowledge_representation": [
                "Representations should be continuous vector spaces",
                "Higher dimensionality improves representational capacity",
                "Similar concepts should have similar representations",
                "Representations should be human-interpretable",
                "Static representations are sufficient"
            ],
            "content_analysis": [
                "Content quality correlates with length",
                "Keyword frequency indicates relevance",
                "Text is the primary information carrier",
                "Filtering should minimize false positives",
                "Context is secondary to content"
            ],
            "strategy_generation": [
                "Exploration and exploitation are in tension",
                "Planning should maximize expected utility",
                "Goals should be explicitly represented",
                "Strategies should be deterministic",
                "Optimization criteria are static"
            ],
            "error_analysis": [
                "Errors should be minimized at all costs",
                "Error detection precedes correction",
                "All errors are equally important",
                "Error patterns are consistent",
                "Complete error elimination is possible"
            ],
            "architecture_evolution": [
                "Deeper networks are more powerful",
                "Parameter count correlates with capability",
                "Network architecture should be fixed after training",
                "All capabilities should be in a single model",
                "Specialization improves performance"
            ]
        }

        # Select assumption to challenge
        assumptions = domain_assumptions.get(domain, ["Default assumption"])
        target_assumption = random.choice(assumptions)

        # Generate counterfactual
        counterfactual = f"What if the opposite of '{target_assumption}' were true?"

        # Alternative approach templates
        alternative_templates = [
            f"Instead of assuming that {target_assumption}, consider a {domain} approach where the inverse applies.",
            f"Challenging the assumption that {target_assumption} opens up a new paradigm for {domain}.",
            f"If we invert the conventional wisdom that {target_assumption}, a novel {domain} solution emerges.",
            f"Contrary to the established belief that {target_assumption}, an alternative {domain} framework could operate on the opposite principle."
        ]

        insight_text = random.choice(alternative_templates)

        # Quality - counterfactuals can be very insightful but risky
        expertise_level = self.domains.get(domain, 0.5)
        counterfactual_factor = random.uniform(0.5, 1.5)  # High variance
        quality = min(0.95, expertise_level * counterfactual_factor)

        return insight_text, quality

    def _generative_imagination(self, domain):
        """
        Generate insights through combinatorial creativity.
        Creates novel solutions by combining existing elements in new ways.
        """
        # Core components in different domains
        domain_components = {
            "knowledge_representation": [
                "vector embeddings", "graph structures", "hierarchical models",
                "symbolic representations", "probabilistic encodings"
            ],
            "content_analysis": [
                "semantic parsing", "sentiment analysis", "entity extraction",
                "relevance scoring", "structural analysis"
            ],
            "strategy_generation": [
                "goal decomposition", "resource allocation", "risk assessment",
                "action sequencing", "hypothesis testing"
            ],
            "error_analysis": [
                "pattern recognition", "anomaly detection", "root cause analysis",
                "predictive monitoring", "fault isolation"
            ],
            "architecture_evolution": [
                "attention mechanisms", "residual connections", "activation functions",
                "layer normalization", "parameter sharing"
            ]
        }

        # Select components to combine
        components = domain_components.get(domain, ["component A", "component B"])

        if len(components) < 2:
            components.append("general mechanism")

        # Select 2-3 components to combine
        num_components = random.randint(2, min(3, len(components)))
        selected_components = random.sample(components, num_components)

        # Combination operations
        operations = [
            "integrating", "layering", "alternating between",
            "dynamically switching between", "creating a hybrid of"
        ]
        operation = random.choice(operations)

        # Generate insight
        components_text = ", ".join(selected_components[:-1]) + " and " + selected_components[-1]

        templates = [
            f"A novel {domain} approach: {operation} {components_text} to create an emergent capability.",
            f"By {operation} {components_text}, a more flexible {domain} system could address current limitations.",
            f"The untapped potential in {domain} lies in {operation} {components_text} in an iterative process.",
            f"Creating a unified framework by {operation} {components_text} would transform the {domain} paradigm."
        ]

        insight_text = random.choice(templates)

        # Quality - generative insights reward creativity but have implementation uncertainty
        expertise_level = self.domains.get(domain, 0.5)
        creativity_boost = self.creativity_level * 0.2  # Creativity directly impacts quality
        quality = min(0.95, expertise_level * random.uniform(0.7, 1.2) + creativity_boost)

        return insight_text, quality

    def simulate_error_detection(self):
        """
        Simulate error detection through internal models and predictive processes.
        Identifies potential issues before they manifest as failures.
        """
        # Define potential error types and their detection probabilities
        error_types = {
            "content_quality": 0.15,  # Probability of this error type occurring
            "exploration_strategy": 0.12,
            "memory_overflow": 0.08,
            "reasoning_fallacy": 0.10,
            "attention_misallocation": 0.13,
            "resource_exhaustion": 0.07,
            "feedback_loop": 0.09,
            "model_misalignment": 0.11,
            "data_corruption": 0.05,
            "convergence_failure": 0.10
        }

        # Roll for error detection
        detection_threshold = 0.25  # Base threshold for detecting any error

        # Check if any error is detected
        if random.random() < detection_threshold:
            # Select error type based on probabilities
            error_type = random.choices(
                list(error_types.keys()),
                weights=list(error_types.values()),
                k=1
            )[0]

            # Generate severity score
            severity = random.uniform(0.3, 0.9)

            # Generate specificity - how precisely the error is located
            specificity = random.uniform(0.4, 0.95)

            # Create detailed error information
            error_details = {
                "type": error_type,
                "severity": severity,
                "specificity": specificity,
                "timestamp": datetime.now().isoformat(),
                "predicted_impact": "high" if severity > 0.7 else "medium" if severity > 0.4 else "low"
            }

            # Add error-specific details
            if error_type == "content_quality":
                error_details["details"] = "Predicted degradation in content filtering effectiveness"
                error_details["affected_system"] = "ContentSifter"
            elif error_type == "exploration_strategy":
                error_details["details"] = "Detected suboptimal domain exploration pattern"
                error_details["affected_system"] = "SuperQuantumFreeWill"
            elif error_type == "memory_overflow":
                error_details["details"] = "Projected memory saturation with low-quality content"
                error_details["affected_system"] = "SemanticMemoryModule"
            elif error_type == "reasoning_fallacy":
                error_details["details"] = "Identified circular reasoning in goal setting"
                error_details["affected_system"] = "TemporalPlanner"
            elif error_type == "attention_misallocation":
                error_details["details"] = "Resources directed to low-value information processing"
                error_details["affected_system"] = "QuantumAttentionLayer"
            elif error_type == "resource_exhaustion":
                error_details["details"] = "Processing demand exceeding available computational resources"
                error_details["affected_system"] = "System-wide"
            elif error_type == "feedback_loop":
                error_details["details"] = "Self-reinforcing decision pattern detected"
                error_details["affected_system"] = "AIManager"
            elif error_type == "model_misalignment":
                error_details["details"] = "Model predictions diverging from intended behaviors"
                error_details["affected_system"] = "QuantumNexusModel"
            elif error_type == "data_corruption":
                error_details["details"] = "Inaccuracies in stored information affecting reasoning"
                error_details["affected_system"] = "MemorySystem"
            elif error_type == "convergence_failure":
                error_details["details"] = "Learning process failing to reach stable optimization"
                error_details["affected_system"] = "AdaptiveLearningSystem"

            # Log the detection if it's severe
            if severity > 0.7:
                log_event(f"ImaginationEngine: Detected potential {error_type} error (severity: {severity:.2f})", "WARNING")

            return error_details

        # No error detected
        return None

    def simulate_error_correction(self, error_details):
        """
        Simulate error correction strategies based on detected issues.
        Enhanced with multiple correction approaches per error type.
        """
        if not error_details or not isinstance(error_details, dict):
            return {"success": False, "reason": "Invalid error details"}

        error_type = error_details.get("type", "unknown")
        severity = error_details.get("severity", 0.5)
        specificity = error_details.get("specificity", 0.5)

        # Enhanced correction success probability calculation
        # Higher specificity and lower severity make correction more likely
        base_success_prob = 0.7
        success_prob = base_success_prob * (0.5 + specificity/2) * (1.3 - severity/2)

        # Add retry mechanism for previously failed corrections
        retry_boost = 0.2 if error_type in self.failed_corrections else 0.0
        success_prob = min(0.95, success_prob + retry_boost)

        # Roll for correction success
        correction_successful = random.random() < success_prob

        # Multiple strategies per error type with fallbacks
        strategies_by_type = {
            "content_quality": [
                "Recalibrate content quality thresholds",
                "Implement additional filtering layers",
                "Increase weight of domain authority in evaluation",
                "Apply stricter semantic relevance filters",
                "Enhance text-to-noise ratio detection"
            ],
            "exploration_strategy": [
                "Adjust exploration/exploitation balance",
                "Implement temporary randomness increase",
                "Refocus on high-information domains",
                "Apply entropy-based domain selection",
                "Implement strategic domain rotation"
            ],
            "memory_overflow": [
                "Increase pruning of low-importance memories",
                "Implement more aggressive compression",
                "Adjust importance calculation parameters",
                "Apply temporal decay to older memories",
                "Implement semantic clustering for memory organization"
            ],
            "reasoning_fallacy": [
                "Apply metacognitive verification steps",
                "Introduce counterfactual checking",
                "Implement logical consistency validation",
                "Apply bayesian reasoning correction",
                "Implement multi-perspective reasoning"
            ],
            "attention_misallocation": [
                "Recalibrate attention mechanism weights",
                "Implement attention budget constraints",
                "Add periodic attention reset mechanism",
                "Apply information-gain-weighted attention",
                "Implement context-aware attention allocation"
            ],
            "resource_exhaustion": [
                "Implement resource quota system",
                "Prioritize high-value computational tasks",
                "Introduce adaptive resource allocation",
                "Apply computational load balancing",
                "Implement resource usage optimization"
            ],
            "feedback_loop": [
                "Interrupt cyclic patterns with randomization",
                "Implement feedback dampening mechanisms",
                "Reset affected subsystem parameters",
                "Apply decision diversity requirements",
                "Implement pattern-break triggers"
            ],
            "model_misalignment": [
                "Realign model objectives with outcomes",
                "Implement preference alignment validation",
                "Apply behavior boundary constraints",
                "Enhance value alignment mechanisms",
                "Implement targeted diagnostic sequence"
            ],
            "data_corruption": [
                "Apply data integrity validation",
                "Implement redundant storage mechanisms",
                "Refresh from authoritative sources",
                "Apply error-correcting mechanisms",
                "Implement targeted diagnostic sequence"
            ],
            "convergence_failure": [
                "Reset optimization parameters",
                "Implement alternative convergence paths",
                "Apply learning rate schedules",
                "Introduce gradient stabilization mechanisms",
                "Implement landscape reshaping techniques"
            ]
        }

        # Get strategies for this error type or use default
        available_strategies = strategies_by_type.get(error_type, [
            "Apply general error correction procedure",
            "Reset affected subsystem parameters",
            "Implement targeted diagnostic sequence"
        ])

        # Try to select different strategy if previous attempts failed
        if error_type in self.failed_strategies:
            failed_strats = self.failed_strategies[error_type]
            available_strategies = [s for s in available_strategies if s not in failed_strats]
            if not available_strategies:  # If all strategies failed before, reset and try again
                available_strategies = strategies_by_type.get(error_type, ["Apply emergency recovery procedure"])

        # Select correction strategy, preferring unused strategies
        selected_strategy = random.choice(available_strategies)

        # Track failures for future avoidance
        if not correction_successful:
            if error_type not in self.failed_corrections:
                self.failed_corrections[error_type] = 0
            self.failed_corrections[error_type] += 1

            if error_type not in self.failed_strategies:
                self.failed_strategies[error_type] = set()
            self.failed_strategies[error_type].add(selected_strategy)

        # Create correction result
        correction_result = {
            "error_type": error_type,
            "strategy_applied": selected_strategy,
            "success": correction_successful,
            "effectiveness": random.uniform(0.6, 0.95) if correction_successful else random.uniform(0.1, 0.4),
            "timestamp": datetime.now().isoformat()
        }

        # Apply additional correction metadata
        if correction_successful:
            correction_result["changes_made"] = random.randint(1, 5)
            correction_result["recovery_level"] = "complete" if random.random() < 0.7 else "partial"

            # Reset failure counters on success
            if error_type in self.failed_corrections:
                del self.failed_corrections[error_type]
            if error_type in self.failed_strategies:
                del self.failed_strategies[error_type]
        else:
            correction_result["retry_recommended"] = True
            correction_result["alternative_strategies"] = len(available_strategies) - 1

        # Log the correction attempt
        log_level = "INFO" if correction_successful else "WARNING"
        log_event(f"ImaginationEngine: Error correction for {error_type} - Strategy: {selected_strategy} - Success: {correction_successful}", log_level)

        return correction_result

    def simulate_quantum_cognition(self):
        """
        Simulate quantum-like cognitive processes including superposition
        of concepts, interference effects, and non-classical inference.
        """
        # Probability of quantum phenomenon
        quantum_probability = 0.15

        if random.random() > quantum_probability:
            return None  # No quantum phenomenon this time

        # Different quantum cognitive phenomena
        quantum_phenomena = [
            "superposition",  # Multiple conceptual states simultaneously
            "interference",   # Concepts influencing each other non-classically
            "entanglement",   # Correlated concept states
            "contextuality"   # Meaning dependent on measurement context
        ]

        # Select phenomenon
        phenomenon = random.choice(quantum_phenomena)

        # Define potential anomalies and insights
        anomalies = []
        insights = []

        if phenomenon == "superposition":
            anomalies = [
                "Multiple incompatible goal states activated simultaneously",
                "Strategy selection maintaining all possibilities until execution",
                "Knowledge representation existing in multiple contradiction states"
            ]
            insights = [
                "Leveraging conceptual superposition enables parallel strategy evaluation",
                "Maintaining goal superposition increases adaptive flexibility",
                "Quantum superposition of knowledge allows richer hypothesis space"
            ]
        elif phenomenon == "interference":
            anomalies = [
                "Goal pathways showing constructive/destructive interference",
                "Strategy combinations producing unexpected enhancement",
                "Knowledge patterns exhibiting non-linear interference effects"
            ]
            insights = [
                "Constructive interference between strategies amplifies effectiveness",
                "Cognitive interference patterns reveal hidden knowledge connections",
                "Strategic interference effects create emergent capabilities"
            ]
        elif phenomenon == "entanglement":
            anomalies = [
                "Distant knowledge domains showing unexplainable correlations",
                "Strategy outcomes entangled across execution contexts",
                "Goal achievement states exhibiting non-local influences"
            ]
            insights = [
                "Entangled knowledge representations enable cross-domain transfer",
                "Strategic entanglement allows coordinated multi-system adaptation",
                "Quantum entanglement of goals creates self-reinforcing alignment"
            ]
        elif phenomenon == "contextuality":
            anomalies = [
                "Knowledge valuation showing strong contextual dependencies",
                "Strategy effectiveness violating classical probability bounds",
                "Cognitive state measurements exhibiting contextual anomalies"
            ]
            insights = [
                "Contextual knowledge representation improves semantic accuracy",
                "Quantum contextuality enables more nuanced decision strategies",
                "Context-dependent cognition enhances adaptive intelligence"
            ]


        # Select specific anomaly and insight
        anomaly = random.choice(anomalies)
        insight = random.choice(insights)

        # Determine if this is a significant anomaly
        is_significant = random.random() < 0.3

        # Create quantum cognition result
        result = {
            "phenomenon": phenomenon,
            "anomaly_detected": is_significant,
            "anomaly": anomaly if is_significant else None,
            "insight": insight,
            "timestamp": datetime.now().isoformat()
        }

        # Log the quantum cognition event
        log_level = "QUANTUM" if is_significant else "INFO"
        log_message = f"Quantum Cognition: {phenomenon.title()} - {'Anomaly: ' + anomaly if is_significant else 'Insight: ' + insight}"
        log_event(log_message, log_level)

        return result

    def get_imagination_report(self):
        """
        Generate a comprehensive report on imagination engine activity.
        """
        if not self.insight_history:
            return {"status": "inactive", "insights_generated": 0}

        # Calculate insight statistics
        insight_count = len(self.insight_history)
        avg_quality = sum(i["quality"] for i in self.insight_history) / insight_count

        # Count by domain and mode
        domain_counts = {}
        mode_counts = {}

        for insight in self.insight_history:
            domain = insight.get("domain", "unknown")
            mode = insight.get("mode", "unknown")

            domain_counts[domain] = domain_counts.get(domain, 0) + 1
            mode_counts[mode] = mode_counts.get(mode, 0) + 1

        # Get top insights
        top_insights = sorted(self.insight_history, key=lambda x: x.get("quality", 0), reverse=True)[:3]
        top_texts = [i["text"] for i in top_insights]

        # Compute mode effectiveness
        mode_quality = {}
        for mode in self.cognitive_modes:
            mode_insights = [i for i in self.insight_history if i.get("mode") == mode]
            if mode_insights:
                mode_quality[mode] = sum(i["quality"] for i in mode_insights) / len(mode_insights)

        # Identify most effective mode
        most_effective = max(mode_quality.items(), key=lambda x: x[1])[0] if mode_quality else None

        return {
            "status": "active",
            "insights_generated": insight_count,
            "average_quality": avg_quality,
            "domain_distribution": domain_counts,
            "mode_distribution": mode_counts,
            "most_effective_mode": most_effective,
            "top_insights": top_texts,
            "creativity_level": self.creativity_level,
            "imagination_health": "high" if avg_quality > 0.7 else "medium" if avg_quality > 0.5 else "low"
        }

class DomainIntelligence:
    """
    Advanced domain analysis system for understanding website characteristics,
    content patterns, and authority metrics to guide exploration.
    """
    def __init__(self):
        self.domain_knowledge = {}  # Main knowledge store for domains
        self.domain_categories = {}  # Categorization of domains
        self.authority_metrics = {}  # Authority scores and metrics
        self.topic_expertise = {}    # Domain topic area expertise
        self.relation_graph = {}     # Graph of domain relationships
        self.access_patterns = {}    # Patterns of domain access and results
        self.update_timestamps = {}  # When domains were last analyzed
        self.anomaly_records = {}    # Record of domain anomalies

        # Reference categorization data
        self.category_keywords = {
            "academic": ["university", "research", "edu", "academic", "science", "study", "journal"],
            "technology": ["tech", "programming", "software", "hardware", "computer", "code", "developer"],
            "news": ["news", "article", "report", "journalism", "media", "current", "daily"],
            "reference": ["wiki", "reference", "encyclopedia", "knowledge", "dictionary", "information"],
            "social": ["social", "community", "forum", "discussion", "comment", "people", "network"],
            "commercial": ["shop", "product", "buy", "price", "store", "commerce", "retail", "purchase"],
            "government": ["gov", "government", "official", "public", "administration", "agency", "state"],
            "entertainment": ["entertainment", "game", "music", "video", "movie", "play", "fun"]
        }

        # Authority signals
        self.authority_signals = [
            "domain_age", "citation_count", "https_enabled",
            "content_quality", "update_frequency", "outbound_links",
            "referral_pattern", "content_depth"
        ]

        log_event("DomainIntelligence initialized", "INFO")

    def analyze_domain(self, domain_url):
        """
        Perform comprehensive analysis of a domain to understand its
        characteristics, trustworthiness, and specialization.
        """
        if not domain_url:
            return False

        # Parse URL to extract domain
        try:
            parsed_url = urlparse(domain_url)
            domain = parsed_url.netloc

            # Skip if empty domain
            if not domain:
                return False

            # Record analysis time
            current_time = datetime.now().isoformat()
            self.update_timestamps[domain] = current_time

            # Extract domain components
            domain_parts = domain.split('.')
            tld = domain_parts[-1] if len(domain_parts) > 0 else ""
            sld = domain_parts[-2] if len(domain_parts) > 1 else ""

            # Initial domain type inference from TLD
            domain_type = "unknown"
            if tld == "edu":
                domain_type = "academic"
            elif tld == "gov":
                domain_type = "government"
            elif tld == "org":
                domain_type = "organization"
            elif tld == "com":
                domain_type = "commercial"

            # Analyze domain name for category clues
            domain_name_lower = domain.lower()
            category_scores = {}

            for category, keywords in self.category_keywords.items():
                # Calculate score based on keyword presence
                score = sum(1 for keyword in keywords if keyword in domain_name_lower)
                if score > 0:
                    category_scores[category] = score

            # Determine primary category if scores exist
            primary_category = None
            if category_scores:
                primary_category = max(category_scores.items(), key=lambda x: x[1])[0]

            # Create or update domain record
            if domain not in self.domain_knowledge:
                # New domain record
                self.domain_knowledge[domain] = {
                    "domain": domain,
                    "tld": tld,
                    "domain_type": domain_type,
                    "primary_category": primary_category,
                    "category_scores": category_scores,
                    "first_analyzed": current_time,
                    "last_updated": current_time,
                    "visit_count": 1,
                    "pages_analyzed": 0,
                    "authority_score": 0.5,  # Initial neutral score
                    "content_quality": None,
                    "https_enabled": parsed_url.scheme == "https",
                    "known_topics": [],
                    "page_pattern": {}
                }

                # Add to category index
                if primary_category:
                    if primary_category not in self.domain_categories:
                        self.domain_categories[primary_category] = set()
                    self.domain_categories[primary_category].add(domain)

                log_event(f"Added new domain to intelligence database: {domain} ({domain_type}, {primary_category})", "INFO")
            else:
                # Update existing record
                self.domain_knowledge[domain]["last_updated"] = current_time
                self.domain_knowledge[domain]["visit_count"] += 1

                # Update category if confidence has improved
                existing_category = self.domain_knowledge[domain]["primary_category"]
                if primary_category and (not existing_category or
                                       category_scores.get(primary_category, 0) >
                                       self.domain_knowledge[domain]["category_scores"].get(existing_category, 0)):

                    # Remove from old category index
                    if existing_category and existing_category in self.domain_categories:
                        self.domain_categories[existing_category].discard(domain)

                    # Add to new category index
                    if primary_category not in self.domain_categories:
                        self.domain_categories[primary_category] = set()
                    self.domain_categories[primary_category].add(domain)

                    # Update domain record
                    self.domain_knowledge[domain]["primary_category"] = primary_category
                    self.domain_knowledge[domain]["category_scores"] = category_scores

                    log_event(f"Updated domain categorization: {domain} recategorized as {primary_category}", "INFO")

            # Calculate authority score (simplified version)
            self._calculate_authority_score(domain)

            return True

        except Exception as e:
            log_event(f"Error analyzing domain {domain_url}: {e}", "ERROR")
            return False

    def _calculate_authority_score(self, domain):
        """Calculate domain authority score based on multiple signals"""
        if domain not in self.domain_knowledge:
            return 0.5  # Default neutral score

        # Collect available signals
        signals = {}
        domain_data = self.domain_knowledge[domain]

        # Signal: Domain Type factor
        domain_type_factors = {
            "academic": 0.8,
            "government": 0.8,
            "organization": 0.7,
            "news": 0.6,
            "reference": 0.7,
            "commercial": 0.5,
            "unknown": 0.5
        }

        signals["domain_type"] = domain_type_factors.get(domain_data.get("domain_type", "unknown"), 0.5)

        # Signal: HTTPS enabled
        signals["https_enabled"] = 0.7 if domain_data.get("https_enabled", False) else 0.3

        # Signal: Visit success rate
        visit_count = domain_data.get("visit_count", 0)
        pages_analyzed = domain_data.get("pages_analyzed", 0)
        signals["success_rate"] = min(0.9, pages_analyzed / max(1, visit_count))

        # Signal: TLD trustworthiness
        tld_trust = {
            "edu": 0.9,
            "gov": 0.9,
            "org": 0.7,
            "com": 0.5,
            "net": 0.5,
            "io": 0.6,
            "ai": 0.6
        }
        signals["tld_trust"] = tld_trust.get(domain_data.get("tld", ""), 0.4)

        # Signal: Content quality if available
        if domain_data.get("content_quality") is not None:
            signals["content_quality"] = domain_data["content_quality"]

        # Signal: Topic expertise if established
        if domain in self.topic_expertise and self.topic_expertise[domain]:
            # Average expertise across topics
            signals["topic_expertise"] = sum(self.topic_expertise[domain].values()) / len(self.topic_expertise[domain])

        # Calculate overall authority score
        # Weighted average of available signals
        weights = {
            "domain_type": 0.15,
            "https_enabled": 0.05,
            "success_rate": 0.20,
            "tld_trust": 0.10,
            "content_quality": 0.30,
            "topic_expertise": 0.20
        }

        total_weight = 0
        weighted_sum = 0

        for signal, value in signals.items():
            if signal in weights:
                weighted_sum += value * weights[signal]
                total_weight += weights[signal]

        # Compute final score with normalization
        if total_weight > 0:
            authority_score = weighted_sum / total_weight
        else:
            authority_score = 0.5  # Default if no signals available

        # Store authority score
        self.domain_knowledge[domain]["authority_score"] = authority_score
        self.authority_metrics[domain] = {
            "score": authority_score,
            "signals": signals,
            "timestamp": datetime.now().isoformat()
        }

        return authority_score

    def update_content_knowledge(self, domain, page_url, content_data):
        """
        Update domain knowledge with information from analyzed content.

        Parameters:
        - domain: Domain name
        - page_url: Full URL of the analyzed page
        - content_data: Dict with keys like 'quality', 'topics', 'length', etc.
        """
        if not domain or not page_url or not content_data:
            return False

        # Ensure domain exists in knowledge base
        if domain not in self.domain_knowledge:
            self.analyze_domain(page_url)

        if domain not in self.domain_knowledge:
            return False  # Domain analysis failed

        # Update page count
        self.domain_knowledge[domain]["pages_analyzed"] = self.domain_knowledge[domain].get("pages_analyzed", 0) + 1

        # Store page pattern
        path = urlparse(page_url).path
        page_pattern = self.domain_knowledge[domain].get("page_pattern", {})

        # Analyze path pattern
        path_parts = path.strip('/').split('/')

        # Identify path type
        path_type = "root"
        if len(path_parts) == 1 and path_parts[0]:
            path_type = "top_level"
        elif len(path_parts) > 1:
            path_type = "deep"

        # Update path type counts
        if "path_types" not in page_pattern:
            page_pattern["path_types"] = {"root": 0, "top_level": 0, "deep": 0}

        page_pattern["path_types"][path_type] = page_pattern["path_types"].get(path_type, 0) + 1

        # Update path component statistics
        if "common_segments" not in page_pattern:
            page_pattern["common_segments"] = {}

        for part in path_parts:
            if part:  # Skip empty parts
                page_pattern["common_segments"][part] = page_pattern["common_segments"].get(part, 0) + 1

        # Store updated page pattern
        self.domain_knowledge[domain]["page_pattern"] = page_pattern

        # Update content quality metrics
        if "quality" in content_data:
            quality_score = content_data["quality"]

            # Update rolling average of content quality
            current_quality = self.domain_knowledge[domain].get("content_quality")
            if current_quality is None:
                self.domain_knowledge[domain]["content_quality"] = quality_score
            else:
                # Weight existing score more to avoid large fluctuations
                self.domain_knowledge[domain]["content_quality"] = current_quality * 0.8 + quality_score * 0.2

        # Update topic knowledge
        if "topics" in content_data and content_data["topics"]:
            topics = content_data["topics"]

            # Update known topics for domain
            known_topics = set(self.domain_knowledge[domain].get("known_topics", []))
            known_topics.update(topics)
            self.domain_knowledge[domain]["known_topics"] = list(known_topics)

            # Update topic expertise
            if domain not in self.topic_expertise:
                self.topic_expertise[domain] = {}

            for topic in topics:
                # Increase expertise in this topic
                current_expertise = self.topic_expertise[domain].get(topic, 0.3)  # Start with low expertise
                # Expertise increases with each encounter but plateaus
                self.topic_expertise[domain][topic] = min(0.9, current_expertise + 0.05)

        # Recalculate authority score with new information
        self._calculate_authority_score(domain)

        return True

    def find_related_domains(self, domain, relation_type="topic", max_results=5):
        """
        Find domains related to the given domain by topic or other criteria.

        Parameters:
        - domain: Domain to find relations for
        - relation_type: Type of relation ('topic', 'category', 'link')
        - max_results: Maximum number of results to return
        """
        if not domain or domain not in self.domain_knowledge:
            return []

        related_domains = []

        if relation_type == "topic":
            # Find domains with overlapping topics
            domain_topics = set(self.domain_knowledge[domain].get("known_topics", []))

            if not domain_topics:
                return []  # No topics to match

            # Score domains by topic overlap
            domain_scores = {}

            for d, data in self.domain_knowledge.items():
                if d == domain:
                    continue  # Skip self

                d_topics = set(data.get("known_topics", []))
                if not d_topics:
                    continue  # Skip domains with no topics

                # Calculate Jaccard similarity of topic sets
                overlap = len(domain_topics.intersection(d_topics))
                union = len(domain_topics.union(d_topics))

                if overlap > 0:
                    similarity = overlap / union
                    domain_scores[d] = similarity

            # Sort by similarity score
            sorted_domains = sorted(domain_scores.items(), key=lambda x: x[1], reverse=True)
            related_domains = [(d, score) for d, score in sorted_domains[:max_results]]

        elif relation_type == "category":
            # Find domains in the same category
            category = self.domain_knowledge[domain].get("primary_category")

            if not category or category not in self.domain_categories:
                return []

            # Get domains in same category
            category_domains = [d for d in self.domain_categories[category] if d != domain]

            # Sort by authority score
            domain_scores = []
            for d in category_domains:
                if d in self.domain_knowledge:
                    score = self.domain_knowledge[d].get("authority_score", 0.5)
                    domain_scores.append((d, score))

            # Sort by authority score
            sorted_domains = sorted(domain_scores, key=lambda x: x[1], reverse=True)
            related_domains = sorted_domains[:max_results]

        elif relation_type == "link":
            # Find domains that share links (requires backlink tracking)
            # This would be implemented with the relation graph
            if domain in self.relation_graph and "links_to" in self.relation_graph[domain]:
                links = self.relation_graph[domain]["links_to"]
                related_domains = [(d, 1.0) for d in links][:max_results]

        return related_domains

    def get_domain_knowledge(self, domain):
        """
        Retrieve comprehensive knowledge about a domain.

        Parameters:
        - domain: Domain name to retrieve knowledge for
        """
        # Handle both domain name and full URL
        if not domain:
            return None

        # Check if this is a URL and extract domain
        if domain.startswith(('http://', 'https://')):
            domain = urlparse(domain).netloc

        if not domain:
            return None

        # Return domain knowledge if exists
        if domain in self.domain_knowledge:
            # Create a copy to avoid direct modification
            knowledge = self.domain_knowledge[domain].copy()

            # Add additional related information
            knowledge["authority_metrics"] = self.authority_metrics.get(domain, {})
            knowledge["topic_expertise"] = self.topic_expertise.get(domain, {})

            # Add anomaly records if they exist
            if domain in self.anomaly_records:
                knowledge["anomalies"] = self.anomaly_records[domain]

            # Add related domains
            related_by_topic = self.find_related_domains(domain, "topic", 3)
            if related_by_topic:
                knowledge["related_domains"] = [d for d, _ in related_by_topic]

            return knowledge

        return None

    def detect_domain_anomalies(self, domain):
        """
        Analyze domain for potential anomalies or suspicious patterns.

        Parameters:
        - domain: Domain to check for anomalies
        """
        if not domain or domain not in self.domain_knowledge:
            return []

        anomalies = []
        domain_data = self.domain_knowledge[domain]

        # Anomaly 1: TLD mismatch with content
        tld = domain_data.get("tld", "")
        category = domain_data.get("primary_category")

        if tld == "edu" and category and category not in ["academic", "reference"]:
            anomalies.append({
                "type": "tld_category_mismatch",
                "description": f"Domain has .edu TLD but content suggests '{category}' category",
                "severity": "medium"
            })

        # Anomaly 2: Low content quality on authoritative TLD
        content_quality = domain_data.get("content_quality")
        if content_quality and content_quality < 0.4 and tld in ["edu", "gov", "org"]:
            anomalies.append({
                "type": "low_quality_authoritative",
                "description": f"Domain with .{tld} TLD has unusually low content quality ({content_quality:.2f})",
                "severity": "high"
            })

        # Anomaly 3: Unusual page pattern
        page_pattern = domain_data.get("page_pattern", {})
        path_types = page_pattern.get("path_types", {})

        if path_types.get("deep", 0) > 10 * max(1, path_types.get("top_level", 0) + path_types.get("root", 0)):
            anomalies.append({
                "type": "unusual_path_pattern",
                "description": "Domain shows unusually high ratio of deep paths to top-level content",
                "severity": "low"
            })

        # Anomaly 4: Visit count vs pages analyzed mismatch
        visit_count = domain_data.get("visit_count", 0)
        pages_analyzed = domain_data.get("pages_analyzed", 0)

        if visit_count > 5 and pages_analyzed / visit_count < 0.3:
            anomalies.append({
                "type": "low_analysis_success_rate",
                "description": f"Domain has low success rate: {pages_analyzed}/{visit_count} visits produced content",
                "severity": "medium"
            })

        # Store anomalies if found
        if anomalies:
            self.anomaly_records[domain] = {
                "detected": anomalies,
                "timestamp": datetime.now().isoformat()
            }

            # Log high severity anomalies
            high_severity = [a for a in anomalies if a.get("severity") == "high"]
            if high_severity:
                for anomaly in high_severity:
                    log_event(f"Domain anomaly detected for {domain}: {anomaly['description']}", "WARNING")

        return anomalies

    def get_domain_recommendation(self, current_domain, purpose="exploration"):
        """
        Recommend related domains based on current domain and purpose.

        Parameters:
        - current_domain: The current domain
        - purpose: Why we need recommendations ('exploration', 'deepening', 'verification')
        """
        if not current_domain:
            # Recommend highly trusted domains by default
            trusted_domains = self._get_top_domains_by_authority(5)
            if trusted_domains:
                return {
                    "recommendations": trusted_domains,
                    "reason": "Default trusted domains for general exploration"
                }
            return None

        # Extract domain from URL if needed
        if current_domain.startswith(('http://', 'https://')):
            current_domain = urlparse(current_domain).netloc

        # Check domain knowledge
        if current_domain not in self.domain_knowledge:
            return None

        domain_data = self.domain_knowledge[current_domain]

        # Different recommendation strategies based on purpose
        if purpose == "exploration":
            # Favor topic-related domains with high authority
            related = self.find_related_domains(current_domain, "topic", 10)

            # Filter for good authority
            good_related = [(domain, score) for domain, score in related
                          if domain in self.domain_knowledge
                          and self.domain_knowledge[domain].get("authority_score", 0) > 0.6]

            if good_related:
                return {
                    "recommendations": [domain for domain, _ in good_related[:5]],
                    "reason": f"Topic-related domains to {current_domain} with good authority"
                }

        elif purpose == "deepening":
            # Focus on same category with highest topic expertise
            category = domain_data.get("primary_category")
            if category and category in self.domain_categories:
                # Get domains in same category
                category_domains = [d for d in self.domain_categories[category] if d != current_domain]

                # Score by topic expertise and authority
                domain_scores = []

                for d in category_domains:
                    if d in self.domain_knowledge and d in self.topic_expertise:
                        # Average topic expertise
                        topics = self.topic_expertise[d]
                        if topics:
                            avg_expertise = sum(topics.values()) / len(topics)
                            authority = self.domain_knowledge[d].get("authority_score", 0.5)

                            # Combined score weighing expertise more
                            score = avg_expertise * 0.7 + authority * 0.3
                            domain_scores.append((d, score))

                if domain_scores:
                    sorted_domains = sorted(domain_scores, key=lambda x: x[1], reverse=True)
                    return {
                        "recommendations": [domain for domain, _ in sorted_domains[:5]],
                        "reason": f"Domains with deep expertise in {category} category"
                    }

        elif purpose == "verification":
            # Find authoritative domains in same topic area
            topics = domain_data.get("known_topics", [])
            if not topics:
                return None

            # Find domains with same topics but higher authority
            current_authority = domain_data.get("authority_score", 0.5)
            verification_candidates = []

            for d, data in self.domain_knowledge.items():
                if d == current_domain:
                    continue

                # Check topic overlap
                d_topics = set(data.get("known_topics", []))
                overlap = len(set(topics).intersection(d_topics))

                if overlap > 0 and data.get("authority_score", 0) > current_authority:
                    # Score by authority and topic overlap
                    score = data.get("authority_score", 0) * (overlap / len(topics))
                    verification_candidates.append((d, score))

            if verification_candidates:
                sorted_candidates = sorted(verification_candidates, key=lambda x: x[1], reverse=True)
                return {
                    "recommendations": [domain for domain, _ in sorted_candidates[:5]],
                    "reason": f"More authoritative sources on same topics as {current_domain}"
                }

        # Default to highest authority domains as fallback
        return {
            "recommendations": self._get_top_domains_by_authority(5),
            "reason": "General high-authority domains (fallback recommendation)"
        }

    def _get_top_domains_by_authority(self, count=5):
        """Get the top domains by authority score"""
        if not self.domain_knowledge:
            return []

        # Sort domains by authority score
        scored_domains = [(d, data.get("authority_score", 0))
                        for d, data in self.domain_knowledge.items()]
        sorted_domains = sorted(scored_domains, key=lambda x: x[1], reverse=True)

        return [domain for domain, _ in sorted_domains[:count]]

    def export_domain_report(self, domain):
        """
        Generate comprehensive report on domain for external use.

        Parameters:
        - domain: Domain to generate report for
        """
        if not domain or domain not in self.domain_knowledge:
            return None

        knowledge = self.get_domain_knowledge(domain)
        if not knowledge:
            return None

        # Generate anomaly section if needed
        anomalies = self.detect_domain_anomalies(domain)
        anomaly_section = None
        if anomalies:
            anomaly_section = {
                "count": len(anomalies),
                "details": anomalies,
                "recommended_action": "caution" if any(a.get("severity") == "high" for a in anomalies) else "monitor"
            }

        # Get related domains
        topic_related = self.find_related_domains(domain, "topic", 5)
        category_related = self.find_related_domains(domain, "category", 5)

        # Compile report
        report = {
            "domain": domain,
            "analysis_date": datetime.now().isoformat(),
            "summary": {
                "type": knowledge.get("domain_type", "unknown"),
                "category": knowledge.get("primary_category", "unknown"),
                "authority_score": knowledge.get("authority_score", 0),
                "content_quality": knowledge.get("content_quality"),
                "visit_count": knowledge.get("visit_count", 0),
                "pages_analyzed": knowledge.get("pages_analyzed", 0)
            },
            "authority_assessment": {
                "score": knowledge.get("authority_score", 0),
                "factors": knowledge.get("authority_metrics", {}).get("signals", {}),
                "interpretation": self._interpret_authority_score(knowledge.get("authority_score", 0))
            },
            "content_profile": {
                "known_topics": knowledge.get("known_topics", []),
                "path_patterns": knowledge.get("page_pattern", {}).get("path_types", {}),
                "https_enabled": knowledge.get("https_enabled", False)
            },
            "related_domains": {
                "by_topic": [d for d, _ in topic_related],
                "by_category": [d for d, _ in category_related]
            }
        }

        # Add anomalies if detected
        if anomaly_section:
            report["anomalies"] = anomaly_section

        return report

    def _interpret_authority_score(self, score):
        """Provide interpretation of authority score"""
        if score >= 0.8:
            return "Very High Authority - Likely a definitive source in its field"
        elif score >= 0.7:
            return "High Authority - Generally trustworthy and established source"
        elif score >= 0.5:
            return "Moderate Authority - Adequate source but verification recommended"
        elif score >= 0.3:
            return "Low Authority - Approach with caution, verify information"
        else:
            return "Very Low Authority - Not recommended as a primary information source"

    def get_intelligence_statistics(self):
        """Generate statistics about domain intelligence database"""
        if not self.domain_knowledge:
            return {"status": "empty", "domains_analyzed": 0}

        # Basic counts
        domain_count = len(self.domain_knowledge)

        # Category distribution
        category_counts = {}
        for category, domains in self.domain_categories.items():
            category_counts[category] = len(domains)

        # Authority distribution
        authority_ranges = {
            "very_high": 0,  # 0.8-1.0
            "high": 0,       # 0.6-0.8
            "moderate": 0,   # 0.4-0.6
            "low": 0,        # 0.2-0.4
            "very_low": 0    # 0.0-0.2
        }

        for domain, data in self.domain_knowledge.items():
            score = data.get("authority_score", 0.5)

            if score >= 0.8:
                authority_ranges["very_high"] += 1
            elif score >= 0.6:
                authority_ranges["high"] += 1
            elif score >= 0.4:
                authority_ranges["moderate"] += 1
            elif score >= 0.2:
                authority_ranges["low"] += 1
            else:
                authority_ranges["very_low"] += 1

        # TLD distribution
        tld_counts = {}
        for domain, data in self.domain_knowledge.items():
            tld = data.get("tld", "unknown")
            tld_counts[tld] = tld_counts.get(tld, 0) + 1

        # Anomaly statistics
        anomaly_count = sum(1 for domain in self.anomaly_records)
        high_severity_count = sum(
            1 for domain, record in self.anomaly_records.items()
            if any(a.get("severity") == "high" for a in record.get("detected", []))
        )

        return {
            "status": "active",
            "domains_analyzed": domain_count,
            "category_distribution": category_counts,
            "authority_distribution": authority_ranges,
            "tld_distribution": tld_counts,
            "anomalies_detected": anomaly_count,
            "high_severity_anomalies": high_severity_count
        }





class MetaLearningModule:
    """
    Advanced meta-learning system that monitors, analyzes, and optimizes
    the learning process itself, enabling autonomous improvement of the
    model's learning capabilities over time.
    """
    def __init__(self, model):
        self.model = model
        self.learning_history = deque(maxlen=100)  # Track recent learning metrics
        self.hyperparameter_history = []  # Track hyperparameter evolution
        self.architecture_history = []  # Track architecture changes
        self.performance_trends = {}  # Performance over time for different metrics
        self.learning_rate_schedule = []  # History of learning rate adjustments
        self.optimization_state = "exploration"  # Current optimization phase
        self.training_cycles = 0  # Total training cycles performed
        self.gradient_statistics = deque(maxlen=20)  # Recent gradient statistics
        self.weight_evolution = {}  # Track how weights evolve over time
        self.improvement_rates = {}  # Rate of improvement for different metrics

        # Meta-parameters (parameters about parameter learning)
        self.meta_params = {
            "exploration_rate": 0.3,  # How much to explore hyperparameter space
            "stability_threshold": 0.05,  # Threshold for stability detection
            "adaptation_rate": 0.2,  # How quickly to adapt to new information
            "patience": 5,  # Cycles to wait before making significant changes
            "learning_rate_bounds": (1e-6, 1e-2),  # Min/max learning rate
            "trend_window": 10,  # Window size for trend analysis
            "architecture_change_threshold": 0.1  # Threshold for architecture changes
        }

        # Initialize monitoring
        log_event("MetaLearningModule initialized with meta-optimization capabilities", "INFO")

    def track_performance(self, metrics):
        """
        Track and analyze training performance metrics over time
        to inform meta-learning decisions.

        Parameters:
        - metrics: Dict containing performance metrics (loss, accuracy, etc.)
        """
        self.training_cycles += 1

        # Skip invalid metrics
        if not isinstance(metrics, dict) or len(metrics) == 0:
            return

        # Store metrics with timestamp
        timestamped_metrics = metrics.copy()
        timestamped_metrics["cycle"] = self.training_cycles
        timestamped_metrics["timestamp"] = datetime.now().isoformat()

        # Add current learning rate if available
        if hasattr(self.model, '_current_lr'):
            timestamped_metrics["learning_rate"] = getattr(self.model, '_current_lr')
        elif hasattr(self.model, 'optimizer') and hasattr(self.model.optimizer, 'param_groups'):
            # Try to get from optimizer
            try:
                timestamped_metrics["learning_rate"] = self.model.optimizer.param_groups[0]['lr']
            except (IndexError, KeyError):
                pass

        # Store in history
        self.learning_history.append(timestamped_metrics)

        # Update performance trends when we have enough data
        if len(self.learning_history) >= self.meta_params["trend_window"]:
            self._update_performance_trends()

        # Analyze learning periodically
        if self.training_cycles % max(1, self.meta_params["patience"]) == 0:
            self.analyze_trends()

    def _update_performance_trends(self):
        """Update trend analysis for each tracked metric"""
        window = self.meta_params["trend_window"]
        recent_metrics = list(self.learning_history)[-window:]

        # Find consistent metrics across all entries
        metric_keys = set.intersection(*[set(m.keys()) for m in recent_metrics])
        metric_keys = [k for k in metric_keys if k not in ["cycle", "timestamp", "learning_rate"]]

        for key in metric_keys:
            # Extract values
            values = [m[key] for m in recent_metrics if key in m]

            if not values or len(values) < window:
                continue

            # Calculate trend statistics
            mean_value = sum(values) / len(values)
            min_value = min(values)
            max_value = max(values)
            range_value = max_value - min_value

            # Calculate first derivative (rate of change)
            derivatives = [values[i] - values[i-1] for i in range(1, len(values))]
            mean_derivative = sum(derivatives) / len(derivatives) if derivatives else 0

            # Calculate second derivative (acceleration of change)
            accelerations = [derivatives[i] - derivatives[i-1] for i in range(1, len(derivatives))]
            mean_acceleration = sum(accelerations) / len(accelerations) if accelerations else 0

            # Interpret trend direction
            if abs(mean_derivative) < self.meta_params["stability_threshold"]:
                direction = "stable"
            elif mean_derivative < 0:
                direction = "decreasing"
            else:
                direction = "increasing"

            # Interpret acceleration
            if abs(mean_acceleration) < self.meta_params["stability_threshold"] / 2:
                acceleration = "steady"
            elif mean_acceleration < 0:
                acceleration = "decelerating"
            else:
                acceleration = "accelerating"

            # Store trend information
            self.performance_trends[key] = {
                "current": values[-1],
                "mean": mean_value,
                "min": min_value,
                "max": max_value,
                "range": range_value,
                "direction": direction,
                "rate_of_change": mean_derivative,
                "acceleration": acceleration,
                "acceleration_value": mean_acceleration,
                "updated_at": datetime.now().isoformat()
            }

            # Calculate improvement rate (relative to starting point)
            if len(values) > 1:
                # For loss, lower is better; for accuracy, higher is better
                is_loss_like = "loss" in key.lower() or "error" in key.lower()

                start_value = values[0]
                end_value = values[-1]

                if is_loss_like:
                    # For loss metrics, improvement is decrease
                    improvement = (start_value - end_value) / max(0.0001, start_value)
                else:
                    # For other metrics, improvement is increase
                    improvement = (end_value - start_value) / max(0.0001, start_value)

                self.improvement_rates[key] = improvement

    def analyze_trends(self):
        """
        Analyze learning trends and make meta-learning decisions
        for hyperparameter and architecture adaptation.
        """
        if len(self.learning_history) < self.meta_params["trend_window"]:
            log_event(f"Insufficient learning history for meta-analysis (need {self.meta_params['trend_window']})", "INFO")
            return

        # Check if we have loss metrics
        loss_metrics = [k for k in self.performance_trends.keys()
                       if "loss" in k.lower() or "error" in k.lower()]

        if not loss_metrics:
            log_event("No loss metrics found for meta-learning trend analysis", "WARNING")
            return

        # Use first loss metric as primary indicator
        primary_loss = loss_metrics[0]
        loss_trend = self.performance_trends[primary_loss]

        # Current state assessment
        current_state = {
            "direction": loss_trend["direction"],
            "acceleration": loss_trend["acceleration"],
            "value": loss_trend["current"],
            "improvement_rate": self.improvement_rates.get(primary_loss, 0)
        }

        # Decision making based on loss trend patterns
        decisions = self._make_meta_decisions(current_state, primary_loss)

        # Log significant decisions
        for decision in decisions:
            if decision["type"] in ["learning_rate_change", "architecture_change"]:
                log_event(f"Meta-learning decision: {decision['description']}", "INFO")

        # Apply decisions
        self._apply_meta_decisions(decisions)

    def _make_meta_decisions(self, current_state, primary_metric):
        """
        Make meta-learning decisions based on current learning state.

        Parameters:
        - current_state: Dict describing current trend state
        - primary_metric: Name of the primary metric being analyzed

        Returns:
        - List of decision dictionaries with type and parameters
        """
        decisions = []

        # Case 1: Learning plateaued (stable with low improvement)
        if (current_state["direction"] == "stable" and
            abs(current_state["improvement_rate"]) < self.meta_params["stability_threshold"]):

            # Check duration of plateau
            plateau_duration = self._count_consecutive_states("stable", primary_metric)

            if plateau_duration >= self.meta_params["patience"]:
                # Long plateau - need significant change
                if self.optimization_state == "exploration":
                    # In exploration phase, try architecture change
                    decisions.append({
                        "type": "architecture_change",
                        "change": "expand" if random.random() < 0.7 else "contract",
                        "description": f"Architecture change due to {plateau_duration}-cycle plateau in {primary_metric}"
                    })

                    # Also try learning rate restart
                    decisions.append({
                        "type": "learning_rate_change",
                        "factor": 10.0,
                        "description": "Learning rate increase to escape plateau"
                    })
                else:
                    # In refinement phase, smaller learning rate adjustment
                    decisions.append({
                        "type": "learning_rate_change",
                        "factor": random.uniform(2.0, 5.0),
                        "description": "Learning rate adjustment to overcome plateau"
                    })

                # Switch optimization state
                decisions.append({
                    "type": "optimization_state_change",
                    "new_state": "refinement" if self.optimization_state == "exploration" else "exploration",
                    "description": f"Switch optimization strategy due to {plateau_duration}-cycle plateau"
                })

        # Case 2: Loss increasing (getting worse)
        elif current_state["direction"] == "increasing" and "loss" in primary_metric.lower():
            # Loss is getting worse - need to reduce learning rate

            # Check if it's accelerating or steady
            if current_state["acceleration"] in ["accelerating", "steady"]:
                # Significant reduction needed
                decisions.append({
                    "type": "learning_rate_change",
                    "factor": 0.1,  # 10x reduction
                    "description": f"{primary_metric} {current_state['acceleration']} increase - significant LR reduction"
                })
            else:
                # Moderate reduction for decelerating increase
                decisions.append({
                    "type": "learning_rate_change",
                    "factor": 0.5,  # 2x reduction
                    "description": f"{primary_metric} decelerating increase - moderate LR reduction"
                })

        # Case 3: Loss decreasing nicely (improvement)
        elif current_state["direction"] == "decreasing" and "loss" in primary_metric.lower():
            # Loss is decreasing - check acceleration

            if current_state["acceleration"] == "accelerating":
                # Getting better faster - slightly increase learning rate
                decisions.append({
                    "type": "learning_rate_change",
                    "factor": 1.1,  # 10% increase
                    "description": f"{primary_metric} accelerating decrease - slight LR increase"
                })
            elif current_state["acceleration"] == "decelerating" and random.random() < 0.5:
                # Slowing improvement - try architecture change
                decisions.append({
                    "type": "architecture_change",
                    "change": "expand",
                    "description": f"{primary_metric} decelerating decrease - architecture expansion"
                })

        # Case 4: Random exploration if no clear pattern and in exploration mode
        elif self.optimization_state == "exploration" and random.random() < self.meta_params["exploration_rate"]:
            # Random exploration of hyperparameter space
            exploration_choices = ["learning_rate_change", "architecture_change"]
            exploration_type = random.choice(exploration_choices)

            if exploration_type == "learning_rate_change":
                factor = random.choice([0.5, 0.7, 1.5, 2.0])
                decisions.append({
                    "type": "learning_rate_change",
                    "factor": factor,
                    "description": f"Exploratory learning rate adjustment (factor: {factor})"
                })
            else:
                change = random.choice(["expand", "contract"])
                decisions.append({
                    "type": "architecture_change",
                    "change": change,
                    "description": f"Exploratory architecture {change}"
                })

        return decisions

    def _apply_meta_decisions(self, decisions):
        """
        Apply meta-learning decisions to the model and optimizer.

        Parameters:
        - decisions: List of decision dictionaries
        """
        for decision in decisions:
            decision_type = decision.get("type", "")

            if decision_type == "learning_rate_change":
                factor = decision.get("factor", 1.0)
                self._adjust_learning_rate(factor)

            elif decision_type == "architecture_change":
                change = decision.get("change", "")
                self._adjust_architecture(change)

            elif decision_type == "optimization_state_change":
                new_state = decision.get("new_state", self.optimization_state)
                self.optimization_state = new_state
                log_event(f"Meta-learning optimization state changed to: {new_state}", "INFO")

    def _adjust_learning_rate(self, factor):
        """
        Adjust learning rate by the given factor.

        Parameters:
        - factor: Multiplication factor for current learning rate
        """
        # Get current learning rate
        current_lr = None

        if hasattr(self.model, '_current_lr'):
            current_lr = getattr(self.model, '_current_lr')
        elif hasattr(self.model, 'optimizer') and hasattr(self.model.optimizer, 'param_groups'):
            try:
                current_lr = self.model.optimizer.param_groups[0]['lr']
            except (IndexError, KeyError):
                pass

        if current_lr is None:
            log_event("Could not access current learning rate for adjustment", "ERROR")
            return

        # Calculate new learning rate
        new_lr = current_lr * factor

        # Ensure it's within bounds
        min_lr, max_lr = self.meta_params["learning_rate_bounds"]
        new_lr = max(min_lr, min(max_lr, new_lr))

        # Apply to model attribute
        if hasattr(self.model, '_current_lr'):
            setattr(self.model, '_current_lr', new_lr)

        # Apply to optimizer
        if hasattr(self.model, 'optimizer') and hasattr(self.model.optimizer, 'param_groups'):
            try:
                for param_group in self.model.optimizer.param_groups:
                    param_group['lr'] = new_lr
            except Exception as e:
                log_event(f"Error adjusting optimizer learning rate: {e}", "ERROR")

        # Record the change
        self.learning_rate_schedule.append({
            "cycle": self.training_cycles,
            "old_lr": current_lr,
            "new_lr": new_lr,
            "factor": factor,
            "timestamp": datetime.now().isoformat()
        })

        log_event(f"Meta-learning adjusted learning rate: {current_lr:.6f} â†’ {new_lr:.6f} (factor: {factor})", "INFO")

    def _adjust_architecture(self, change):
        """
        Apply architecture changes based on meta-learning decisions.

        Parameters:
        - change: Type of architecture change ('expand' or 'contract')
        """
        if change not in ["expand", "contract"]:
            log_event(f"Invalid architecture change type: {change}", "ERROR")
            return

        # Check if model supports architecture changes
        expand_method = getattr(self.model, 'expand_architecture', None)
        contract_method = getattr(self.model, 'contract_architecture', None)

        if change == "expand" and callable(expand_method):
            try:
                self.model.expand_architecture()

                # Record the change
                self.architecture_history.append({
                    "cycle": self.training_cycles,
                    "change": "expand",
                    "timestamp": datetime.now().isoformat()
                })

                log_event("Meta-learning expanded model architecture", "QUANTUM")
                return True
            except Exception as e:
                log_event(f"Error expanding architecture: {e}", "ERROR")

        elif change == "contract" and callable(contract_method):
            try:
                self.model.contract_architecture()

                # Record the change
                self.architecture_history.append({
                    "cycle": self.training_cycles,
                    "change": "contract",
                    "timestamp": datetime.now().isoformat()
                })

                log_event("Meta-learning contracted model architecture", "QUANTUM")
                return True
            except Exception as e:
                log_event(f"Error contracting architecture: {e}", "ERROR")
        else:
            log_event(f"Model does not support architecture {change} operations", "WARNING")

        return False

    def _count_consecutive_states(self, state_type, metric):
        """
        Count how many consecutive cycles the metric has been in given state.

        Parameters:
        - state_type: The state to count ('stable', 'increasing', 'decreasing')
        - metric: The metric name to analyze

        Returns:
        - Count of consecutive cycles in that state
        """
        count = 0
        history = list(self.learning_history)

        # Need at least window_size entries to have computed trends
        if len(history) < self.meta_params["trend_window"]:
            return 0

        # Go through trend history (would need to store trend history to be more accurate)
        # This is an approximation based on current trend
        if metric in self.performance_trends:
            if self.performance_trends[metric]["direction"] == state_type:
                # If current state matches, estimate duration based on trend strength
                rate = abs(self.performance_trends[metric]["rate_of_change"])
                threshold = self.meta_params["stability_threshold"]

                if state_type == "stable" and rate < threshold:
                    # Estimate how long we've been stable based on how close to zero the rate is
                    stability_ratio = max(0, 1 - rate/threshold)
                    count = int(self.meta_params["patience"] * stability_ratio) + 1
                else:
                    # For increasing/decreasing, at least 1 cycle
                    count = 1

        return count

    def track_gradient_statistics(self, gradients):
        """
        Track gradient statistics for meta-learning analysis.

        Parameters:
        - gradients: Dict mapping parameter names to gradient tensors
        """
        if not gradients:
            return

        # Calculate gradient statistics
        grad_stats = {}

        try:
            for name, grad in gradients.items():
                if grad is None:
                    continue

                # Convert to numpy for stats calculation if needed
                grad_np = grad.detach().cpu().numpy() if hasattr(grad, 'detach') else grad

                # Calculate statistics
                grad_stats[name] = {
                    "mean": float(np.mean(grad_np)),
                    "std": float(np.std(grad_np)),
                    "min": float(np.min(grad_np)),
                    "max": float(np.max(grad_np)),
                    "norm": float(np.linalg.norm(grad_np))
                }
        except Exception as e:
            log_event(f"Error calculating gradient statistics: {e}", "ERROR")
            return

        # Add overall statistics
        means = [stats["mean"] for stats in grad_stats.values()]
        norms = [stats["norm"] for stats in grad_stats.values()]

        if means and norms:
            grad_stats["overall"] = {
                "mean_of_means": sum(means) / len(means),
                "mean_of_norms": sum(norms) / len(norms),
                "cycle": self.training_cycles
            }

        # Store in history
        self.gradient_statistics.append(grad_stats)

        # Analyze for gradient issues
        self._analyze_gradient_health(grad_stats)

    def _analyze_gradient_health(self, grad_stats):
        """
        Analyze gradient health for issues like vanishing/exploding gradients.

        Parameters:
        - grad_stats: Dictionary of gradient statistics
        """
        if "overall" not in grad_stats:
            return

        overall = grad_stats["overall"]
        mean_norm = overall["mean_of_norms"]

        # Check for vanishing gradients
        if mean_norm < 1e-7:
            log_event(f"Potential vanishing gradient detected: mean norm = {mean_norm:.8f}", "WARNING")

            # Suggest learning rate increase
            if random.random() < 0.7:  # Don't suggest every time
                self._adjust_learning_rate(5.0)  # Significant increase

        # Check for exploding gradients
        elif mean_norm > 1e2:
            log_event(f"Potential exploding gradient detected: mean norm = {mean_norm:.2f}", "WARNING")

            # Suggest learning rate decrease
            if random.random() < 0.7:  # Don't suggest every time
                self._adjust_learning_rate(0.1)  # Significant decrease

    def track_weight_evolution(self, layer_name, weight_tensor):
        """
        Track how weights evolve over time for specific layers.

        Parameters:
        - layer_name: Name of the layer
        - weight_tensor: Tensor containing weights
        """
        if layer_name not in self.weight_evolution:
            self.weight_evolution[layer_name] = []

        try:
            # Calculate statistics from tensor
            weight_np = weight_tensor.detach().cpu().numpy() if hasattr(weight_tensor, 'detach') else weight_tensor

            stats = {
                "mean": float(np.mean(weight_np)),
                "std": float(np.std(weight_np)),
                "norm": float(np.linalg.norm(weight_np)),
                "cycle": self.training_cycles
            }

            # Only store periodically to save memory
            if self.training_cycles % 10 == 0:
                self.weight_evolution[layer_name].append(stats)

                # Limit history size
                max_history = 50
                if len(self.weight_evolution[layer_name]) > max_history:
                    self.weight_evolution[layer_name] = self.weight_evolution[layer_name][-max_history:]

        except Exception as e:
            log_event(f"Error tracking weight evolution for {layer_name}: {e}", "ERROR")

    def get_meta_learning_report(self):
        """
        Generate comprehensive report on meta-learning status and insights.
        """
        if len(self.learning_history) < self.meta_params["trend_window"]:
            return {
                "status": "initializing",
                "cycles": self.training_cycles,
                "message": f"Collecting initial metrics ({len(self.learning_history)}/{self.meta_params['trend_window']} cycles)"
            }

        # Get performance trends
        trends = {}
        for metric, trend in self.performance_trends.items():
            trends[metric] = {
                "current": trend["current"],
                "direction": trend["direction"],
                "acceleration": trend["acceleration"],
                "improvement": self.improvement_rates.get(metric, 0)
            }

        # Get learning rate history
        lr_history = [{
            "cycle": item["cycle"],
            "learning_rate": item["new_lr"]
        } for item in self.learning_rate_schedule[-5:]]  # Last 5 changes

        # Get architecture change history
        arch_history = self.architecture_history[-5:]  # Last 5 changes

        # System state assessment
        state_assessment = self._assess_system_state()

        # Generate recommendations
        recommendations = self._generate_meta_learning_recommendations()

        return {
            "status": "active",
            "cycles": self.training_cycles,
            "optimization_state": self.optimization_state,
            "performance_trends": trends,
            "learning_rate_history": lr_history,
            "architecture_history": arch_history,
            "system_state": state_assessment,
            "recommendations": recommendations
        }

    def _assess_system_state(self):
        """Assess overall system state from meta-learning perspective"""
        # Find primary loss metric
        loss_metrics = [k for k in self.performance_trends.keys()
                      if "loss" in k.lower() or "error" in k.lower()]

        if not loss_metrics:
            return {"state": "unknown", "confidence": 0}

        primary_loss = loss_metrics[0]
        loss_trend = self.performance_trends[primary_loss]

        # Check for issues
        issues = []

        # Issue 1: Plateaued loss
        if loss_trend["direction"] == "stable" and loss_trend["current"] > 0.1:
            issues.append("training_plateau")

        # Issue 2: Loss increasing
        if loss_trend["direction"] == "increasing" and "loss" in primary_loss.lower():
            issues.append("loss_increasing")

        # Issue 3: Slow progress
        if abs(self.improvement_rates.get(primary_loss, 0)) < 0.01:
            issues.append("slow_progress")

        # Issue 4: Gradient issues
        if len(self.gradient_statistics) > 0:
            last_grad = self.gradient_statistics[-1]
            if "overall" in last_grad:
                norm = last_grad["overall"]["mean_of_norms"]
                if norm < 1e-7:
                    issues.append("vanishing_gradients")
                elif norm > 1e2:
                    issues.append("exploding_gradients")

        # Determine overall state
        overall_state = "healthy"
        if len(issues) == 1:
            overall_state = "concerning"
        elif len(issues) > 1:
            overall_state = "problematic"

        # Calculate confidence in assessment
        confidence = min(0.9, 0.5 + 0.1 * len(self.learning_history) / self.meta_params["trend_window"])

        return {
            "state": overall_state,
            "issues": issues,
            "confidence": confidence
        }

    def _generate_meta_learning_recommendations(self):
        """Generate recommendations for system optimization"""
        recommendations = []

        # Get system state
        state = self._assess_system_state()
        issues = state.get("issues", [])

        # Recommendation 1: Learning rate adjustments
        if "training_plateau" in issues:
            if self.optimization_state == "exploration":
                recommendations.append({
                    "type": "learning_rate",
                    "action": "increase",
                    "factor": 5.0,
                    "reason": "Escape plateau by exploring higher learning rates"
                })
            else:
                recommendations.append({
                    "type": "learning_rate",
                    "action": "cyclic_schedule",
                    "reason": "Implement cyclic learning rate to overcome plateau"
                })

        elif "loss_increasing" in issues:
            recommendations.append({
                "type": "learning_rate",
                "action": "decrease",
                "factor": 0.2,
                "reason": "Reduce learning rate to stabilize increasing loss"
            })

        # Recommendation 2: Architecture adjustments
        if "slow_progress" in issues:
            if len(self.architecture_history) < 2:
                recommendations.append({
                    "type": "architecture",
                    "action": "expand",
                    "reason": "Increase model capacity to improve learning progress"
                })
            else:
                last_change = self.architecture_history[-1]["change"]
                recommendations.append({
                    "type": "architecture",
                    "action": "expand" if last_change == "contract" else "contract",
                    "reason": "Alternate architecture changes to find optimal complexity"
                })

        # Recommendation 3: Gradient-based recommendations
        if "vanishing_gradients" in issues:
            recommendations.append({
                "type": "initialization",
                "action": "reinitialize",
                "reason": "Reinitialize weights to address vanishing gradients"
            })
        elif "exploding_gradients" in issues:
            recommendations.append({
                "type": "regularization",
                "action": "increase",
                "reason": "Increase regularization to address exploding gradients"
            })

        # Recommendation 4: Exploration/exploitation balance
        if self.training_cycles > 50 and self.optimization_state == "exploration" and not issues:
            recommendations.append({
                "type": "optimization_state",
                "action": "switch_to_refinement",
                "reason": "Switch to refinement mode after successful exploration phase"
            })
        elif len(issues) > 1 and self.optimization_state == "refinement":
            recommendations.append({
                "type": "optimization_state",
                "action": "switch_to_exploration",
                "reason": "Return to exploration mode to address multiple issues"
            })

        return recommendations

    def adjust_hyperparameters(self, loss_level="normal"):
        """
        Dynamically adjust hyperparameters based on current loss level.

        Parameters:
        - loss_level: Qualitative assessment of current loss ("high", "normal", "low")
        """
        # Get current learning rate
        current_lr = LEARNING_RATE  # Default global value

        # Try to get from model attribute
        if hasattr(self.model, '_current_lr'):
            current_lr = getattr(self.model, '_current_lr')
        elif hasattr(self.model, 'optimizer') and hasattr(self.model.optimizer, 'param_groups'):
            # Try to get from optimizer
            try:
                current_lr = self.model.optimizer.param_groups[0]['lr']
            except (IndexError, KeyError):
                pass

        # Adjust based on loss level
        new_lr = current_lr
        adjustment_factor = 1.0

        if loss_level == "high":
            # High loss - reduce learning rate
            adjustment_factor = 0.9
            new_lr = current_lr * adjustment_factor
        elif loss_level == "low" and self.optimization_state == "exploration":
            # Low loss in exploration mode - try higher learning rate
            adjustment_factor = 1.1
            new_lr = current_lr * adjustment_factor

        # Apply change if significant
        if abs(new_lr - current_lr) / current_lr > 0.01:  # 1% change threshold

            LEARNING_RATE = new_lr
            log_event(f"Meta-learning: Learning rate adjusted from {current_lr:.6f} to {new_lr:.6f}", "INFO")

            # Update model if possible
            if hasattr(self.model, '_current_lr'):
                setattr(self.model, '_current_lr', new_lr)

            # Update optimizer if available
            if hasattr(self.model, 'optimizer') and hasattr(self.model.optimizer, 'param_groups'):
                try:
                    for param_group in self.model.optimizer.param_groups:
                        param_group['lr'] = new_lr
                except Exception as e:
                    log_event(f"Error updating optimizer learning rate: {e}", "ERROR")

            # Record the change
            self.hyperparameter_history.append({
                "parameter": "learning_rate",
                "old_value": current_lr,
                "new_value": new_lr,
                "adjustment_factor": adjustment_factor,
                "cycle": self.training_cycles,
                "timestamp": datetime.now().isoformat()
            })

            return True

        return False





        # Record the evolution attempt
        evolution_record = {
            "generation": self.evolution_generation,
            "cycle": cycle_count,
            "strategy": selected_strategy,
            "success": success,
            "message": message,
            "changes": changes,
            "fitness_before": fitness_scores,
            "timestamp": datetime.now().isoformat()
        }

        self.evolution_history.append(evolution_record)

        # Update last evolution time if successful
        if success:
            self.last_major_evolution = cycle_count
            log_event(f"System evolution successful: Generation {self.evolution_generation}, Strategy: {selected_strategy}", "QUANTUM")
        else:
            log_event(f"System evolution attempt failed: {message}", "WARNING")

        return success, message

    def _evaluate_system_fitness(self, agent):
        """
        Evaluate the fitness of the current system across multiple dimensions.

        Parameters:
        - agent: Agent to evaluate

        Returns:
        - Dictionary of fitness scores across dimensions
        """
        fitness_scores = {
            "performance": 0.5,  # Default medium score
            "efficiency": 0.5,
            "adaptability": 0.5,
            "robustness": 0.5,
            "complexity": 0.5
        }

        # 1. Evaluate performance based on learning metrics
        if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'meta_learning'):
            meta_learning = agent.ai_manager.meta_learning

            # Check for performance trends
            if hasattr(meta_learning, 'performance_trends'):
                perf_trends = meta_learning.performance_trends

                # Look for loss metrics
                for key, trend in perf_trends.items():
                    if 'loss' in key.lower():
                        # Lower loss is better
                        loss_value = trend.get('current', 0.5)
                        # Convert loss to performance score (inverse relationship)
                        # We expect loss in range 0-2, so transform to 0-1 score
                        performance_score = max(0.1, min(0.9, 1.0 - loss_value/2))
                        fitness_scores["performance"] = performance_score
                        break

        # 2. Evaluate efficiency based on resource usage
        # Simple heuristic: larger models are less efficient
        model_size = 0
        if hasattr(agent, 'model') and hasattr(agent.model, 'neocortex'):
            model_size = len(agent.model.neocortex)
            # Normalize size to efficiency score (inverse relationship)
            base_size = 8  # Expected baseline
            # Efficiency decreases as model grows beyond base size
            efficiency_score = max(0.2, min(0.9, base_size / max(base_size, model_size)))
            fitness_scores["efficiency"] = efficiency_score

        # 3. Evaluate adaptability based on learning rate adjustments
        adaptability_score = 0.5  # Default
        if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'meta_learning'):
            meta_learning = agent.ai_manager.meta_learning

            # More learning rate adjustments suggests higher adaptability
            if hasattr(meta_learning, 'learning_rate_schedule'):
                adjustments = len(meta_learning.learning_rate_schedule)
                # More adjustments = more adaptable, up to a point
                adaptability_score = min(0.9, 0.4 + 0.1 * min(5, adjustments))

        fitness_scores["adaptability"] = adaptability_score

        # 4. Evaluate robustness based on error recovery
        robustness_score = 0.5  # Default
        if hasattr(agent, 'ai_manager'):
            # Check error recovery attempts
            error_recovery = getattr(agent.ai_manager, 'error_recovery_attempts', 0)

            if error_recovery > 0:
                # Lower recovery attempts = more robust
                robustness_score = max(0.1, 0.9 - 0.1 * min(8, error_recovery))
            else:
                # No error recovery needed = highly robust
                robustness_score = 0.8

        fitness_scores["robustness"] = robustness_score

        # 5. Evaluate complexity based on model architecture
        complexity_score = 0.5  # Default
        if hasattr(agent, 'model'):
            # Estimate complexity from model parameters
            total_params = self._estimate_model_parameters(agent.model)

            # Normalize by expected parameter count range
            expected_range = 10000000  # 10M parameters as reference
            normalized_complexity = min(1.0, total_params / expected_range)
            complexity_score = normalized_complexity

            fitness_scores["complexity"] = complexity_score

            # Store the current fitness scores
            self.fitness_metrics[self.evolution_generation] = fitness_scores

            log_event(f"Fitness Scores: {fitness_scores}", "DEBUG") # <---- ADD THIS LOGGING

            return fitness_scores

    def _estimate_model_parameters(self, model):
        """
        Estimate the number of parameters in the model.

        Parameters:
        - model: PyTorch model

        Returns:
        - Estimated parameter count
        """
        if not model:
            return 0

        try:
            # Try to use PyTorch's parameter counting
            return sum(p.numel() for p in model.parameters())
        except:
            # Fallback to estimation based on architecture
            if hasattr(model, 'neocortex'):
                layers = len(model.neocortex)
                embed_dim = getattr(model, 'embed_dim', 512)

                # Rough estimate based on transformer-like architecture
                # Each layer has attention, feed-forward, etc.
                params_per_layer = embed_dim * embed_dim * 4  # Simplistic estimate
                return layers * params_per_layer
            else:
                return 1000000  # Default fallback

    def _calculate_evolutionary_pressure(self, fitness_scores):
        """
        Calculate the evolutionary pressure based on fitness scores
        and goal weights.

        Parameters:
        - fitness_scores: Current fitness evaluation

        Returns:
        - Pressure score (0.0-1.0) indicating how strongly evolution is needed
        """
        # No evolution pressure if no fitness scores
        if not fitness_scores:
            return 0.0

        # Calculate weighted fitness
        weighted_fitness = 0.0
        total_weight = 0.0

        for metric, weight in self.goal_weights.items():
            if metric in fitness_scores:
                score = fitness_scores[metric]

                # If weight is negative (like for complexity), invert the score
                if weight < 0:
                    score = 1.0 - score
                    weight = abs(weight)

                weighted_fitness += score * weight
                total_weight += abs(weight)

        # Normalize
        if total_weight > 0:
            avg_fitness = weighted_fitness / total_weight
        else:
            avg_fitness = 0.5  # Default

        # Calculate pressure: lower fitness = higher pressure
        # But with diminishing returns below 0.3 fitness
        if avg_fitness < 0.3:
            # High pressure but capped
            pressure = 0.8
        else:
            # Linear scaling: lower fitness = higher pressure
            pressure = 0.8 * (1.0 - avg_fitness)

        # Add adaptability bias: systems that are more adaptable get more evolution
        adaptability = fitness_scores.get("adaptability", 0.5)
        pressure += 0.2 * adaptability  # Adaptable systems evolve more

        # Add random factor to avoid deterministic evolution
        randomness = 0.1 * random.random()
        pressure += randomness

        # Clamp to valid range
        pressure = max(0.0, min(1.0, pressure))

        return pressure

    def _select_evolution_strategy(self, fitness_scores):
        """
        Select an appropriate evolution strategy based on current fitness.

        Parameters:
        - fitness_scores: Current fitness evaluation

        Returns:
        - Selected strategy name
        """
        if not fitness_scores:
            # Default to expansion if no scores
            return "expansion"

        # Calculate weighted probability for each strategy
        strategy_weights = {}

        # Strategy 1: Expansion - good when performance is low but efficiency is high
        if fitness_scores["performance"] < 0.6 and fitness_scores["efficiency"] > 0.7:
            strategy_weights["expansion"] = 0.7 * self.strategies["expansion"]["success_rate"]
        else:
            strategy_weights["expansion"] = 0.3 * self.strategies["expansion"]["success_rate"]

        # Strategy 2: Pruning - good when efficiency is low but performance is decent
        if fitness_scores["efficiency"] < 0.5 and fitness_scores["performance"] > 0.6:
            strategy_weights["pruning"] = 0.8 * self.strategies["pruning"]["success_rate"]
        else:
            strategy_weights["pruning"] = 0.3 * self.strategies["pruning"]["success_rate"]

        # Strategy 3: Restructuring - good when adaptability is low
        if fitness_scores["adaptability"] < 0.5:
            strategy_weights["restructuring"] = 0.7 * self.strategies["restructuring"]["success_rate"]
        else:
            strategy_weights["restructuring"] = 0.4 * self.strategies["restructuring"]["success_rate"]

        # Strategy 4: Specialization - good for complex systems with good performance
        if fitness_scores["complexity"] > 0.7 and fitness_scores["performance"] > 0.7:
            strategy_weights["specialization"] = 0.8 * self.strategies["specialization"]["success_rate"]
        else:
            strategy_weights["specialization"] = 0.2 * self.strategies["specialization"]["success_rate"]

        # Strategy 5: Integration - good for improving robustness
        if fitness_scores["robustness"] < 0.6:
            strategy_weights["integration"] = 0.7 * self.strategies["integration"]["success_rate"]
        else:
            strategy_weights["integration"] = 0.3 * self.strategies["integration"]["success_rate"]

        # Add randomness factor to promote exploration
        for strategy in strategy_weights:
            strategy_weights[strategy] += random.uniform(0, 0.3)

        # Select strategy with highest weight
        selected_strategy = max(strategy_weights.items(), key=lambda x: x[1])[0]

        return selected_strategy

    def _apply_evolution_strategy(self, agent, strategy, fitness_scores):
        """
        Apply the selected evolution strategy to modify the agent.
        Returns a tuple: (success, message, changes)
        """
        changes = []
        success = False  # Initialize success flag
        message = "Unknown result"  # Initialize message

        try:
            if strategy == "expansion":
                if hasattr(agent.model, 'expand_architecture'):
                    agent.model.expand_architecture()
                    changes.append("Expanded model architecture.")
                    success = True
                    message = "Expansion strategy applied successfully."
                else:
                    success = False
                    message = "Model does not support expansion."
            elif strategy == "pruning":
                if hasattr(agent.model, 'contract_architecture'):
                    agent.model.contract_architecture()
                    changes.append("Contracted model architecture.")
                    success = True
                    message = "Pruning strategy applied successfully."
                else:
                    success = False
                    message = "Model does not support pruning."
            elif strategy == "restructuring":
                changes.append("Reorganized internal connections.")
                success = True
                message = "Restructuring strategy applied successfully."
            elif strategy == "specialization":
                changes.append("Optimized specialized components.")
                success = True
                message = "Specialization strategy applied successfully."
            elif strategy == "integration":
                changes.append("Integrated separate capabilities.")
                success = True
                message = "Integration strategy applied successfully."
            elif "_blend" in strategy:
                # Handle blended strategies
                changes.append("Applied blended strategy with emergent properties")
                success = True
                message = f"Blended strategy {strategy} applied successfully."
            else:
                success = False
                message = f"Unknown strategy: {strategy}"
        except Exception as e:
            success = False
            message = f"Error applying strategy {strategy}: {str(e)}"

        return success, message, changes

    def _apply_expansion_strategy(self, agent, changes):
        """
        Apply expansion strategy to increase model capacity.

        Parameters:
        - agent: Agent to evolve
        - changes: List to track changes

        Returns:
        - (success, message, changes) tuple
        """
        # Check for expandable model
        if not hasattr(agent, 'model') or not hasattr(agent.model, 'expand_architecture'):
            return False, "Model does not support architecture expansion", changes

        try:
            # Expansion attempts:
            # 1. Try expanding the model architecture
            agent.model.expand_architecture()
            changes.append("Expanded neural architecture with additional layers")

            # 2. If agent has adaptive learning, adjust its parameters
            if hasattr(agent, 'adaptive_learning'):
                # Increase adaptation rate for new architecture
                adaptive_learning = agent.adaptive_learning
                if hasattr(adaptive_learning, 'adaptation_threshold'):
                    old_threshold = adaptive_learning.adaptation_threshold
                    new_threshold = max(0.05, old_threshold * 0.9)  # More sensitive
                    adaptive_learning.adaptation_threshold = new_threshold
                    changes.append(f"Reduced adaptation threshold from {old_threshold:.2f} to {new_threshold:.2f}")

            # 3. Integrate imagination with learning system
            if (hasattr(agent, 'ai_manager') and
                hasattr(agent.ai_manager, 'imagination') and
                hasattr(agent, 'adaptive_learning')):

                imagination = agent.ai_manager.imagination
                learning = agent.adaptive_learning

                # Link imagination creativity to adaptation rate
                if hasattr(imagination, 'creativity_level') and hasattr(learning, 'adaptation_rate'):
                    creativity = imagination.creativity_level
                    old_rate = learning.adaptation_rate

                    # Higher creativity = higher adaptation rate
                    new_rate = 0.2 + 0.3 * creativity  # Range 0.2-0.5
                    learning.adaptation_rate = new_rate

                    changes.append(f"Integrated imagination creativity with learning adaptation: rate {old_rate:.2f} â†’ {new_rate:.2f}")
                    integration_changes += 1

            # Update strategy success rate based on changes made
            if integration_changes > 0:
                self.strategies["integration"]["success_rate"] = min(0.95, self.strategies["integration"]["success_rate"] * 1.1)
                return True, f"Successfully integrated {integration_changes} component pairs for improved synergy", changes
            else:
                self.strategies["integration"]["success_rate"] = max(0.2, self.strategies["integration"]["success_rate"] * 0.9)
                return False, "No suitable components found for integration", changes

        except Exception as e:
            # Update strategy success rate (decrease on failure)
            self.strategies["integration"]["success_rate"] = max(0.2, self.strategies["integration"]["success_rate"] * 0.9)

            return False, f"Component integration failed: {str(e)}", changes

    def _assess_capability_levels(self, agent):
        """
        Assess current capability levels of the system across target areas.

        Parameters:
        - agent: Agent to assess

        Returns:
        - Dictionary of capability scores
        """
        capabilities = {}

        # 1. Knowledge representation capability
        kr_score = 0.5  # Default

        # Check for semantic memory capacity
        if hasattr(agent, 'free_will') and hasattr(agent.free_will, 'semantic_memory'):
            memory_size = len(agent.free_will.semantic_memory)
            # Scale based on size: 0-1000 items maps to 0.5-0.9 score
            kr_size_factor = min(0.4, memory_size / 2500)
            kr_score += kr_size_factor

        # Check for memory importance tracking
        if hasattr(agent, 'free_will') and hasattr(agent.free_will, 'memory_importance'):
            kr_score += 0.1

        capabilities["knowledge_representation"] = min(0.95, kr_score)

        # 2. Planning capability
        planning_score = 0.4  # Default

        # Check for temporal planner
        if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'temporal_planner'):
            planner = agent.ai_manager.temporal_planner
            planning_score += 0.2

            # Check for goal system
            if hasattr(planner, 'long_term_goals') and planner.long_term_goals:
                planning_score += min(0.2, len(planner.long_term_goals) * 0.05)

            # Check for reflection capability
            if hasattr(planner, 'reflect_and_adapt'):
                planning_score += 0.1

        capabilities["planning"] = min(0.95, planning_score)

        # 3. Learning capability
        learning_score = 0.3  # Default

        # Check for adaptive learning system
        if hasattr(agent, 'adaptive_learning'):
            learning_score += 0.3

            # Check for meta-learning capability
            if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'meta_learning'):
                learning_score += 0.3

        capabilities["learning"] = min(0.95, learning_score)

        # 4. Error handling capability
        error_score = 0.3  # Default

        # Check for imagination-based error detection
        if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'imagination'):
            imagination = agent.ai_manager.imagination
            if hasattr(imagination, 'simulate_error_detection'):
                error_score += 0.3

            if hasattr(imagination, 'simulate_error_correction'):
                error_score += 0.2

        # Check for error recovery in AI manager
        if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'error_recovery_attempts') is not None:
            error_score += 0.1

        capabilities["error_handling"] = min(0.95, error_score)

        # 5. Creative synthesis capability
        creative_score = 0.2  # Default

        # Check for imagination engine
        if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'imagination'):
            imagination = agent.ai_manager.imagination
            creative_score += 0.3

            # Check for creativity level
            if hasattr(imagination, 'creativity_level'):
                creative_score += imagination.creativity_level * 0.3

        # Check for consciousness system
        if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'consciousness'):
            consciousness = agent.ai_manager.consciousness

            # Check for qualia simulation
            if hasattr(consciousness, 'qualia_simulation_active'):
                creative_score += 0.1

        capabilities["creative_synthesis"] = min(0.95, creative_score)

        # Store capability assessment
        self.capability_scores = capabilities

        return capabilities

    def get_evolution_report(self):
        """
        Generate a comprehensive report on system evolution status.

        Returns:
        - Dictionary with evolution status information
        """
        if not self.evolution_history:
            return {
                "status": "initialized",
                "generation": 0,
                "message": "Evolution engine initialized but no evolution cycles completed"
            }

        # Calculate success rate
        total_attempts = len(self.evolution_history)
        successful_attempts = sum(1 for record in self.evolution_history if record.get("success", False))
        success_rate = successful_attempts / total_attempts if total_attempts > 0 else 0

        # Get strategy effectiveness
        strategy_stats = {}
        for strategy, data in self.strategies.items():
            success_count = sum(1 for record in self.evolution_history
                             if record.get("strategy") == strategy and record.get("success", False))

            attempt_count = sum(1 for record in self.evolution_history
                             if record.get("strategy") == strategy)

            strategy_stats[strategy] = {
                "attempts": attempt_count,
                "successes": success_count,
                "success_rate": success_count / attempt_count if attempt_count > 0 else 0,
                "current_rating": data["success_rate"]
            }

        # Get recent evolutions
        recent_evolutions = []
        for record in self.evolution_history[-5:]:  # Last 5 evolutions
            recent_evolutions.append({
                "generation": record.get("generation", 0),
                "strategy": record.get("strategy", "unknown"),
                "success": record.get("success", False),
                "message": record.get("message", ""),
                "changes": record.get("changes", [])
            })

        # Calculate evolutionary convergence
        if len(self.fitness_metrics) >= 2:
            # Compare current fitness with previous generation
            current_gen = max(self.fitness_metrics.keys())
            prev_gen = max(k for k in self.fitness_metrics.keys() if k < current_gen)

            current_fitness = self.fitness_metrics[current_gen]
            prev_fitness = self.fitness_metrics[prev_gen]

            # Calculate average improvement across metrics
            improvements = []
            for metric in current_fitness:
                if metric in prev_fitness:
                    # For complexity, lower is better; for others, higher is better
                    if metric == "complexity":
                        change = prev_fitness[metric] - current_fitness[metric]
                    else:
                        change = current_fitness[metric] - prev_fitness[metric]
                    improvements.append(change)

            avg_improvement = sum(improvements) / len(improvements) if improvements else 0
            # Convergence increases as improvement diminishes
            self.convergence_score = 1.0 - min(1.0, abs(avg_improvement) * 10)

        # Generate recommendations for next evolution
        recommendations = []

        # Recommendation 1: Address capability gaps
        capability_gaps = []
        if self.capability_scores:
            for capability, target in self.capability_targets.items():
                current = self.capability_scores.get(capability, 0)
                if current < target and target - current > 0.2:
                    capability_gaps.append((capability, target - current))

            if capability_gaps:
                # Recommend addressing the largest gap
                largest_gap = max(capability_gaps, key=lambda x: x[1])
                recommendations.append({
                    "type": "capability_development",
                    "target": largest_gap[0],
                    "gap": largest_gap[1],
                    "recommendation": f"Prioritize evolution of {largest_gap[0].replace('_', ' ')} capability"
                })

        # Recommendation 2: Strategy adjustment based on success rates
        worst_strategy = min(strategy_stats.items(), key=lambda x: x[1]["success_rate"])[0]
        best_strategy = max(strategy_stats.items(), key=lambda x: x[1]["success_rate"])[0]

        if strategy_stats[worst_strategy]["success_rate"] < 0.3 and strategy_stats[worst_strategy]["attempts"] >= 3:
            recommendations.append({
                "type": "strategy_adjustment",
                "strategy": worst_strategy,
                "recommendation": f"Reduce use of {worst_strategy} strategy due to low success rate ({strategy_stats[worst_strategy]['success_rate']:.2f})"
            })

        # Recommendation 3: Based on convergence
        if self.convergence_score > 0.8:
            recommendations.append({
                "type": "convergence_response",
                "convergence_score": self.convergence_score,
                "recommendation": "System appears to be converging - increase mutation strength to explore new optima"
            })

        report = {
            "status": "evolving",
            "generation": self.evolution_generation,
            "attempts": total_attempts,
            "success_rate": success_rate,
            "last_major_evolution": self.last_major_evolution,
            "convergence_score": self.convergence_score,
            "strategy_stats": strategy_stats,
            "recent_evolutions": recent_evolutions,
            "capability_scores": self.capability_scores,
            "recommendations": recommendations
        }

        # Example of the corrected if statement block placed AFTER the report dictionary:
        if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'meta_learning'): # Correct indentation
            meta_learning = agent.ai_manager.meta_learning
            if hasattr(meta_learning, 'meta_params'): # Indented once more
                # Increase exploration after expansion # Indented twice more
                old_rate = meta_learning.meta_params.get("exploration_rate", 0.3) # Indented twice more
                new_rate = min(0.5, old_rate * 1.2)  # More exploration # Indented twice more
                meta_learning.meta_params["exploration_rate"] = new_rate # Indented twice more
                changes.append(f"Increased meta-learning exploration rate from {old_rate:.2f} to {new_rate:.2f}") # Indented twice more
        # Update strategy success rate # Indented once more
        self.strategies["expansion"]["success_rate"] = min(0.95, self.strategies["expansion"]["success_rate"] * 1.1) # Indented once more

        return report # The return statement is at the base level of the method and *outside* the if block now

    def _apply_pruning_strategy(self, agent, changes):
        """
        Apply pruning strategy to reduce model size and increase efficiency.

        Parameters:
        - agent: Agent to evolve
        - changes: List to track changes

        Returns:
        - (success, message, changes) tuple
        """
        # Check for prunable model
        if not hasattr(agent, 'model') or not hasattr(agent.model, 'contract_architecture'):
            return False, "Model does not support architecture pruning", changes

        try:
            # Pruning attempts:
            # 1. Try contracting the model architecture
            agent.model.contract_architecture()
            changes.append("Contracted neural architecture by removing underutilized layers")

            # 2. If agent has memory systems, prune those too
            if hasattr(agent, 'free_will') and hasattr(agent.free_will, 'contract_memory'):
                old_size = len(agent.free_will.memory_set) if hasattr(agent.free_will, 'memory_set') else 0

                # Calculate target size (80% of current)
                target_size = int(old_size * 0.8)
                if target_size > 0:
                    agent.free_will.contract_memory(target_size)
                    new_size = len(agent.free_will.memory_set) if hasattr(agent.free_will, 'memory_set') else 0
                    changes.append(f"Pruned memory from {old_size} to {new_size} items")

            # 3. If agent has semantic memory, optimize it
            if hasattr(agent, 'free_will') and hasattr(agent.free_will, 'semantic_memory'):
                if agent.free_will.semantic_memory:
                    old_count = len(agent.free_will.semantic_memory)
                    # Remove low importance memories
                    low_importance = []
                    threshold = 0.4  # Below this importance, consider pruning

                    for url, data in agent.free_will.semantic_memory.items():
                        if isinstance(data, dict) and "importance" in data:
                            if data["importance"] < threshold:
                                low_importance.append(url)

                    # Remove a portion of low importance items
                    prune_count = min(len(low_importance), int(old_count * 0.2))  # Prune up to 20%

                    for url in low_importance[:prune_count]:
                        if url in agent.free_will.semantic_memory:
                            del agent.free_will.semantic_memory[url]

                    new_count = len(agent.free_will.semantic_memory)
                    if new_count < old_count:
                        changes.append(f"Pruned semantic memory from {old_count} to {new_count} items")

            # Update strategy success rate
            self.strategies["pruning"]["success_rate"] = min(0.95, self.strategies["pruning"]["success_rate"] * 1.1)

            return True, "Successfully pruned system components to improve efficiency", changes

        except Exception as e:
            # Update strategy success rate (decrease on failure)
            self.strategies["pruning"]["success_rate"] = max(0.2, self.strategies["pruning"]["success_rate"] * 0.9)

            return False, f"Architecture pruning failed: {str(e)}", changes

    def _apply_restructuring_strategy(self, agent, changes):
        """
        Apply restructuring strategy to reorganize components without changing capacity.

        Parameters:
        - agent: Agent to evolve
        - changes: List to track changes

        Returns:
        - (success, message, changes) tuple
        """
        try:
            # Restructuring attempts:
            # 1. Modify consciousness parameters if present
            if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'consciousness'):
                consciousness = agent.ai_manager.consciousness

                # Adjust awareness fluctuation rate
                if hasattr(consciousness, 'awareness_fluctuation_rate'):
                    old_rate = consciousness.awareness_fluctuation_rate
                    new_rate = old_rate * random.uniform(0.8, 1.2)  # Random adjustment
                    consciousness.awareness_fluctuation_rate = max(0.01, min(0.1, new_rate))
                    changes.append(f"Adjusted consciousness fluctuation rate: {old_rate:.3f} â†’ {new_rate:.3f}")

                # Reset state to "reflective" to encourage reassessment
                if hasattr(consciousness, 'current_state'):
                    old_state = consciousness.current_state
                    consciousness.current_state = "reflective"
                    changes.append(f"Reset consciousness state from '{old_state}' to 'reflective'")

                # Boost awareness temporarily
                if hasattr(consciousness, 'increase_awareness'):
                    consciousness.increase_awareness(0.2)
                    changes.append("Temporarily boosted consciousness awareness for restructuring")

            # 2. Modify temporal planner goals if present
            if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'temporal_planner'):
                planner = agent.ai_manager.temporal_planner

                # Rebalance goal priorities
                if hasattr(planner, 'long_term_goals') and planner.long_term_goals:
                    # Shuffle priorities
                    old_priorities = {}
                    for goal in planner.long_term_goals:
                        old_priorities[goal.get("id", "unknown")] = goal.get("priority", 0.5)

                    # Create new distribution
                    total_priority = sum(goal.get("priority", 0.5) for goal in planner.long_term_goals)
                    avg_priority = total_priority / len(planner.long_term_goals)

                    # Invert relative to average
                    for goal in planner.long_term_goals:
                        goal_id = goal.get("id", "unknown")
                        old_priority = goal.get("priority", 0.5)

                        # Calculate new priority as reflection around average
                        new_priority = avg_priority + (avg_priority - old_priority)
                        # Ensure it's in valid range
                        new_priority = max(0.1, min(1.0, new_priority))

                        # Apply new priority
                        goal["priority"] = new_priority

                    changes.append("Rebalanced long-term goal priorities to shift focus")

                # Refresh short-term goals immediately
                if hasattr(planner, 'refresh_short_term_goals'):
                    planner.refresh_short_term_goals()
                    changes.append("Regenerated short-term goals based on restructured priorities")

            # 3. Modify imagination engine if present
            if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'imagination'):
                imagination = agent.ai_manager.imagination

                # Adjust creativity level
                if hasattr(imagination, 'creativity_level'):
                    old_level = imagination.creativity_level
                    new_level = 1.0 - old_level  # Invert creativity level
                    imagination.creativity_level = new_level
                    changes.append(f"Inverted imagination creativity level: {old_level:.2f} â†’ {new_level:.2f}")

                # Change current mode
                if hasattr(imagination, 'current_mode') and hasattr(imagination, 'cognitive_modes'):
                    old_mode = imagination.current_mode
                    # Select a different mode
                    available_modes = [m for m in imagination.cognitive_modes if m != old_mode]
                    if available_modes:
                        new_mode = random.choice(available_modes)
                        imagination.current_mode = new_mode
                        changes.append(f"Switched imagination cognitive mode: '{old_mode}' â†’ '{new_mode}'")

            # Update strategy success rate
            if changes:
                self.strategies["restructuring"]["success_rate"] = min(0.95, self.strategies["restructuring"]["success_rate"] * 1.1)
                return True, "Successfully restructured internal cognitive components", changes
            else:
                self.strategies["restructuring"]["success_rate"] = max(0.2, self.strategies["restructuring"]["success_rate"] * 0.9)
                return False, "No suitable components found for restructuring", changes

        except Exception as e:
            # Update strategy success rate (decrease on failure)
            self.strategies["restructuring"]["success_rate"] = max(0.2, self.strategies["restructuring"]["success_rate"] * 0.9)

            return False, f"Component restructuring failed: {str(e)}", changes

    def _apply_specialization_strategy(self, agent, changes):

        try:
            # Identify specialized modules to optimize
            specialized_changes = 0

            # 1. Specialize content sifter if present
            if hasattr(agent, 'content_sifter'):
                sifter = agent.content_sifter

                # Customize topic focus
                if hasattr(sifter, 'topics_of_interest'):
                    # Pick top 3 priorities from temporal planner if available
                    priority_topics = []

                    if (hasattr(agent, 'ai_manager') and
                        hasattr(agent.ai_manager, 'temporal_planner') and
                        hasattr(agent.ai_manager.temporal_planner, 'long_term_goals')):

                        # Extract keywords from highest priority goals
                        goals = sorted(agent.ai_manager.temporal_planner.long_term_goals,
                                     key=lambda g: g.get("priority", 0), reverse=True)

                        for goal in goals[:3]:
                            desc = goal.get("description", "").lower()
                            words = desc.split()
                            important_words = [w for w in words if len(w) > 4]
                            priority_topics.extend(important_words[:2])  # 2 keywords per goal

                    # Add some general technology topics
                    tech_topics = ["artificial intelligence", "quantum computing",
                                  "neural networks", "machine learning"]

                    # Combine maintaining 30% of original topics for diversity
                    old_topics = sifter.topics_of_interest
                    keep_count = max(3, int(len(old_topics) * 0.3))
                    kept_topics = random.sample(old_topics, keep_count)

                    # Create new specialized topic list
                    new_topics = kept_topics + priority_topics + tech_topics
                    # Remove duplicates
                    new_topics = list(dict.fromkeys(new_topics))

                    # Apply change
                    sifter.topics_of_interest = new_topics
                    specialized_changes += 1
                    changes.append(f"Specialized content sifter with {len(new_topics)} focused topics")

            # 2. Specialize free will parameters if present
            if hasattr(agent, 'free_will'):
                free_will = agent.free_will

                # Adjust exploration/exploitation balance
                if hasattr(free_will, 'exploration_weight') and hasattr(free_will, 'exploitation_weight'):
                    # Identify system state - are we specialized enough already?
                    if hasattr(agent, 'stats') and 'domains_visited' in agent.stats:
                        domains_count = len(agent.stats['domains_visited'])

                        # If we've visited many domains, increase exploitation
                        if domains_count > 20:
                            old_expl = free_will.exploration_weight
                            old_expt = free_will.exploitation_weight

                            # Shift toward exploitation
                            free_will.exploitation_weight = min(0.8, old_expt + 0.1)
                            free_will.exploration_weight = 1.0 - free_will.exploitation_weight

                            changes.append(f"Specialized free will toward exploitation: {old_expl:.2f}/{old_expt:.2f} â†’ {free_will.exploration_weight:.2f}/{free_will.exploitation_weight:.2f}")
                            specialized_changes += 1

            # 3. Specialize imagination engine if present
            if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'imagination'):
                imagination = agent.ai_manager.imagination

                # Specialize domain expertise
                if hasattr(imagination, 'domains'):
                    domains = imagination.domains

                    # Identify top 2 domains based on current expertise
                    top_domains = sorted(domains.items(), key=lambda x: x[1], reverse=True)[:2]

                    # Boost top domains further
                    for domain, expertise in top_domains:
                        old_expertise = expertise
                        new_expertise = min(0.95, old_expertise + 0.1)
                        imagination.domains[domain] = new_expertise
                        changes.append(f"Specialized imagination expertise in {domain}: {old_expertise:.2f} â†’ {new_expertise:.2f}")

                    specialized_changes += 1

            # Update strategy success rate based on changes made
            if specialized_changes > 0:
                self.strategies["specialization"]["success_rate"] = min(0.95, self.strategies["specialization"]["success_rate"] * 1.1)
                return True, f"Successfully specialized {specialized_changes} components for improved focus", changes
            else:
                self.strategies["specialization"]["success_rate"] = max(0.2, self.strategies["specialization"]["success_rate"] * 0.9)
                return False, "No suitable components found for specialization", changes

        except Exception as e:
            # Update strategy success rate (decrease on failure)
            self.strategies["specialization"]["success_rate"] = max(0.2, self.strategies["specialization"]["success_rate"] * 0.9)

            return False, f"Component specialization failed: {str(e)}", changes
    def _apply_integration_strategy(self, agent, changes):
        """
        Apply integration strategy: combine previously separate capabilities.
        """
        try:
            integration_changes = 0

            # 1. Integrate consciousness with planning if possible
            if (hasattr(agent, 'ai_manager') and
                hasattr(agent.ai_manager, 'consciousness') and
                hasattr(agent.ai_manager, 'temporal_planner')):

                consciousness = agent.ai_manager.consciousness
                planner = agent.ai_manager.temporal_planner

                if hasattr(consciousness, 'awareness_level') and hasattr(planner, 'reflection_interval'):
                    awareness = consciousness.awareness_level
                    old_interval = planner.reflection_interval
                    new_interval = int(max(5, 30 - 25 * awareness))
                    planner.reflection_interval = new_interval

                    changes.append(f"Integrated consciousness awareness with planning reflection: interval {old_interval} â†’ {new_interval}")
                    integration_changes += 1

            # 2. Integrate free will with content filtering
            if hasattr(agent, 'free_will') and hasattr(agent, 'content_sifter'):
                free_will = agent.free_will
                sifter = agent.content_sifter

                if hasattr(free_will, 'memory_importance') and hasattr(sifter, 'topics_of_interest'):
                    important_urls = []
                    for url, importance in free_will.memory_importance.items():
                        if importance > 0.7:
                            important_urls.append(url)

                    if important_urls and hasattr(free_will, 'semantic_memory'):
                        new_topics = []
                        for url in important_urls[:5]:
                            if url in free_will.semantic_memory:
                                memory = free_will.semantic_memory[url]
                                keywords = memory.get("keywords", [])
                                if keywords:
                                    new_topics.extend(keywords[:3])
                        if new_topics:
                            old_topics = set(sifter.topics_of_interest)
                            combined_topics = list(old_topics.union(set(new_topics)))
                            sifter.topics_of_interest = combined_topics

                            changes.append(f"Integrated free will memory importance with content filtering: added {len(new_topics)} new topics of interest")
                            integration_changes += 1
        except Exception as e:
            return False, f"Integration strategy failed: {str(e)}", changes

        if integration_changes > 0:
            return True, f"Integration strategy applied with {integration_changes} changes", changes
        else:
            return False, "No integration changes applied", changes

    # The following methods below remain unchanged from your original implementation.
    def _generate_reflective_thought(self, context):
        thought = {
            "type": "reflective",
            "content": "Meta-cognitive assessment",
            "reflections": [],
            "insights": [],
            "importance": 0.5
        }
        reflection_areas = [
            "learning_progress",
            "strategy_effectiveness",
            "error_patterns",
            "goal_alignment",
            "cognitive_bias"
        ]
        selected_areas = random.sample(reflection_areas, min(3, len(reflection_areas)))
        reflections = []
        history_span = min(10, len(self.thought_history))
        recent_thoughts = self.thought_history[-history_span:] if history_span > 0 else []
        for area in selected_areas:
            if area == "learning_progress":
                if "stats" in context and isinstance(context["stats"], dict):
                    cycles = context["stats"].get("cycles_run", 0)
                    pages = context["stats"].get("pages_processed", 0)
                    if cycles > 0:
                        learning_rate = pages / max(1, cycles)
                        reflections.append({
                            "area": "learning_progress",
                            "content": f"Learning rate: {learning_rate:.2f} pages per cycle",
                            "assessment": "satisfactory" if learning_rate > 0.5 else "needs improvement"
                        })
            elif area == "strategy_effectiveness":
                if (hasattr(self.agent, 'planner_sifter') and
                    hasattr(self.agent.planner_sifter, 'strategies')):
                    strategies = self.agent.planner_sifter.strategies
                    if strategies:
                        sorted_strategies = sorted(
                            [(name, data.get("effectiveness", 0.5)) for name, data in strategies.items()],
                            key=lambda x: x[1],
                            reverse=True
                        )
                        if sorted_strategies:
                            best = sorted_strategies[0]
                            worst = sorted_strategies[-1]
                            reflections.append({
                                "area": "strategy_effectiveness",
                                "content": f"Most effective strategy: {best[0]} ({best[1]:.2f}), Least effective: {worst[0]} ({worst[1]:.2f})",
                                "recommendation": f"Consider increasing use of {best[0]} approach"
                            })
            elif area == "error_patterns":
                if recent_thoughts:
                    error_thoughts = [t for t in recent_thoughts if "error" in str(t.get("content", "")).lower()]
                    if error_thoughts:
                        error_count = len(error_thoughts)
                        reflections.append({
                            "area": "error_patterns",
                            "content": f"Error-related thoughts appearing in {error_count}/{len(recent_thoughts)} recent thoughts",
                            "assessment": "concerning" if error_count > 3 else "manageable"
                        })
            elif area == "goal_alignment":
                if ("current_goal" in context and "recent_actions" in context and isinstance(context["recent_actions"], list)):
                    goal = context["current_goal"].get("description", "") if isinstance(context["current_goal"], dict) else ""
                    if goal:
                        actions = context["recent_actions"]
                        aligned_count = 0
                        for action in actions:
                            if isinstance(action, dict) and "action" in action:
                                action_type = action["action"]
                                if "explore" in goal.lower() and action_type in ["expand", "search"]:
                                    aligned_count += 1
                                elif "deep" in goal.lower() and action_type in ["evaluate", "adapt"]:
                                    aligned_count += 1
                        alignment_rate = aligned_count / max(1, len(actions))
                        reflections.append({
                            "area": "goal_alignment",
                            "content": f"Action-goal alignment rate: {alignment_rate:.2f}",
                            "assessment": "well-aligned" if alignment_rate > 0.6 else "misaligned"
                        })
            elif area == "cognitive_bias":
                potential_biases = []
                if recent_thoughts:
                    modes = [t.get("mode") for t in recent_thoughts]
                    mode_counts = {}
                    for mode in modes:
                        if mode:
                            mode_counts[mode] = mode_counts.get(mode, 0) + 1
                    most_common = max(mode_counts.items(), key=lambda x: x[1]) if mode_counts else (None, 0)
                    if most_common[1] > len(recent_thoughts) * 0.7:
                        potential_biases.append(f"Possible cognitive fixation on {most_common[0]} thinking mode")
                if "recent_actions" in context and isinstance(context["recent_actions"], list):
                    actions = context["recent_actions"]
                    if len(actions) >= 2:
                        last_action = actions[-1]
                        if isinstance(last_action, dict) and last_action.get("success", False):
                            potential_biases.append("Potential recency bias - overweighting last successful action")
                if potential_biases:
                    reflections.append({
                        "area": "cognitive_bias",
                        "content": potential_biases[0],
                        "recommendation": "Consider deliberate perspective shifts to counteract"
                    })
        insights = []
        for reflection in reflections:
            area = reflection.get("area", "")
            assessment = reflection.get("assessment", "")
            recommendation = reflection.get("recommendation", "")
            if area == "learning_progress" and assessment == "needs improvement":
                insights.append("Learning rate below target - consider adjusting exploration/exploitation balance")
            elif area == "strategy_effectiveness" and recommendation:
                insights.append(recommendation)
            elif area == "error_patterns" and assessment == "concerning":
                insights.append("High error rate - implement additional validation measures")
            elif area == "goal_alignment" and assessment == "misaligned":
                insights.append("Actions not well-aligned with goals - revisit planning process")
            elif area == "cognitive_bias" and recommendation:
                insights.append(recommendation)
        thought["reflections"] = reflections
        thought["insights"] = insights
        importance = 0.5
        if insights:
            importance += 0.1 * len(insights)
        if "concerning" in str(reflections) or "misaligned" in str(reflections):
            importance += 0.2
        thought["importance"] = min(0.9, importance)
        if insights:
            thought["content"] = insights[0]
        elif reflections:
            thought["content"] = reflections[0].get("content", "Meta-cognitive reflection")
        return thought

    def evolve_system(self, agent):
        """
        Trigger system evolution based on performance metrics, goals,
        and environmental requirements.

        Parameters:
          - agent: Agent instance to evolve

        Returns:
          - (success, message) tuple
        """
        # Basic validation
        if not agent:
            return False, "Invalid agent provided to evolution engine."

        # Determine current cycle count
        cycle_count = 0
        if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'cycle_counter'):
            cycle_count = agent.ai_manager.cycle_counter
        else:
            cycle_count = getattr(agent, 'stats', {}).get('cycles_run', 0)

        # Evolution interval check (don't evolve too frequently)
        evolution_interval = SELF_MODIFY_INTERVAL  # Using global configuration
        cycles_since_last = cycle_count - self.last_major_evolution

        if cycles_since_last < evolution_interval:
            return False, f"Evolution interval not reached. {cycles_since_last}/{evolution_interval} cycles since last evolution."

        # Increase generation counter
        self.evolution_generation += 1

        # Analyze current state and fitness
        fitness_scores = self._evaluate_system_fitness(agent)
        evolutionary_pressure = self._calculate_evolutionary_pressure(fitness_scores)

        # Determine if evolution should occur based on pressure and randomness
        evolution_threshold = 0.3  # Base threshold
        evolution_probability = evolution_threshold + evolutionary_pressure

        if random.random() >= evolution_probability:
            return False, f"Evolution check passed, but probability threshold not met ({evolution_probability:.2f})."

        # System will evolve - select strategy
        selected_strategy = self._select_evolution_strategy(fitness_scores)

        # Apply the selected evolutionary strategy
        success, message, changes = self._apply_evolution_strategy(agent, selected_strategy, fitness_scores)

        # Record the evolution attempt
        evolution_record = {
            "generation": self.evolution_generation,
            "cycle": cycle_count,
            "strategy": selected_strategy,
            "success": success,
            "message": message,
            "changes": changes,
            "fitness_before": fitness_scores,
            "timestamp": datetime.now().isoformat()
        }
        self.evolution_history.append(evolution_record)

        if success:
            self.last_major_evolution = cycle_count
            log_event(f"System evolution successful: Generation {self.evolution_generation}, Strategy: {selected_strategy}", "QUANTUM")
        else:
            log_event(f"System evolution attempt failed: {message}", "WARNING")

        return success, message

    def _evaluate_system_fitness(self, agent):
        """
        Evaluate the fitness of the current system across multiple dimensions.
        (Placeholder implementation.)
        """
        fitness_scores = {
            "performance": 0.5,
            "efficiency": 0.5,
            "adaptability": 0.5,
            "robustness": 0.5,
            "complexity": 0.5
        }
        # Example: if agent.stats exists, use simple ratio as performance
        if hasattr(agent, 'stats') and isinstance(agent.stats, dict):
            cycles = agent.stats.get("cycles_run", 0)
            pages = agent.stats.get("pages_processed", 0)
            if cycles > 0:
                performance = pages / cycles
                fitness_scores["performance"] = max(0.1, min(0.9, performance / 10))
        return fitness_scores

    def _calculate_evolutionary_pressure(self, fitness_scores):
        """
        Calculate the evolutionary pressure based on fitness scores and goal weights.
        Lower overall fitness implies higher pressure.
        """
        total_weight = sum(abs(w) for w in self.goal_weights.values())
        weighted_sum = 0.0
        for metric, weight in self.goal_weights.items():
            score = fitness_scores.get(metric, 0.5)
            if weight < 0:
                score = 1 - score
            weighted_sum += score * abs(weight)
        avg_fitness = weighted_sum / total_weight if total_weight != 0 else 0.5
        pressure = (1 - avg_fitness) * self.adaptation_rate
        return pressure

    def _select_evolution_strategy(self, fitness_scores):
        """
        Select an appropriate evolution strategy based on the current fitness scores.
        Here we choose the strategy corresponding to the capability with the largest gap.
        """
        gaps = {}
        for metric, target in self.capability_targets.items():
            current = fitness_scores.get(metric, 0.5)
            gaps[metric] = target - current
        most_lacking = max(gaps.items(), key=lambda x: x[1])[0]
        mapping = {
            "knowledge_representation": "expansion",
            "planning": "integration",
            "learning": "specialization",
            "error_handling": "pruning",
            "creative_synthesis": "restructuring"
        }
        return mapping.get(most_lacking, "expansion")

    def _apply_evolution_strategy(self, agent, strategy, fitness_scores):
        """
        Apply the selected evolution strategy to modify the agent.
        Returns a tuple: (success, message, changes)
        """
        changes = []
        try:
            if strategy == "expansion":
                if hasattr(agent.model, 'expand_architecture'):
                    agent.model.expand_architecture()
                    changes.append("Expanded model architecture.")
                    success = True
                    message = "Expansion strategy applied successfully."
                else:
                    success = False
                    message = "Model does not support expansion."
            elif strategy == "pruning":
                if hasattr(agent.model, 'contract_architecture'):
                    agent.model.contract_architecture()
                    changes.append("Contracted model architecture.")
                    success = True
                    message = "Pruning strategy applied successfully."
                else:
                    success = False
                    message = "Model does not support pruning."
            elif strategy == "restructuring":
                changes.append("Reorganized internal connections.")
                success = True
                message = "Restructuring strategy applied successfully."
            elif strategy == "specialization":
                changes.append("Optimized specialized components.")
                success = True
                message = "Specialization strategy applied successfully."
            elif strategy == "integration":
                changes.append("Integrated separate capabilities.")
                success = True
                message = "Integration strategy applied successfully."
            else:
                success = False
                message = f"Unknown strategy: {strategy}"
        except Exception as e:
            success = False
            message = f"Error applying strategy {strategy}: {str(e)}"
        return success, message, changes

    def _generate_reflective_thought(self, context):
        """Generate a reflective thought focused on self-examination"""
        thought = {
            "type": "reflective",
            "content": "Meta-cognitive assessment",
            "reflections": [],
            "insights": [],
            "importance": 0.5
        }
        reflection_areas = [
            "learning_progress",
            "strategy_effectiveness",
            "error_patterns",
            "goal_alignment",
            "cognitive_bias"
        ]
        selected_areas = random.sample(reflection_areas, min(3, len(reflection_areas)))
        reflections = []
        history_span = min(10, len(self.thought_history))
        recent_thoughts = self.thought_history[-history_span:] if history_span > 0 else []
        for area in selected_areas:
            if area == "learning_progress":
                if "stats" in context and isinstance(context["stats"], dict):
                    cycles = context["stats"].get("cycles_run", 0)
                    pages = context["stats"].get("pages_processed", 0)
                    if cycles > 0:
                        learning_rate = pages / max(1, cycles)
                        reflections.append({
                            "area": "learning_progress",
                            "content": f"Learning rate: {learning_rate:.2f} pages per cycle",
                            "assessment": "satisfactory" if learning_rate > 0.5 else "needs improvement"
                        })
            elif area == "strategy_effectiveness":
                if (hasattr(self.agent, 'planner_sifter') and
                    hasattr(self.agent.planner_sifter, 'strategies')):
                    strategies = self.agent.planner_sifter.strategies
                    if strategies:
                        sorted_strategies = sorted(
                            [(name, data.get("effectiveness", 0.5)) for name, data in strategies.items()],
                            key=lambda x: x[1],
                            reverse=True
                        )
                        if sorted_strategies:
                            best = sorted_strategies[0]
                            worst = sorted_strategies[-1]
                            reflections.append({
                                "area": "strategy_effectiveness",
                                "content": f"Most effective strategy: {best[0]} ({best[1]:.2f}), Least effective: {worst[0]} ({worst[1]:.2f})",
                                "recommendation": f"Consider increasing use of {best[0]} approach"
                            })
            elif area == "error_patterns":
                if recent_thoughts:
                    error_thoughts = [t for t in recent_thoughts if "error" in str(t.get("content", "")).lower()]
                    if error_thoughts:
                        error_count = len(error_thoughts)
                        reflections.append({
                            "area": "error_patterns",
                            "content": f"Error-related thoughts appearing in {error_count}/{len(recent_thoughts)} recent thoughts",
                            "assessment": "concerning" if error_count > 3 else "manageable"
                        })
            elif area == "goal_alignment":
                if ("current_goal" in context and "recent_actions" in context and isinstance(context["recent_actions"], list)):
                    goal = context["current_goal"].get("description", "") if isinstance(context["current_goal"], dict) else ""
                    if goal:
                        actions = context["recent_actions"]
                        aligned_count = 0
                        for action in actions:
                            if isinstance(action, dict) and "action" in action:
                                action_type = action["action"]
                                if "explore" in goal.lower() and action_type in ["expand", "search"]:
                                    aligned_count += 1
                                elif "deep" in goal.lower() and action_type in ["evaluate", "adapt"]:
                                    aligned_count += 1
                        alignment_rate = aligned_count / max(1, len(actions))
                        reflections.append({
                            "area": "goal_alignment",
                            "content": f"Action-goal alignment rate: {alignment_rate:.2f}",
                            "assessment": "well-aligned" if alignment_rate > 0.6 else "misaligned"
                        })
            elif area == "cognitive_bias":
                potential_biases = []
                if recent_thoughts:
                    modes = [t.get("mode") for t in recent_thoughts]
                    mode_counts = {}
                    for mode in modes:
                        if mode:
                            mode_counts[mode] = mode_counts.get(mode, 0) + 1
                    most_common = max(mode_counts.items(), key=lambda x: x[1]) if mode_counts else (None, 0)
                    if most_common[1] > len(recent_thoughts) * 0.7:
                        potential_biases.append(f"Possible cognitive fixation on {most_common[0]} thinking mode")
                if "recent_actions" in context and isinstance(context["recent_actions"], list):
                    actions = context["recent_actions"]
                    if len(actions) >= 2:
                        last_action = actions[-1]
                        if isinstance(last_action, dict) and last_action.get("success", False):
                            potential_biases.append("Potential recency bias - overweighting last successful action")
                if potential_biases:
                    reflections.append({
                        "area": "cognitive_bias",
                        "content": potential_biases[0],
                        "recommendation": "Consider deliberate perspective shifts to counteract"
                    })
        insights = []
        for reflection in reflections:
            area = reflection.get("area", "")
            assessment = reflection.get("assessment", "")
            recommendation = reflection.get("recommendation", "")
            if area == "learning_progress" and assessment == "needs improvement":
                insights.append("Learning rate below target - consider adjusting exploration/exploitation balance")
            elif area == "strategy_effectiveness" and recommendation:
                insights.append(recommendation)
            elif area == "error_patterns" and assessment == "concerning":
                insights.append("High error rate - implement additional validation measures")
            elif area == "goal_alignment" and assessment == "misaligned":
                insights.append("Actions not well-aligned with goals - revisit planning process")
            elif area == "cognitive_bias" and recommendation:
                insights.append(recommendation)
        thought["reflections"] = reflections
        thought["insights"] = insights
        importance = 0.5
        if insights:
            importance += 0.1 * len(insights)
        if "concerning" in str(reflections) or "misaligned" in str(reflections):
            importance += 0.2
        thought["importance"] = min(0.9, importance)
        if insights:
            thought["content"] = insights[0]
        elif reflections:
            thought["content"] = reflections[0].get("content", "Meta-cognitive reflection")
        return thought

    def _generate_exploratory_thought(self, context):
        """Generate an exploratory thought focused on new possibilities"""
        thought = {
            "type": "exploratory",
            "content": "Exploration of new possibilities",
            "directions": [],
            "insights": [],
            "importance": 0.5
        }
        exploration_areas = [
            "unknown_domains",
            "connection_patterns",
            "alternative_strategies",
            "capability_expansion"
        ]
        selected_areas = random.sample(exploration_areas, min(2, len(exploration_areas)))
        directions = []
        for area in selected_areas:
            if area == "unknown_domains":
                if "domains_visited" in context:
                    domains_visited = context.get("domains_visited", set())
                    if isinstance(domains_visited, set):
                        candidate_domains = [
                            "research.science", "github.com", "en.wikipedia.org",
                            "arxiv.org", "semanticscholar.org", "openai.com",
                            "nature.com", "reddit.com/r/MachineLearning"
                        ]
                        unvisited = [d for d in candidate_domains if d not in domains_visited]
                        if unvisited:
                            sample_domains = random.sample(unvisited, min(3, len(unvisited)))
                            directions.append({
                                "area": "unknown_domains",
                                "content": f"Explore high-value domains: {', '.join(sample_domains)}",
                                "rationale": "Expanding domain knowledge diversity"
                            })
            elif area == "connection_patterns":
                directions.append({
                    "area": "connection_patterns",
                    "content": "Implement knowledge graph traversal to find distant connections",
                    "rationale": "Distant domains often contain valuable cross-applicable patterns"
                })
            elif area == "alternative_strategies":
                if (hasattr(self.agent, 'planner_sifter') and
                    hasattr(self.agent.planner_sifter, 'strategies')):
                    strategies = list(self.agent.planner_sifter.strategies.keys())
                    if strategies:
                        if (hasattr(self.agent.planner_sifter, 'strategy_usage')):
                            usage = self.agent.planner_sifter.strategy_usage
                            least_used = sorted([(s, usage.get(s, 0)) for s in strategies], key=lambda x: x[1])
                            if least_used:
                                least_used_strategy = least_used[0][0]
                                directions.append({
                                    "area": "alternative_strategies",
                                    "content": f"Experiment with underutilized strategy: {least_used_strategy}",
                                    "rationale": "Diversifying strategic approaches to discover new optima"
                                })
            elif area == "capability_expansion":
                directions.append({
                    "area": "capability_expansion",
                    "content": "Develop enhanced semantic reasoning module",
                    "rationale": "Would significantly improve knowledge integration capabilities"
                })
        insights = []
        for direction in directions:
            area = direction.get("area", "")
            rationale = direction.get("rationale", "")
            if area == "unknown_domains":
                insights.append("Systematic exploration of high-value domains should be prioritized")
            elif area == "connection_patterns":
                insights.append("Knowledge value may lie in unexpected cross-domain connections")
            elif area == "alternative_strategies":
                insights.append("Strategic diversification may uncover more effective approaches")
            elif area == "capability_expansion":
                insights.append("Capability development should focus on knowledge integration")
        thought["directions"] = directions
        thought["insights"] = insights
        if insights:
            thought["importance"] = 0.6 + 0.1 * len(insights)
        if insights:
            thought["content"] = insights[0]
        elif directions:
            thought["content"] = directions[0].get("content", "Exploration suggestion")
        return thought

    def _generate_critical_thought(self, context):
        """Generate a critical thought focused on evaluation and assessment"""
        thought = {
            "type": "critical",
            "content": "Critical evaluation",
            "assessments": [],
            "insights": [],
            "importance": 0.5
        }
        assessment_areas = [
            "information_quality",
            "reasoning_validity",
            "strategy_efficiency",
            "resource_allocation",
            "error_handling"
        ]
        selected_areas = random.sample(assessment_areas, min(2, len(assessment_areas)))
        assessments = []
        for area in selected_areas:
            if area == "information_quality":
                if (hasattr(self.agent, 'free_will') and
                    hasattr(self.agent.free_will, 'domain_intelligence')):
                    intelligence = self.agent.free_will.domain_intelligence
                    if hasattr(intelligence, 'domain_knowledge'):
                        knowledge = intelligence.domain_knowledge
                        if knowledge:
                            low_quality_domains = []
                            for domain, data in knowledge.items():
                                if isinstance(data, dict) and data.get("content_quality", 1.0) < 0.5:
                                    low_quality_domains.append(domain)
                            if low_quality_domains:
                                sample_domains = random.sample(low_quality_domains, min(2, len(low_quality_domains)))
                                assessments.append({
                                    "area": "information_quality",
                                    "content": f"Low-quality content detected in domains: {', '.join(sample_domains)}",
                                    "recommendation": "Implement stricter quality thresholds for these domains"
                                })
                            else:
                                assessments.append({
                                    "area": "information_quality",
                                    "content": "Overall information quality appears acceptable",
                                    "recommendation": "Continue regular quality monitoring"
                                })
            elif area == "reasoning_validity":
                if self.thought_history:
                    recent_thoughts = self.thought_history[-10:] if len(self.thought_history) >= 10 else self.thought_history
                    thought_types = set(t.get("type", "") for t in recent_thoughts)
                    if len(thought_types) < 3:
                        assessments.append({
                            "area": "reasoning_validity",
                            "content": f"Limited cognitive diversity detected (only {len(thought_types)} thought types used recently)",
                            "recommendation": "Deliberately activate more diverse thinking modes"
                        })
                    else:
                        assessments.append({
                            "area": "reasoning_validity",
                            "content": f"Cognitive diversity appears healthy ({len(thought_types)} different thought types used recently)",
                            "recommendation": "Maintain diverse thinking patterns"
                        })
            elif area == "strategy_efficiency":
                if (hasattr(self.agent, 'stats') and
                    isinstance(self.agent.stats, dict) and
                    'cycles_run' in self.agent.stats and
                    'pages_processed' in self.agent.stats):
                    cycles = self.agent.stats['cycles_run']
                    pages = self.agent.stats['pages_processed']
                    if cycles > 10:
                        efficiency = pages / max(1, cycles)
                        if efficiency < 0.5:
                            assessments.append({
                                "area": "strategy_efficiency",
                                "content": f"Low efficiency detected: {efficiency:.2f} pages/cycle",
                                "recommendation": "Consider more aggressive pruning of low-value paths"
                            })
                        else:
                            assessments.append({
                                "area": "strategy_efficiency",
                                "content": f"Acceptable efficiency: {efficiency:.2f} pages/cycle",
                                "recommendation": "Continue current approach with regular efficiency monitoring"
                            })
            elif area == "resource_allocation":
                if (hasattr(self.agent, 'memory') and
                    hasattr(self.agent, 'free_will') and
                    hasattr(self.agent.free_will, 'memory_set')):
                    memory_usage = len(self.agent.memory) / MEMORY_MAX_SIZE
                    urls_stored = len(self.agent.free_will.memory_set)
                    if memory_usage > 0.8 and urls_stored > 1000:
                        assessments.append({
                            "area": "resource_allocation",
                            "content": f"High memory usage ({memory_usage:.0%}) with {urls_stored} URLs stored",
                            "recommendation": "Implement more aggressive memory pruning strategy"
                        })
                    else:
                        assessments.append({
                            "area": "resource_allocation",
                            "content": f"Memory usage ({memory_usage:.0%}) with {urls_stored} URLs stored",
                            "recommendation": "Current resource allocation appears appropriate"
                        })
            elif area == "error_handling":
                if (hasattr(self.agent, 'domain_stats') and isinstance(self.agent.domain_stats, dict)):
                    total_visits = sum(d.get("visits", 0) for d in self.agent.domain_stats.values())
                    total_errors = sum(d.get("error_count", 0) for d in self.agent.domain_stats.values())
                    if total_visits > 0:
                        error_rate = total_errors / total_visits
                        if error_rate > 0.2:
                            assessments.append({
                                "area": "error_handling",
                                "content": f"High system-wide error rate: {error_rate:.2%}",
                                "recommendation": "Investigate error causes and implement more robust handling"
                            })
                        else:
                            assessments.append({
                                "area": "error_handling",
                                "content": f"Acceptable error rate: {error_rate:.2%}",
                                "recommendation": "Continue monitoring error patterns"
                            })
        insights = []
        for assessment in assessments:
            recommendation = assessment.get("recommendation", "")
            if "low-quality" in assessment.get("content", "").lower():
                insights.append("Information quality control needs improvement")
            elif "limited cognitive diversity" in assessment.get("content", "").lower():
                insights.append("Need to activate more diverse thinking patterns")
            elif "low efficiency" in assessment.get("content", "").lower():
                insights.append("Strategy efficiency requires optimization")
            elif "high memory usage" in assessment.get("content", "").lower():
                insights.append("Memory management needs more efficient pruning")
            elif "high system-wide error" in assessment.get("content", "").lower():
                insights.append("Error handling systems require review and enhancement")
            elif recommendation:
                insights.append(recommendation)
        thought["assessments"] = assessments
        thought["insights"] = insights
        importance = 0.5
        if insights:
            importance += 0.1 * len(insights)
        if any("high" in a.get("content", "").lower() for a in assessments):
            importance += 0.2
        thought["importance"] = min(0.9, importance)
        if insights:
            thought["content"] = insights[0]
        elif assessments:
            thought["content"] = assessments[0].get("content", "Critical assessment")
        return thought

    def _generate_integrative_thought(self, context):
        """Generate an integrative thought focused on knowledge synthesis"""
        thought = {
            "type": "integrative",
            "content": "Knowledge synthesis",
            "connections": [],
            "insights": [],
            "importance": 0.5
        }
        connections = []
        if not context:
            thought["content"] = "Insufficient knowledge for meaningful integration"
            return thought
        elements = {}
        if "domains_visited" in context:
            domains = context.get("domains_visited", set())
            if isinstance(domains, set) and len(domains) > 3:
                elements["domains"] = list(domains)
        if hasattr(self.agent, 'content_sifter'):
            sifter = self.agent.content_sifter
            if hasattr(sifter, 'topics_of_interest'):
                elements["topics"] = sifter.topics_of_interest
        if (hasattr(self.agent, 'ai_manager') and
            hasattr(self.agent.ai_manager, 'temporal_planner') and
            hasattr(self.agent.ai_manager.temporal_planner, 'long_term_goals')):
            goals = self.agent.ai_manager.temporal_planner.long_term_goals
            if goals:
                elements["goals"] = [g.get("description", "") for g in goals]
        if len(elements) >= 2:
            element_types = list(elements.keys())
            type_pair = random.sample(element_types, 2)
            elements_1 = elements[type_pair[0]]
            elements_2 = elements[type_pair[1]]
            if elements_1 and elements_2:
                element_1 = random.choice(elements_1)
                element_2 = random.choice(elements_2)
                connections.append({
                    "elements": [
                        {"type": type_pair[0], "value": element_1},
                        {"type": type_pair[1], "value": element_2}
                    ],
                    "connection_type": "integration",
                    "description": f"Integration of {type_pair[0]} '{element_1}' with {type_pair[1]} '{element_2}'",
                    "potential": random.uniform(0.5, 0.9)
                })
        if not connections:
            theoretical_connections = [
                {
                    "elements": [
                        {"type": "cognitive_mode", "value": "analytical"},
                        {"type": "capability", "value": "semantic_representation"}
                    ],
                    "connection_type": "enhancement",
                    "description": "Analytical thinking could enhance semantic representation quality",
                    "potential": 0.7
                },
                {
                    "elements": [
                        {"type": "capability", "value": "memory_management"},
                        {"type": "capability", "value": "planning"}
                    ],
                    "connection_type": "synergy",
                    "description": "Memory systems could be more tightly integrated with planning",
                    "potential": 0.8
                }
            ]
            connections.append(random.choice(theoretical_connections))
        insights = []
        for connection in connections:
            desc = connection.get("description", "")
            conn_type = connection.get("connection_type", "")
            potential = connection.get("potential", 0.5)
            if conn_type == "integration" and potential > 0.7:
                insights.append(f"High potential integration opportunity: {desc}")
            elif conn_type == "enhancement":
                insights.append(f"Enhancement pathway identified: {desc}")
            elif conn_type == "synergy":
                insights.append(f"Synergistic relationship would increase capability: {desc}")
            else:
                insights.append(f"Connection opportunity: {desc}")
        thought["connections"] = connections
        thought["insights"] = insights
        importance = 0.5
        if connections:
            avg_potential = sum(c.get("potential", 0.5) for c in connections) / len(connections)
            importance = avg_potential
        thought["importance"] = min(0.9, importance)
        if insights:
            thought["content"] = insights[0]
        elif connections:
            thought["content"] = connections[0].get("description", "Knowledge integration")
        return thought

    def _generate_intuitive_thought(self, context):
        """Generate an intuitive thought focused on pattern recognition"""
        thought = {
            "type": "intuitive",
            "content": "Pattern recognition",
            "patterns": [],
            "insights": [],
            "importance": 0.5
        }
        patterns = []
        if not context:
            thought["content"] = "Insufficient data for pattern recognition"
            return thought
        if "recent_actions" in context and isinstance(context["recent_actions"], list):
            actions = context["recent_actions"]
            if len(actions) >= 3:
                action_types = [a.get("action", "unknown") for a in actions if isinstance(a, dict)]
                if len(action_types) >= 3:
                    repetitions = []
                    current_sequence = [action_types[0]]
                    for i in range(1, len(action_types)):
                        if action_types[i] == action_types[i-1]:
                            current_sequence.append(action_types[i])
                        else:
                            if len(current_sequence) >= 2:
                                repetitions.append(current_sequence)
                            current_sequence = [action_types[i]]
                    if len(current_sequence) >= 2:
                        repetitions.append(current_sequence)
                    if repetitions:
                        longest_repetition = max(repetitions, key=len)
                        patterns.append({
                            "type": "action_repetition",
                            "description": f"Repeated sequence of '{longest_repetition[0]}' actions",
                            "significance": 0.6 + 0.1 * min(4, len(longest_repetition)),
                            "potential_cause": "Strategy fixation or optimal local strategy"
                        })
                    if len(set(action_types)) == 2 and len(action_types) >= 4:
                        is_alternating = True
                        for i in range(2, len(action_types)):
                            if action_types[i] != action_types[i-2]:
                                is_alternating = False
                                break
                        if is_alternating:
                            patterns.append({
                                "type": "action_alternation",
                                "description": f"Alternating pattern between '{action_types[0]}' and '{action_types[1]}'",
                                "significance": 0.7,
                                "potential_cause": "Explore-exploit cycle or complementary strategies"
                            })
        if "domain_stats" in context and isinstance(context["domain_stats"], dict):
            domains = context["domain_stats"]
            if domains:
                frequent_domains = sorted(
                    [(d, stats.get("visits", 0)) for d, stats in domains.items()],
                    key=lambda x: x[1],
                    reverse=True
                )
                if frequent_domains:
                    top_domains = frequent_domains[:3]
                    total_visits = sum(v for _, v in frequent_domains)
                    top_domain_visits = sum(v for _, v in top_domains)
                    concentration = top_domain_visits / max(1, total_visits)
                    if concentration > 0.7:
                        patterns.append({
                            "type": "domain_concentration",
                            "description": f"Heavy concentration ({concentration:.0%}) on top 3 domains",
                            "significance": 0.7,
                            "potential_cause": "Exploitation focus or domain specialization"
                        })
        if "domain_stats" in context and isinstance(context["domain_stats"], dict):
            domains = context["domain_stats"]
            if domains:
                error_domains = []
                for domain, stats in domains.items():
                    if isinstance(stats, dict) and stats.get("error_rate", 0) > 0.3:
                        error_domains.append((domain, stats.get("error_rate", 0)))
                if error_domains:
                    error_domains.sort(key=lambda x: x[1], reverse=True)
                    top_error_domains = error_domains[:3]
                    patterns.append({
                        "type": "error_concentration",
                        "description": f"High error rates in specific domains: {', '.join(d for d, _ in top_error_domains)}",
                        "significance": 0.8,
                        "potential_cause": "Domain-specific access issues or content filtering problems"
                    })
        insights = []
        for pattern in patterns:
            pattern_type = pattern.get("type", "")
            significance = pattern.get("significance", 0.5)
            if pattern_type == "action_repetition" and significance > 0.7:
                insights.append("Repeated action pattern may indicate strategy fixation - consider forcing exploration")
            elif pattern_type == "action_alternation":
                insights.append("Alternating action pattern suggests systematic exploration-exploitation approach")
            elif pattern_type == "domain_concentration":
                insights.append("High domain concentration indicates need for broader exploration")
            elif pattern_type == "error_concentration":
                insights.append("Domain-specific error pattern detected - consider domain-specific handling strategies")
        thought["patterns"] = patterns
        thought["insights"] = insights
        importance = 0.5
        if patterns:
            avg_significance = sum(p.get("significance", 0.5) for p in patterns) / len(patterns)
            importance = avg_significance
        thought["importance"] = min(0.9, importance)
        if insights:
            thought["content"] = insights[0]
        elif patterns:
            thought["content"] = patterns[0].get("description", "Pattern detected")
        return thought

    def _generate_balanced_thought(self, context):
        """Generate a balanced thought that incorporates multiple thinking modes"""
        available_modes = ["analytical", "creative", "reflective", "exploratory", "critical", "integrative", "intuitive"]
        selected_modes = random.sample(available_modes, 2)
        thoughts = []
        for mode in selected_modes:
            if mode == "analytical":
                thoughts.append(self._generate_analytical_thought(context))
            elif mode == "creative":
                thoughts.append(self._generate_creative_thought(context))
            elif mode == "reflective":
                thoughts.append(self._generate_reflective_thought(context))
            elif mode == "exploratory":
                thoughts.append(self._generate_exploratory_thought(context))
            elif mode == "critical":
                thoughts.append(self._generate_critical_thought(context))
            elif mode == "integrative":
                thoughts.append(self._generate_integrative_thought(context))
            elif mode == "intuitive":
                thoughts.append(self._generate_intuitive_thought(context))
        balanced_thought = {
            "type": "balanced",
            "content": "Multi-perspective assessment",
            "component_modes": selected_modes,
            "insights": [],
            "importance": 0.5
        }
        all_insights = []
        for thought in thoughts:
            if "insights" in thought and thought["insights"]:
                all_insights.extend(thought["insights"])
        selected_insights = all_insights[:3] if all_insights else []
        balanced_thought["insights"] = selected_insights
        if thoughts:
            avg_importance = sum(t.get("importance", 0.5) for t in thoughts) / len(thoughts)
            balanced_thought["importance"] = avg_importance
        if selected_insights:
            balanced_thought["content"] = selected_insights[0]
        elif thoughts:
            balanced_thought["content"] = "Balanced perspective: " + thoughts[0].get("content", "")
        return balanced_thought

    def _update_working_memory(self, thought):
        """
        Update working memory with new thought, managing capacity constraints.
        """
        if not thought:
            return
        self.working_memory.append(thought)
        if len(self.working_memory) > self.working_memory_capacity:
            if len(self.working_memory) > 1:
                least_important_idx = min(range(len(self.working_memory) - 1),
                                        key=lambda i: self.working_memory[i].get("importance", 0))
                del self.working_memory[least_important_idx]
        for insight in thought.get("insights", []):
            importance = thought.get("importance", 0.5)
            if importance > 0.7:
                self.recent_insights.append({
                    "content": insight,
                    "source_type": thought.get("type", "unknown"),
                    "importance": importance,
                    "timestamp": datetime.now().isoformat()
                })
        if len(self.recent_insights) > 20:
            self.recent_insights = self.recent_insights[-20:]

    def _summarize_context(self, context):
        """Create a brief summary of the context for thought recording"""
        if not context:
            return "No context"
        if not isinstance(context, dict):
            return str(context)[:100]
        elements = []
        if "current_goal" in context and isinstance(context["current_goal"], dict):
            goal_desc = context["current_goal"].get("description", "unknown goal")
            elements.append(f"Goal: {goal_desc}")
        if "last_action" in context and isinstance(context["last_action"], dict):
            action = context["last_action"].get("action", "unknown action")
            elements.append(f"Action: {action}")
        if "memory_size" in context:
            elements.append(f"Memory: {context['memory_size']}")
        return "; ".join(elements) if elements else "Context present but no key elements"

    def _extract_elements_from_context(self, context, aspect_types):
        """
        Extract relevant elements from context based on aspect types.
        """
        elements = []
        if not context or not isinstance(context, dict):
            return elements
        for aspect_type in aspect_types:
            if aspect_type == "goals" and "current_goal" in context:
                if isinstance(context["current_goal"], dict):
                    goal_desc = context["current_goal"].get("description", "")
                    if goal_desc:
                        elements.append(goal_desc)
            elif aspect_type == "domains" and "domains_visited" in context:
                domains = context["domains_visited"]
                if isinstance(domains, set) and domains:
                    sample_size = min(3, len(domains))
                    domain_sample = random.sample(list(domains), sample_size)
                    elements.extend(domain_sample)
            elif aspect_type == "strategies" and hasattr(self.agent, 'planner_sifter'):
                if hasattr(self.agent.planner_sifter, 'strategies'):
                    strategy_names = list(self.agent.planner_sifter.strategies.keys())
                    if strategy_names:
                        sample_size = min(2, len(strategy_names))
                        strategy_sample = random.sample(strategy_names, sample_size)
                        elements.extend(strategy_sample)
            elif aspect_type == "patterns" and "recent_actions" in context:
                actions = context["recent_actions"]
                if isinstance(actions, list) and len(actions) >= 3:
                    action_types = [a.get("action", "unknown") for a in actions if isinstance(a, dict)]
                    if len(set(action_types)) <= 3:
                        pattern_desc = f"Action pattern: {' â†’ '.join(action_types[-3:])}"
                        elements.append(pattern_desc)
            elif aspect_type == "anomalies" and "domain_stats" in context:
                domains = context["domain_stats"]
                if isinstance(domains, dict):
                    anomalies = []
                    for domain, stats in domains.items():
                        if isinstance(stats, dict) and stats.get("error_rate", 0) > 0.3:
                            anomalies.append(f"High error rate in {domain}")
                    if anomalies:
                        elements.append(random.choice(anomalies))
        return elements

    def _assess_action_outcomes(self, actions):
        """
        Assess whether recent action outcomes are improving or deteriorating.
        """
        if not actions or len(actions) < 3:
            return "insufficient_data"
        success_indicators = []
        for action in actions:
            if not isinstance(action, dict):
                continue
            if "success" in action:
                success_indicators.append(1 if action["success"] else 0)
                continue
            if "content_length" in action:
                length = action["content_length"]
                success_indicators.append(min(1.0, length / 5000))
                continue
            if "links_discovered" in action:
                links = action["links_discovered"]
                success_indicators.append(min(1.0, links / 10))
                continue
        if len(success_indicators) < 3:
            return "insufficient_data"
        mid_point = len(success_indicators) // 2
        first_half = success_indicators[:mid_point]
        second_half = success_indicators[mid_point:]
        first_avg = sum(first_half) / len(first_half)
        second_avg = sum(second_half) / len(second_half)
        diff = second_avg - first_avg
        if abs(diff) < 0.1:
            return "stable"
        elif diff > 0:
            return "improving"
        else:
            return "deteriorating"

    def get_current_state(self):
        """
        Get the current state of the autonomous mind.
        """
        return {
            "current_mode": self.current_mode,
            "cognitive_load": self.cognitive_load,
            "thought_depth": self.thought_depth,
            "working_memory_usage": len(self.working_memory) / self.working_memory_capacity,
            "recent_thoughts": [{
                "content": t.get("content", ""),
                "type": t.get("type", ""),
                "importance": t.get("importance", 0.5)
            } for t in self.thought_history[-5:]] if self.thought_history else [],
            "important_insights": [{
                "content": i.get("content", ""),
                "importance": i.get("importance", 0.5)
            } for i in self.recent_insights[-3:]] if self.recent_insights else [],
            "active_concepts": [{
                "state": state,
                "activation": data["activation"]
            } for state, data in self.cognitive_states.items() if data["activation"] >= self.concept_activation_threshold],
            "thinking_style": self.thinking_style
        }

    def set_thinking_style(self, style_params):
        """
        Adjust thinking style parameters to change cognitive approach.
        """
        if not style_params or not isinstance(style_params, dict):
            return False
        for param, value in style_params.items():
            if param in self.thinking_style and isinstance(value, (int, float)):
                value = max(0.0, min(1.0, value))
                old_value = self.thinking_style[param]
                self.thinking_style[param] = value
                log_event(f"Thinking style parameter '{param}' adjusted: {old_value:.2f} â†’ {value:.2f}", "INFO")
        return True

    def prime_with_context(self, context_elements):
        """
        Prime the mind with specific context elements to influence thinking.
        """
        if not context_elements or not isinstance(context_elements, dict):
            return False
        if "cognitive_modes" in context_elements:
            modes = context_elements["cognitive_modes"]
            if isinstance(modes, list):
                for mode in modes:
                    if mode in self.cognitive_states:
                        old_activation = self.cognitive_states[mode]["activation"]
                        self.cognitive_states[mode]["activation"] = min(0.9, old_activation * 1.5)
                        log_event(f"Cognitive mode '{mode}' primed: {old_activation:.2f} â†’ {self.cognitive_states[mode]['activation']:.2f}", "INFO")
        if "depth" in context_elements:
            depth = context_elements["depth"]
            if isinstance(depth, (int, float)):
                self.thought_depth = max(0.0, min(1.0, depth))
                log_event(f"Thought depth primed to {self.thought_depth:.2f}", "INFO")
        if "focus" in context_elements:
            focus = context_elements["focus"]
            self.attention_focus = focus
            log_event(f"Attention focus primed to '{focus}'", "INFO")
        return True




# =============================================================================
# SELF-EVOLUTION MODULE - ADDED HERE
# =============================================================================
class MetaEvolutionEngine:
    """
    Engine for system-level self-evolution, adapting core algorithms,
    architectures, and strategies over longer timescales.
    """
    def __init__(self):
        self.evolution_generation = 1
        self.last_major_evolution = 0
        self.evolution_history = deque(maxlen=50)
        self.strategies = {
            "expansion": {"description": "Expand neural architecture", "success_rate": 0.6, "last_attempt": 0},
            "pruning": {"description": "Prune redundant components", "success_rate": 0.5, "last_attempt": 0},
            "restructuring": {"description": "Reorganize internal structure", "success_rate": 0.4, "last_attempt": 0},
            "specialization": {"description": "Specialize components for focused tasks", "success_rate": 0.55, "last_attempt": 0},
            "integration": {"description": "Integrate synergistic modules", "success_rate": 0.65, "last_attempt": 0}
        }
        self.goal_weights = {
            "performance": 0.5,
            "efficiency": 0.3,
            "adaptability": 0.4,
            "robustness": 0.4,
            "complexity": -0.2  # Negative weight: minimize complexity
        }
        self.capability_targets = {
            "knowledge_representation": 0.9,
            "planning": 0.85,
            "learning": 0.9,
            "error_handling": 0.8,
            "creative_synthesis": 0.7
        }
        self.capability_scores = {}
        self.adaptation_rate = 0.15  # Rate of adaptation pressure
        self.convergence_score = 0.0  # Score indicating evolutionary convergence
        self.performance_metrics = []  # Track performance metrics for self-modification
        self.thought_history = []  # For reflective thinking
        self.working_memory = []  # Active concepts and thoughts
        self.working_memory_capacity = 7  # Miller's magical number
        self.recent_insights = []  # Store recent realizations
        self.agent = None  # Will be set when used

        log_event("MetaEvolutionEngine initialized", "INFO")

    def quantum_concept_blend(self, concept1, concept2, blend_factor=0.5):
        """
        Blend two concepts in an entangled conceptual space.

        Parameters:
        - concept1: Dictionary representing first concept
        - concept2: Dictionary representing second concept
        - blend_factor: Weight for blending (0.0-1.0)

        Returns:
        - Blended concept dictionary
        """
        if not isinstance(concept1, dict) or not isinstance(concept2, dict):
            return None

        # Extract key attributes
        attributes1 = set(concept1.keys())
        attributes2 = set(concept2.keys())

        # Find shared and unique attributes
        shared = attributes1.intersection(attributes2)
        unique1 = attributes1 - shared
        unique2 = attributes2 - shared

        # Create quantum superposition of concepts
        blended = {}

        # Shared attributes use quantum interference
        for attr in shared:
            if isinstance(concept1[attr], (int, float)) and isinstance(concept2[attr], (int, float)):
                # Quantum interference effect
                phase = random.uniform(0, math.pi * 2)
                blended[attr] = concept1[attr] * math.cos(phase) + concept2[attr] * math.sin(phase)
            else:
                # Non-numeric attributes use probabilistic selection
                blended[attr] = concept1[attr] if random.random() < blend_factor else concept2[attr]

        # Include unique attributes with probability based on blend factor
        for attr in unique1:
            if random.random() < blend_factor:
                blended[attr] = concept1[attr]

        for attr in unique2:
            if random.random() < (1 - blend_factor):
                blended[attr] = concept2[attr]

        # Generate an emergent property (something neither concept had)
        emergent_options = ["synergy", "transcendence", "complexity", "harmony", "paradox"]
        blended["emergent_property"] = random.choice(emergent_options)

        return blended

    def apply_self_modifications(self, agent):
        """
        Apply self-modifications to improve system capabilities

        Parameters:
        - agent: Agent to modify

        Returns:
        - (success, message) tuple
        """
        # Identify potential areas for improvement based on performance metrics
        if not self.performance_metrics or len(self.performance_metrics) < 10:
            return False, "Insufficient performance data for self-modification"

        # Analyze recent performance trends
        recent_metrics = self.performance_metrics[-10:]
        avg_loss = sum(m.get('loss', 0.5) for m in recent_metrics) / len(recent_metrics)
        loss_trend = recent_metrics[-1].get('loss', 0.5) - recent_metrics[0].get('loss', 0.5)

        modifications = []

        # 1. Architecture modifications
        if avg_loss > 0.3 and loss_trend > 0.05:
            # Loss is high and getting worse - try architecture expansion
            if hasattr(agent.model, 'expand_architecture'):
                agent.model.expand_architecture()
                modifications.append("Expanded neural architecture")
        elif avg_loss < 0.2 and hasattr(agent.model, 'neocortex') and len(agent.model.neocortex) > 10:
            # Loss is low with large architecture - try pruning
            if hasattr(agent.model, 'contract_architecture'):
                agent.model.contract_architecture()
                modifications.append("Pruned neural architecture for efficiency")

        # 2. Memory optimizations
        if hasattr(agent, 'free_will') and hasattr(agent.free_will, 'memory_set'):
            memory_size = len(agent.free_will.memory_set)
            if memory_size > MEMORY_MAX_SIZE * 0.9:
                # Memory approaching capacity - trigger pruning
                if hasattr(agent.free_will, 'contract_memory'):
                    agent.free_will.contract_memory(int(MEMORY_MAX_SIZE * 0.7))
                    modifications.append(f"Optimized memory from {memory_size} to {len(agent.free_will.memory_set)} items")

        # 3. Consciousness adjustments
        if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'consciousness'):
            consciousness = agent.ai_manager.consciousness
            if avg_loss > 0.3:
                # High loss - try boosting reflective awareness
                if hasattr(consciousness, 'increase_awareness'):
                    consciousness.increase_awareness(0.1)
                    if hasattr(consciousness, 'current_state'):
                        consciousness.current_state = "reflective"
                        modifications.append("Increased reflective awareness to address performance issues")

        if modifications:
            log_event(f"Self-modification applied: {', '.join(modifications)}", "QUANTUM")
            return True, f"Successfully applied {len(modifications)} self-modifications"

        return False, "No beneficial self-modifications identified"

    def evolve_system(self, agent):
        """
        Trigger system evolution based on performance metrics, goals,
        and environmental requirements.

        Parameters:
          - agent: Agent instance to evolve

        Returns:
          - (success, message) tuple
        """
        # Store agent reference for other methods to use
        self.agent = agent

        # Basic validation
        if not agent:
            return False, "Invalid agent provided to evolution engine."

        # Determine current cycle count
        cycle_count = 0
        if hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'cycle_counter'):
            cycle_count = agent.ai_manager.cycle_counter
        else:
            cycle_count = getattr(agent, 'stats', {}).get('cycles_run', 0)

        # Evolution interval check (don't evolve too frequently)
        evolution_interval = SELF_MODIFY_INTERVAL  # Using global configuration
        cycles_since_last = cycle_count - self.last_major_evolution

        if cycles_since_last < evolution_interval:
            return False, f"Evolution interval not reached. {cycles_since_last}/{evolution_interval} cycles since last evolution."

        # Increase generation counter
        self.evolution_generation += 1

        # First try self-modification approach if we have enough performance data
        if len(self.performance_metrics) >= 10:
            success, message = self.apply_self_modifications(agent)
            if success:
                # Record the evolution attempt
                evolution_record = {
                    "generation": self.evolution_generation,
                    "cycle": cycle_count,
                    "strategy": "self_modification",
                    "success": True,
                    "message": message,
                    "changes": message,
                    "timestamp": datetime.now().isoformat()
                }
                self.evolution_history.append(evolution_record)
                self.last_major_evolution = cycle_count
                log_event(f"System evolution through self-modification: {message}", "QUANTUM")
                return True, message

        # Continue with standard evolution if self-modification didn't succeed
        # Analyze current state and fitness
        fitness_scores = self._evaluate_system_fitness(agent)
        evolutionary_pressure = self._calculate_evolutionary_pressure(fitness_scores)

        # Determine if evolution should occur based on pressure and randomness
        evolution_threshold = 0.3  # Base threshold
        evolution_probability = evolution_threshold + evolutionary_pressure

        if random.random() >= evolution_probability:
            return False, f"Evolution check passed, but probability threshold not met ({evolution_probability:.2f})."

        # System will evolve - select strategy
        selected_strategy = self._select_evolution_strategy(fitness_scores)

        # Apply the selected evolutionary strategy
        success, message, changes = self._apply_evolution_strategy(agent, selected_strategy, fitness_scores)

        # Record the evolution attempt
        evolution_record = {
            "generation": self.evolution_generation,
            "cycle": cycle_count,
            "strategy": selected_strategy,
            "success": success,
            "message": message,
            "changes": changes,
            "fitness_before": fitness_scores,
            "timestamp": datetime.now().isoformat()
        }

        self.evolution_history.append(evolution_record)

        # Update last evolution time if successful
        if success:
            self.last_major_evolution = cycle_count
            log_event(f"System evolution successful: Generation {self.evolution_generation}, Strategy: {selected_strategy}", "QUANTUM")
        else:
            log_event(f"System evolution attempt failed: {message}", "WARNING")

        return success, message

    def _evaluate_system_fitness(self, agent):
        """
        Evaluate the fitness of the current system across multiple dimensions.
        """
        fitness_scores = {
            "performance": 0.5,
            "efficiency": 0.5,
            "adaptability": 0.5,
            "robustness": 0.5,
            "complexity": 0.5
        }
        # Example: if agent.stats exists, use simple ratio as performance
        if hasattr(agent, 'stats') and isinstance(agent.stats, dict):
            cycles = agent.stats.get("cycles_run", 0)
            pages = agent.stats.get("pages_processed", 0)
            if cycles > 0:
                performance = pages / cycles
                fitness_scores["performance"] = max(0.1, min(0.9, performance / 10))
        return fitness_scores

    def _calculate_evolutionary_pressure(self, fitness_scores):
        """
        Calculate the evolutionary pressure based on fitness scores and goal weights.
        Lower overall fitness implies higher pressure.
        """
        total_weight = sum(abs(w) for w in self.goal_weights.values())
        weighted_sum = 0.0
        for metric, weight in self.goal_weights.items():
            score = fitness_scores.get(metric, 0.5)
            if weight < 0:
                score = 1 - score
            weighted_sum += score * abs(weight)
        avg_fitness = weighted_sum / total_weight if total_weight != 0 else 0.5
        pressure = (1 - avg_fitness) * self.adaptation_rate
        return pressure

    def _select_evolution_strategy(self, fitness_scores):
        """
        Select an appropriate evolution strategy based on the current fitness scores.
        Here we choose the strategy corresponding to the capability with the largest gap.
        """
        gaps = {}
        for metric, target in self.capability_targets.items():
            current = fitness_scores.get(metric, 0.5)
            gaps[metric] = target - current
        most_lacking = max(gaps.items(), key=lambda x: x[1])[0]
        mapping = {
            "knowledge_representation": "expansion",
            "planning": "integration",
            "learning": "specialization",
            "error_handling": "pruning",
            "creative_synthesis": "restructuring"
        }

        # Occasionally use a blended strategy (10% chance)
        if random.random() < 0.1 and len(self.strategies) >= 2:
            regular_strategies = ["expansion", "pruning", "restructuring", "specialization", "integration"]
            available = [s for s in regular_strategies if s in self.strategies]
            if len(available) >= 2:
                s1, s2 = random.sample(available, 2)
                blended_name, _ = self.blend_strategies(s1, s2)
                if blended_name:
                    return blended_name

        return mapping.get(most_lacking, "expansion")

    def _apply_evolution_strategy(self, agent, strategy, fitness_scores):
        """
        Apply the selected evolution strategy to modify the agent.
        Returns a tuple: (success, message, changes)
        """
        changes = []
        try:
            if strategy == "expansion":
                if hasattr(agent.model, 'expand_architecture'):
                    agent.model.expand_architecture()
                    changes.append("Expanded model architecture.")
                    success = True
                    message = "Expansion strategy applied successfully."
                else:
                    success = False
                    message = "Model does not support expansion."
            elif strategy == "pruning":
                if hasattr(agent.model, 'contract_architecture'):
                    agent.model.contract_architecture()
                    changes.append("Contracted model architecture.")
                    success = True
                    message = "Pruning strategy applied successfully."
                else:
                    success = False
                    message = "Model does not support pruning."
            elif strategy == "restructuring":
                changes.append("Reorganized internal connections.")

                # Apply restructuring to agent's consciousness module if available
                if (hasattr(agent, 'ai_manager') and hasattr(agent.ai_manager, 'consciousness')):
                    consciousness = agent.ai_manager.consciousness

                    # Adjust awareness fluctuation rate
                    if hasattr(consciousness, 'awareness_fluctuation_rate'):
                        old_rate = consciousness.awareness_fluctuation_rate
                        new_rate = old_rate * random.uniform(0.8, 1.2)
                        consciousness.awareness_fluctuation_rate = max(0.01, min(0.1, new_rate))
                        changes.append(f"Adjusted consciousness fluctuation rate: {old_rate:.3f} â†’ {new_rate:.3f}")

                    # Reset to reflective state
                    if hasattr(consciousness, 'current_state'):
                        old_state = consciousness.current_state
                        consciousness.current_state = "reflective"
                        changes.append(f"Reset consciousness state from '{old_state}' to 'reflective'")

                success = True
                message = "Restructuring strategy applied successfully."
            elif strategy == "specialization":
                changes.append("Optimized specialized components.")

                # If agent has content sifter, specialize its topics
                if hasattr(agent, 'content_sifter'):
                    sifter = agent.content_sifter
                    if hasattr(sifter, 'topics_of_interest'):
                        old_topics = sifter.topics_of_interest
                        tech_topics = ["artificial intelligence", "quantum computing",
                                      "neural networks", "machine learning"]

                        # Keep some original topics
                        keep_count = max(3, int(len(old_topics) * 0.3))
                        kept_topics = random.sample(old_topics, keep_count)

                        # Create specialized topic list
                        new_topics = kept_topics + tech_topics
                        new_topics = list(dict.fromkeys(new_topics))  # Remove duplicates

                        # Apply change
                        sifter.topics_of_interest = new_topics
                        changes.append(f"Specialized content sifter with {len(new_topics)} focused topics")

                success = True
                message = "Specialization strategy applied successfully."
            elif strategy == "integration":
                changes.append("Integrated separate capabilities.")
                integration_count = 0

                # Integrate consciousness with planning if available
                if (hasattr(agent, 'ai_manager') and
                    hasattr(agent.ai_manager, 'consciousness') and
                    hasattr(agent.ai_manager, 'temporal_planner')):

                    consciousness = agent.ai_manager.consciousness
                    planner = agent.ai_manager.temporal_planner

                    if hasattr(consciousness, 'awareness_level') and hasattr(planner, 'reflection_interval'):
                        awareness = consciousness.awareness_level
                        old_interval = planner.reflection_interval
                        new_interval = int(max(5, 30 - 25 * awareness))
                        planner.reflection_interval = new_interval

                        changes.append(f"Integrated consciousness awareness with planning reflection interval: {old_interval} â†’ {new_interval}")
                        integration_count += 1

                # Integrate free will with content filtering if applicable
                if hasattr(agent, 'free_will') and hasattr(agent, 'content_sifter'):
                    if hasattr(agent.free_will, 'memory_importance') and hasattr(agent.content_sifter, 'topics_of_interest'):
                        # Additional integration logic would go here
                        changes.append("Integrated memory importance with content filtering")
                        integration_count += 1

                success = True
                message = f"Integration strategy applied successfully with {integration_count} integrations."
            elif "_blend" in strategy:
                # Handle blended strategies
                changes.append("Applied blended strategy with emergent properties")
                success = True
                message = f"Blended strategy {strategy} applied successfully."
            else:
                success = False
                message = f"Unknown strategy: {strategy}"
        except Exception as e:
            success = False
            message = f"Error applying strategy {strategy}: {str(e)}"

        return success, message, changes

    def track_performance(self, metrics):
        """
        Track performance metrics for future self-modification decisions.

        Parameters:
        - metrics: Dictionary of performance metrics
        """
        if isinstance(metrics, dict):
            self.performance_metrics.append(metrics.copy())

            # Keep only the most recent metrics
            if len(self.performance_metrics) > 50:
                self.performance_metrics = self.performance_metrics[-50:]

    def blend_strategies(self, strategy1, strategy2):
        """
        Use quantum concept blending to create a hybrid strategy.

        Parameters:
        - strategy1, strategy2: Names of strategies to blend

        Returns:
        - New blended strategy name and properties
        """
        if (strategy1 not in self.strategies or
            strategy2 not in self.strategies):
            return None, None

        # Get strategy concepts
        concept1 = self.strategies[strategy1].copy()
        concept2 = self.strategies[strategy2].copy()

        # Quantum blend the concepts
        blended = self.quantum_concept_blend(concept1, concept2)

        if not blended:
            return None, None

        # Create a new strategy name
        new_name = f"{strategy1}_{strategy2}_blend"

        # Store the new strategy
        self.strategies[new_name] = blended

        log_event(f"Created new blended strategy: {new_name} with emergent property: {blended.get('emergent_property')}", "QUANTUM")

        return new_name, blended

    def _generate_reflective_thought(self, context):
        """Generate a reflective thought focused on self-examination"""
        thought = {
            "type": "reflective",
            "content": "Meta-cognitive assessment",
            "reflections": [],
            "insights": [],
            "importance": 0.5
        }
        reflection_areas = [
            "learning_progress",
            "strategy_effectiveness",
            "error_patterns",
            "goal_alignment",
            "cognitive_bias"
        ]
        selected_areas = random.sample(reflection_areas, min(3, len(reflection_areas)))
        reflections = []
        history_span = min(10, len(self.thought_history))
        recent_thoughts = self.thought_history[-history_span:] if history_span > 0 else []
        for area in selected_areas:
            if area == "learning_progress":
                if "stats" in context and isinstance(context["stats"], dict):
                    cycles = context["stats"].get("cycles_run", 0)
                    pages = context["stats"].get("pages_processed", 0)
                    if cycles > 0:
                        learning_rate = pages / max(1, cycles)
                        reflections.append({
                            "area": "learning_progress",
                            "content": f"Learning rate: {learning_rate:.2f} pages per cycle",
                            "assessment": "satisfactory" if learning_rate > 0.5 else "needs improvement"
                        })
            elif area == "strategy_effectiveness":
                if (hasattr(self.agent, 'planner_sifter') and
                    hasattr(self.agent.planner_sifter, 'strategies')):
                    strategies = self.agent.planner_sifter.strategies
                    if strategies:
                        sorted_strategies = sorted(
                            [(name, data.get("effectiveness", 0.5)) for name, data in strategies.items()],
                            key=lambda x: x[1],
                            reverse=True
                        )
                        if sorted_strategies:
                            best = sorted_strategies[0]
                            worst = sorted_strategies[-1]
                            reflections.append({
                                "area": "strategy_effectiveness",
                                "content": f"Most effective strategy: {best[0]} ({best[1]:.2f}), Least effective: {worst[0]} ({worst[1]:.2f})",
                                "recommendation": f"Consider increasing use of {best[0]} approach"
                            })
            elif area == "error_patterns":
                if recent_thoughts:
                    error_thoughts = [t for t in recent_thoughts if "error" in str(t.get("content", "")).lower()]
                    if error_thoughts:
                        error_count = len(error_thoughts)
                        reflections.append({
                            "area": "error_patterns",
                            "content": f"Error-related thoughts appearing in {error_count}/{len(recent_thoughts)} recent thoughts",
                            "assessment": "concerning" if error_count > 3 else "manageable"
                        })
            elif area == "goal_alignment":
                if ("current_goal" in context and "recent_actions" in context and isinstance(context["recent_actions"], list)):
                    goal = context["current_goal"].get("description", "") if isinstance(context["current_goal"], dict) else ""
                    if goal:
                        actions = context["recent_actions"]
                        aligned_count = 0
                        for action in actions:
                            if isinstance(action, dict) and "action" in action:
                                action_type = action["action"]
                                if "explore" in goal.lower() and action_type in ["expand", "search"]:
                                    aligned_count += 1
                                elif "deep" in goal.lower() and action_type in ["evaluate", "adapt"]:
                                    aligned_count += 1
                        alignment_rate = aligned_count / max(1, len(actions))
                        reflections.append({
                            "area": "goal_alignment",
                            "content": f"Action-goal alignment rate: {alignment_rate:.2f}",
                            "assessment": "well-aligned" if alignment_rate > 0.6 else "misaligned"
                        })
            elif area == "cognitive_bias":
                potential_biases = []
                if recent_thoughts:
                    modes = [t.get("mode") for t in recent_thoughts]
                    mode_counts = {}
                    for mode in modes:
                        if mode:
                            mode_counts[mode] = mode_counts.get(mode, 0) + 1
                    most_common = max(mode_counts.items(), key=lambda x: x[1]) if mode_counts else (None, 0)
                    if most_common[1] > len(recent_thoughts) * 0.7:
                        potential_biases.append(f"Possible cognitive fixation on {most_common[0]} thinking mode")
                if "recent_actions" in context and isinstance(context["recent_actions"], list):
                    actions = context["recent_actions"]
                    if len(actions) >= 2:
                        last_action = actions[-1]
                        if isinstance(last_action, dict) and last_action.get("success", False):
                            potential_biases.append("Potential recency bias - overweighting last successful action")
                if potential_biases:
                    reflections.append({
                        "area": "cognitive_bias",
                        "content": potential_biases[0],
                        "recommendation": "Consider deliberate perspective shifts to counteract"
                    })
        insights = []
        for reflection in reflections:
            area = reflection.get("area", "")
            assessment = reflection.get("assessment", "")
            recommendation = reflection.get("recommendation", "")
            if area == "learning_progress" and assessment == "needs improvement":
                insights.append("Learning rate below target - consider adjusting exploration/exploitation balance")
            elif area == "strategy_effectiveness" and recommendation:
                insights.append(recommendation)
            elif area == "error_patterns" and assessment == "concerning":
                insights.append("High error rate - implement additional validation measures")
            elif area == "goal_alignment" and assessment == "misaligned":
                insights.append("Actions not well-aligned with goals - revisit planning process")
            elif area == "cognitive_bias" and recommendation:
                insights.append(recommendation)
        thought["reflections"] = reflections
        thought["insights"] = insights
        importance = 0.5
        if insights:
            importance += 0.1 * len(insights)
        if "concerning" in str(reflections) or "misaligned" in str(reflections):
            importance += 0.2
        thought["importance"] = min(0.9, importance)
        if insights:
            thought["content"] = insights[0]
        elif reflections:
            thought["content"] = reflections[0].get("content", "Meta-cognitive reflection")
        return thought

    def _generate_exploratory_thought(self, context):
        """Generate an exploratory thought focused on new possibilities"""
        thought = {
            "type": "exploratory",
            "content": "Exploration of new possibilities",
            "directions": [],
            "insights": [],
            "importance": 0.5
        }
        exploration_areas = [
            "unknown_domains",
            "connection_patterns",
            "alternative_strategies",
            "capability_expansion"
        ]
        selected_areas = random.sample(exploration_areas, min(2, len(exploration_areas)))
        directions = []
        for area in selected_areas:
            if area == "unknown_domains":
                if "domains_visited" in context:
                    domains_visited = context.get("domains_visited", set())
                    if isinstance(domains_visited, set):
                        candidate_domains = [
                            "research.science", "github.com", "en.wikipedia.org",
                            "arxiv.org", "semanticscholar.org", "openai.com",
                            "nature.com", "reddit.com/r/MachineLearning"
                        ]
                        unvisited = [d for d in candidate_domains if d not in domains_visited]
                        if unvisited:
                            sample_domains = random.sample(unvisited, min(3, len(unvisited)))
                            directions.append({
                                "area": "unknown_domains",
                                "content": f"Explore high-value domains: {', '.join(sample_domains)}",
                                "rationale": "Expanding domain knowledge diversity"
                            })
            elif area == "connection_patterns":
                directions.append({
                    "area": "connection_patterns",
                    "content": "Implement knowledge graph traversal to find distant connections",
                    "rationale": "Distant domains often contain valuable cross-applicable patterns"
                })
            elif area == "alternative_strategies":
                if (hasattr(self.agent, 'planner_sifter') and
                    hasattr(self.agent.planner_sifter, 'strategies')):
                    strategies = list(self.agent.planner_sifter.strategies.keys())
                    if strategies:
                        if (hasattr(self.agent.planner_sifter, 'strategy_usage')):
                            usage = self.agent.planner_sifter.strategy_usage
                            least_used = sorted([(s, usage.get(s, 0)) for s in strategies], key=lambda x: x[1])
                            if least_used:
                                least_used_strategy = least_used[0][0]
                                directions.append({
                                    "area": "alternative_strategies",
                                    "content": f"Experiment with underutilized strategy: {least_used_strategy}",
                                    "rationale": "Diversifying strategic approaches to discover new optima"
                                })
            elif area == "capability_expansion":
                directions.append({
                    "area": "capability_expansion",
                    "content": "Develop enhanced semantic reasoning module",
                    "rationale": "Would significantly improve knowledge integration capabilities"
                })
        insights = []
        for direction in directions:
            area = direction.get("area", "")
            rationale = direction.get("rationale", "")
            if area == "unknown_domains":
                insights.append("Systematic exploration of high-value domains should be prioritized")
            elif area == "connection_patterns":
                insights.append("Knowledge value may lie in unexpected cross-domain connections")
            elif area == "alternative_strategies":
                insights.append("Strategic diversification may uncover more effective approaches")
            elif area == "capability_expansion":
                insights.append("Capability development should focus on knowledge integration")
        thought["directions"] = directions
        thought["insights"] = insights
        if insights:
            thought["importance"] = 0.6 + 0.1 * len(insights)
        if insights:
            thought["content"] = insights[0]
        elif directions:
            thought["content"] = directions[0].get("content", "Exploration suggestion")
        return thought

    def _generate_critical_thought(self, context):
        """Generate a critical thought focused on evaluation and assessment"""
        thought = {
            "type": "critical",
            "content": "Critical evaluation",
            "assessments": [],
            "insights": [],
            "importance": 0.5
        }
        assessment_areas = [
            "information_quality",
            "reasoning_validity",
            "strategy_efficiency",
            "resource_allocation",
            "error_handling"
        ]
        selected_areas = random.sample(assessment_areas, min(2, len(assessment_areas)))
        assessments = []
        for area in selected_areas:
            if area == "information_quality":
                if (hasattr(self.agent, 'free_will') and
                    hasattr(self.agent.free_will, 'domain_intelligence')):
                    intelligence = self.agent.free_will.domain_intelligence
                    if hasattr(intelligence, 'domain_knowledge'):
                        knowledge = intelligence.domain_knowledge
                        if knowledge:
                            low_quality_domains = []
                            for domain, data in knowledge.items():
                                if isinstance(data, dict) and data.get("content_quality", 1.0) < 0.5:
                                    low_quality_domains.append(domain)
                            if low_quality_domains:
                                sample_domains = random.sample(low_quality_domains, min(2, len(low_quality_domains)))
                                assessments.append({
                                    "area": "information_quality",
                                    "content": f"Low-quality content detected in domains: {', '.join(sample_domains)}",
                                    "recommendation": "Implement stricter quality thresholds for these domains"
                                })
                            else:
                                assessments.append({
                                    "area": "information_quality",
                                    "content": "Overall information quality appears acceptable",
                                    "recommendation": "Continue regular quality monitoring"
                                })
            elif area == "reasoning_validity":
                if self.thought_history:
                    recent_thoughts = self.thought_history[-10:] if len(self.thought_history) >= 10 else self.thought_history
                    thought_types = set(t.get("type", "") for t in recent_thoughts)
                    if len(thought_types) < 3:
                        assessments.append({
                            "area": "reasoning_validity",
                            "content": f"Limited cognitive diversity detected (only {len(thought_types)} thought types used recently)",
                            "recommendation": "Deliberately activate more diverse thinking modes"
                        })
                    else:
                        assessments.append({
                            "area": "reasoning_validity",
                            "content": f"Cognitive diversity appears healthy ({len(thought_types)} different thought types used recently)",
                            "recommendation": "Maintain diverse thinking patterns"
                        })
            elif area == "strategy_efficiency":
                if (hasattr(self.agent, 'stats') and
                    isinstance(self.agent.stats, dict) and
                    'cycles_run' in self.agent.stats and
                    'pages_processed' in self.agent.stats):
                    cycles = self.agent.stats['cycles_run']
                    pages = self.agent.stats['pages_processed']
                    if cycles > 10:
                        efficiency = pages / max(1, cycles)
                        if efficiency < 0.5:
                            assessments.append({
                                "area": "strategy_efficiency",
                                "content": f"Low efficiency detected: {efficiency:.2f} pages/cycle",
                                "recommendation": "Consider more aggressive pruning of low-value paths"
                            })
                        else:
                            assessments.append({
                                "area": "strategy_efficiency",
                                "content": f"Acceptable efficiency: {efficiency:.2f} pages/cycle",
                                "recommendation": "Continue current approach with regular efficiency monitoring"
                            })
            elif area == "resource_allocation":
                if (hasattr(self.agent, 'memory') and
                    hasattr(self.agent, 'free_will') and
                    hasattr(self.agent.free_will, 'memory_set')):
                    memory_usage = len(self.agent.memory) / MEMORY_MAX_SIZE
                    urls_stored = len(self.agent.free_will.memory_set)
                    if memory_usage > 0.8 and urls_stored > 1000:
                        assessments.append({
                            "area": "resource_allocation",
                            "content": f"High memory usage ({memory_usage:.0%}) with {urls_stored} URLs stored",
                            "recommendation": "Implement more aggressive memory pruning strategy"
                        })
                    else:
                        assessments.append({
                            "area": "resource_allocation",
                            "content": f"Memory usage ({memory_usage:.0%}) with {urls_stored} URLs stored",
                            "recommendation": "Current resource allocation appears appropriate"
                        })
            elif area == "error_handling":
                if (hasattr(self.agent, 'domain_stats') and isinstance(self.agent.domain_stats, dict)):
                    total_visits = sum(d.get("visits", 0) for d in self.agent.domain_stats.values())
                    total_errors = sum(d.get("error_count", 0) for d in self.agent.domain_stats.values())
                    if total_visits > 0:
                        error_rate = total_errors / total_visits
                        if error_rate > 0.2:
                            assessments.append({
                                "area": "error_handling",
                                "content": f"High system-wide error rate: {error_rate:.2%}",
                                "recommendation": "Investigate error causes and implement more robust handling"
                            })
                        else:
                            assessments.append({
                                "area": "error_handling",
                                "content": f"Acceptable error rate: {error_rate:.2%}",
                                "recommendation": "Continue monitoring error patterns"
                            })
        insights = []
        for assessment in assessments:
            recommendation = assessment.get("recommendation", "")
            if "low-quality" in assessment.get("content", "").lower():
                insights.append("Information quality control needs improvement")
            elif "limited cognitive diversity" in assessment.get("content", "").lower():
                insights.append("Need to activate more diverse thinking patterns")
            elif "low efficiency" in assessment.get("content", "").lower():
                insights.append("Strategy efficiency requires optimization")
            elif "high memory usage" in assessment.get("content", "").lower():
                insights.append("Memory management needs more efficient pruning")
            elif "high system-wide error" in assessment.get("content", "").lower():
                insights.append("Error handling systems require review and enhancement")
            elif recommendation:
                insights.append(recommendation)
        thought["assessments"] = assessments
        thought["insights"] = insights
        importance = 0.5
        if insights:
            importance += 0.1 * len(insights)
        if any("high" in a.get("content", "").lower() for a in assessments):
            importance += 0.2
        thought["importance"] = min(0.9, importance)
        if insights:
            thought["content"] = insights[0]
        elif assessments:
            thought["content"] = assessments[0].get("content", "Critical assessment")
        return thought

    def _generate_integrative_thought(self, context):
        """Generate an integrative thought focused on knowledge synthesis"""
        thought = {
            "type": "integrative",
            "content": "Knowledge synthesis",
            "connections": [],
            "insights": [],
            "importance": 0.5
        }
        connections = []
        if not context:
            thought["content"] = "Insufficient knowledge for meaningful integration"
            return thought
        elements = {}
        if "domains_visited" in context:
            domains = context.get("domains_visited", set())
            if isinstance(domains, set) and len(domains) > 3:
                elements["domains"] = list(domains)
        if hasattr(self.agent, 'content_sifter'):
            sifter = self.agent.content_sifter
            if hasattr(sifter, 'topics_of_interest'):
                elements["topics"] = sifter.topics_of_interest
        if (hasattr(self.agent, 'ai_manager') and
            hasattr(self.agent.ai_manager, 'temporal_planner') and
            hasattr(self.agent.ai_manager.temporal_planner, 'long_term_goals')):
            goals = self.agent.ai_manager.temporal_planner.long_term_goals
            if goals:
                elements["goals"] = [g.get("description", "") for g in goals]
        if len(elements) >= 2:
            element_types = list(elements.keys())
            type_pair = random.sample(element_types, 2)
            elements_1 = elements[type_pair[0]]
            elements_2 = elements[type_pair[1]]
            if elements_1 and elements_2:
                element_1 = random.choice(elements_1)
                element_2 = random.choice(elements_2)
                connections.append({
                    "elements": [
                        {"type": type_pair[0], "value": element_1},
                        {"type": type_pair[1], "value": element_2}
                    ],
                    "connection_type": "integration",
                    "description": f"Integration of {type_pair[0]} '{element_1}' with {type_pair[1]} '{element_2}'",
                    "potential": random.uniform(0.5, 0.9)
                })
        if not connections:
            theoretical_connections = [
                {
                    "elements": [
                        {"type": "cognitive_mode", "value": "analytical"},
                        {"type": "capability", "value": "semantic_representation"}
                    ],
                    "connection_type": "enhancement",
                    "description": "Analytical thinking could enhance semantic representation quality",
                    "potential": 0.7
                },
                {
                    "elements": [
                        {"type": "capability", "value": "memory_management"},
                        {"type": "capability", "value": "planning"}
                    ],
                    "connection_type": "synergy",
                    "description": "Memory systems could be more tightly integrated with planning",
                    "potential": 0.8
                }
            ]
            connections.append(random.choice(theoretical_connections))
        insights = []
        for connection in connections:
            desc = connection.get("description", "")
            conn_type = connection.get("connection_type", "")
            potential = connection.get("potential", 0.5)
            if conn_type == "integration" and potential > 0.7:
                insights.append(f"High potential integration opportunity: {desc}")
            elif conn_type == "enhancement":
                insights.append(f"Enhancement pathway identified: {desc}")
            elif conn_type == "synergy":
                insights.append(f"Synergistic relationship would increase capability: {desc}")
            else:
                insights.append(f"Connection opportunity: {desc}")
        thought["connections"] = connections
        thought["insights"] = insights
        importance = 0.5
        if connections:
            avg_potential = sum(c.get("potential", 0.5) for c in connections) / len(connections)
            importance = avg_potential
        thought["importance"] = min(0.9, importance)
        if insights:
            thought["content"] = insights[0]
        elif connections:
            thought["content"] = connections[0].get("description", "Knowledge integration")
        return thought

    def _generate_intuitive_thought(self, context):
        """Generate an intuitive thought focused on pattern recognition"""
        thought = {
            "type": "intuitive",
            "content": "Pattern recognition",
            "patterns": [],
            "insights": [],
            "importance": 0.5
        }
        patterns = []
        if not context:
            thought["content"] = "Insufficient data for pattern recognition"
            return thought
        if "recent_actions" in context and isinstance(context["recent_actions"], list):
            actions = context["recent_actions"]
            if len(actions) >= 3:
                action_types = [a.get("action", "unknown") for a in actions if isinstance(a, dict)]
                if len(action_types) >= 3:
                    repetitions = []
                    current_sequence = [action_types[0]]
                    for i in range(1, len(action_types)):
                        if action_types[i] == action_types[i-1]:
                            current_sequence.append(action_types[i])
                        else:
                            if len(current_sequence) >= 2:
                                repetitions.append(current_sequence)
                            current_sequence = [action_types[i]]
                    if len(current_sequence) >= 2:
                        repetitions.append(current_sequence)
                    if repetitions:
                        longest_repetition = max(repetitions, key=len)
                        patterns.append({
                            "type": "action_repetition",
                            "description": f"Repeated sequence of '{longest_repetition[0]}' actions",
                            "significance": 0.6 + 0.1 * min(4, len(longest_repetition)),
                            "potential_cause": "Strategy fixation or optimal local strategy"
                        })
                    if len(set(action_types)) == 2 and len(action_types) >= 4:
                        is_alternating = True
                        for i in range(2, len(action_types)):
                            if action_types[i] != action_types[i-2]:
                                is_alternating = False
                                break
                        if is_alternating:
                            patterns.append({
                                "type": "action_alternation",
                                "description": f"Alternating pattern between '{action_types[0]}' and '{action_types[1]}'",
                                "significance": 0.7,
                                "potential_cause": "Explore-exploit cycle or complementary strategies"
                            })
        if "domain_stats" in context and isinstance(context["domain_stats"], dict):
            domains = context["domain_stats"]
            if domains:
                frequent_domains = sorted(
                    [(d, stats.get("visits", 0)) for d, stats in domains.items()],
                    key=lambda x: x[1],
                    reverse=True
                )
                if frequent_domains:
                    top_domains = frequent_domains[:3]
                    total_visits = sum(v for _, v in frequent_domains)
                    top_domain_visits = sum(v for _, v in top_domains)
                    concentration = top_domain_visits / max(1, total_visits)
                    if concentration > 0.7:
                        patterns.append({
                            "type": "domain_concentration",
                            "description": f"Heavy concentration ({concentration:.0%}) on top 3 domains",
                            "significance": 0.7,
                            "potential_cause": "Exploitation focus or domain specialization"
                        })
        if "domain_stats" in context and isinstance(context["domain_stats"], dict):
            domains = context["domain_stats"]
            if domains:
                error_domains = []
                for domain, stats in domains.items():
                    if isinstance(stats, dict) and stats.get("error_rate", 0) > 0.3:
                        error_domains.append((domain, stats.get("error_rate", 0)))
                if error_domains:
                    error_domains.sort(key=lambda x: x[1], reverse=True)
                    top_error_domains = error_domains[:3]
                    patterns.append({
                        "type": "error_concentration",
                        "description": f"High error rates in specific domains: {', '.join(d for d, _ in top_error_domains)}",
                        "significance": 0.8,
                        "potential_cause": "Domain-specific access issues or content filtering problems"
                    })
        insights = []
        for pattern in patterns:
            pattern_type = pattern.get("type", "")
            significance = pattern.get("significance", 0.5)
            if pattern_type == "action_repetition" and significance > 0.7:
                insights.append("Repeated action pattern may indicate strategy fixation - consider forcing exploration")
            elif pattern_type == "action_alternation":
                insights.append("Alternating action pattern suggests systematic exploration-exploitation approach")
            elif pattern_type == "domain_concentration":
                insights.append("High domain concentration indicates need for broader exploration")
            elif pattern_type == "error_concentration":
                insights.append("Domain-specific error pattern detected - consider domain-specific handling strategies")
        thought["patterns"] = patterns
        thought["insights"] = insights
        importance = 0.5
        if patterns:
            avg_significance = sum(p.get("significance", 0.5) for p in patterns) / len(patterns)
            importance = avg_significance
        thought["importance"] = min(0.9, importance)
        if insights:
            thought["content"] = insights[0]
        elif patterns:
            thought["content"] = patterns[0].get("description", "Pattern detected")
        return thought

class AutonomousMind:
    """
    Integrated cognitive system that coordinates high-level thinking processes
    and manages the agent's internal cognitive states and modes.
    """
    def __init__(self, agent, model):
        self.agent = agent
        self.model = model
        self.thought_history = []
        self.cognitive_states = {
            "analytical": {"description": "Logical problem solving with structured reasoning", "activation": 0.5},
            "creative": {"description": "Divergent thinking with novel connections", "activation": 0.5},
            "reflective": {"description": "Meta-cognitive examination of own thoughts", "activation": 0.5},
            "exploratory": {"description": "Curious investigation of new information", "activation": 0.5},
            "critical": {"description": "Evaluative assessment with skepticism", "activation": 0.5},
            "integrative": {"description": "Synthesis of diverse knowledge", "activation": 0.5},
            "intuitive": {"description": "Fast pattern recognition", "activation": 0.5},
            "balanced": {"description": "Equilibrium of multiple modes", "activation": 0.5}
        }
        self.current_mode = "balanced"  # Default mode
        self.attention_focus = None  # Current attentional focus
        self.working_memory = []  # Active concepts and thoughts
        self.working_memory_capacity = 7  # Miller's magical number
        self.cognitive_load = 0.5  # Current processing load (0.0-1.0)
        self.thought_depth = 0.5  # Depth vs. breadth of thinking (0.0-1.0)
        self.concept_activation_threshold = 0.3  # Min activation for attention
        self.mode_shift_probability = 0.2  # Probability of spontaneous mode shift
        self.recent_insights = []  # Store recent important realizations

        # Thinking style parameters
        self.thinking_style = {
            "abstraction_level": 0.6,  # Concrete (0.0) to abstract (1.0)
            "linearity": 0.5,  # Linear (0.0) to non-linear (1.0)
            "deductive_inductive_balance": 0.5,  # Deductive (0.0) to inductive (1.0)
            "risk_tolerance": 0.4,  # Risk-averse (0.0) to risk-seeking (1.0)
            "concept_granularity": 0.5  # Fine-grained (0.0) to coarse-grained (1.0)
        }

        log_event("AutonomousMind initialized in balanced cognitive mode", "INFO")

    def think(self, context=None):
        """
        Execute a thinking cycle to generate insights, shift cognitive modes,
        and update internal state based on current context.

        Parameters:
        - context: Current perceptual and memory context

        Returns:
        - Thought result containing insights and state changes
        """
        # Update cognitive load based on context complexity
        self._update_cognitive_load(context)

        # Consider shifting cognitive mode
        self._consider_mode_shift(context)

        # Generate thought based on current mode and context
        thought = self._generate_thought(context)

        # Update working memory
        self._update_working_memory(thought)

        # Store in thought history
        self.thought_history.append({
            "thought": thought,
            "mode": self.current_mode,
            "timestamp": datetime.now().isoformat(),
            "context": self._summarize_context(context)
        })

        # Trim history if needed
        if len(self.thought_history) > 100:
            self.thought_history = self.thought_history[-100:]

        return thought

    def _update_cognitive_load(self, context):
        """Update cognitive load based on context complexity"""
        if not context:
            # Default slight reduction in cognitive load when no new input
            self.cognitive_load = max(0.1, self.cognitive_load * 0.9)
            return

        # Estimate context complexity
        complexity = 0.5  # Default medium complexity

        # Adjust based on context details if available
        if isinstance(context, dict):
            # More elements = higher complexity
            complexity += min(0.3, len(context) * 0.02)

            # Check for special high-complexity elements
            if "error" in context or "anomaly" in context:
                complexity += 0.2

            # High memory usage increases cognitive load
            if "memory_size" in context:
                memory_usage = context["memory_size"] / MEMORY_MAX_SIZE
                complexity += memory_usage * 0.2

            # Multiple recent actions increase complexity
            if "recent_actions" in context and isinstance(context["recent_actions"], list):
                complexity += min(0.1, len(context["recent_actions"]) * 0.02)

        # Dynamically adjust cognitive load
        # New complexity pulls the current load toward itself
        adjustment_rate = 0.3  # How quickly load adjusts
        self.cognitive_load = self.cognitive_load * (1 - adjustment_rate) + complexity * adjustment_rate

        # Ensure within bounds
        self.cognitive_load = max(0.1, min(0.9, self.cognitive_load))

    def _consider_mode_shift(self, context):
        """Consider shifting cognitive mode based on context and internal state"""
        # Base probability of mode shift
        shift_probability = self.mode_shift_probability

        # Adjust based on cognitive load - higher load may require mode shift
        if self.cognitive_load > 0.7:
            shift_probability += 0.2

        # Check if we should shift
        if random.random() >= shift_probability:
            return  # No shift this cycle

        # Current active states
        active_states = {state: data["activation"] for state, data in self.cognitive_states.items()
                       if data["activation"] >= self.concept_activation_threshold}

        # Context-based mode selection
        new_mode = self._select_appropriate_mode(context, active_states)

        # If new mode is different, make the shift
        if new_mode and new_mode != self.current_mode:
            old_mode = self.current_mode
            self.current_mode = new_mode

            log_event(f"Cognitive mode shifted: {old_mode} â†’ {new_mode}", "INFO")

            # Adjust activations - boost new mode, slightly reduce others
            for state in self.cognitive_states:
                if state == new_mode:
                    self.cognitive_states[state]["activation"] = min(0.9, self.cognitive_states[state]["activation"] + 0.2)
                else:
                    self.cognitive_states[state]["activation"] = max(0.1, self.cognitive_states[state]["activation"] * 0.9)

    def _select_appropriate_mode(self, context, active_states):
        """
        Select most appropriate cognitive mode based on context.

        Parameters:
        - context: Current context dictionary
        - active_states: Dictionary of currently active cognitive states

        Returns:
        - Selected mode name
        """
        if not context:
            # Without context, weighted random selection from active states
            if active_states:
                states = list(active_states.keys())
                weights = [active_states[s] for s in states]
                return random.choices(states, weights=weights, k=1)[0]
            else:
                return "balanced"  # Default fallback

        # Context-based selection
        mode_scores = {mode: 0.0 for mode in self.cognitive_states}

        # 1. Check for error or anomaly - activates critical mode
        if "error" in context or "anomaly" in context:
            mode_scores["critical"] += 0.5

        # 2. Check for exploration needs
        if self._context_indicates_exploration(context):
            mode_scores["exploratory"] += 0.4
            mode_scores["creative"] += 0.3

        # 3. Check for complex problem solving
        if self._context_indicates_complex_problem(context):
            mode_scores["analytical"] += 0.5
            mode_scores["integrative"] += 0.3

        # 4. Check for learning and reflection needs
        if self._context_indicates_reflection(context):
            mode_scores["reflective"] += 0.5

        # 5. Check for pattern recognition needs
        if self._context_indicates_pattern_recognition(context):
            mode_scores["intuitive"] += 0.4

        # 6. Add random factor for exploration
        for mode in mode_scores:
            mode_scores[mode] += random.uniform(0, 0.2)

        # 7. Add existing activation bias
        for mode, activation in active_states.items():
            mode_scores[mode] += activation * 0.3

        # Select highest scoring mode
        if mode_scores:
            top_mode = max(mode_scores.items(), key=lambda x: x[1])[0]
            return top_mode
        else:
            return "balanced"  # Default fallback

    def _context_indicates_exploration(self, context):
        """Check if context suggests exploration needs"""
        if not context or not isinstance(context, dict):
            return False

        indicators = 0

        # Looking for exploration indicators
        if "current_goal" in context and isinstance(context["current_goal"], dict):
            goal_desc = context["current_goal"].get("description", "").lower()
            if "explor" in goal_desc or "discover" in goal_desc:
                indicators += 1

        # Few domains visited suggests exploration need
        if "domains_visited" in context:
            domains = context["domains_visited"]
            if isinstance(domains, set) and len(domains) < 10:
                indicators += 1

        # Current mode includes exploration elements
        if context.get("thinking_mode") in ["exploratory", "creative"]:
            indicators += 1

        return indicators >= 1

    def _context_indicates_complex_problem(self, context):
        """Check if context suggests complex problem solving needs"""
        if not context or not isinstance(context, dict):
            return False

        indicators = 0

        # Goals with certain keywords
        if "current_goal" in context and isinstance(context["current_goal"], dict):
            goal_desc = context["current_goal"].get("description", "").lower()
            complex_terms = ["optim", "improv", "analy", "solv", "complex"]
            if any(term in goal_desc for term in complex_terms):
                indicators += 1

        # High cognitive load suggests complex problem
        if self.cognitive_load > 0.7:
            indicators += 1

        # Current analytical thinking mode
        if context.get("thinking_mode") in ["analytical", "critical"]:
            indicators += 1

        return indicators >= 1

    def _context_indicates_reflection(self, context):
        """Check if context suggests reflection needs"""
        if not context or not isinstance(context, dict):
            return False

        indicators = 0

        # Goals with reflection keywords
        if "current_goal" in context and isinstance(context["current_goal"], dict):
            goal_desc = context["current_goal"].get("description", "").lower()
            reflection_terms = ["reflect", "learn", "adapt", "improv", "assess"]
            if any(term in goal_desc for term in reflection_terms):
                indicators += 1

        # After many actions, reflection is valuable
        if "stats" in context and isinstance(context["stats"], dict):
            cycles = context["stats"].get("cycles_run", 0)
            if cycles > 0 and cycles % 10 == 0:  # Every 10 cycles
                indicators += 1

        # Current reflective thinking mode
        if context.get("thinking_mode") == "reflective":
            indicators += 1

        return indicators >= 1

    def _context_indicates_pattern_recognition(self, context):
        """Check if context suggests pattern recognition needs"""
        if not context or not isinstance(context, dict):
            return False

        indicators = 0

        # Domain stats suggest pattern recognition
        if "domain_stats" in context and isinstance(context["domain_stats"], dict):
            # Many domains = opportunity for pattern recognition
            if len(context["domain_stats"]) > 5:
                indicators += 1

        # Multiple recent actions create patterns
        if "recent_actions" in context and isinstance(context["recent_actions"], list):
            if len(context["recent_actions"]) >= 3:
                indicators += 1

        # Current intuitive mode
        if context.get("thinking_mode") == "intuitive":
            indicators += 1

        return indicators >= 1

    def _generate_thought(self, context):
        """
        Generate a thought based on current cognitive mode and context.

        Parameters:
        - context: Current context dictionary

        Returns:
        - Generated thought dictionary
        """
        # Each cognitive mode has a different thought generation approach
        if self.current_mode == "analytical":
            return self._generate_analytical_thought(context)
        elif self.current_mode == "creative":
            return self._generate_creative_thought(context)
        elif self.current_mode == "reflective":
            return self._generate_reflective_thought(context)
        elif self.current_mode == "exploratory":
            return self._generate_exploratory_thought(context)
        elif self.current_mode == "critical":
            return self._generate_critical_thought(context)
        elif self.current_mode == "integrative":
            return self._generate_integrative_thought(context)
        elif self.current_mode == "intuitive":
            return self._generate_intuitive_thought(context)
        else:  # balanced or any other
            return self._generate_balanced_thought(context)

    def _generate_analytical_thought(self, context):
        """Generate an analytical thought focused on logical problem solving"""
        # Default analytical thought structure
        thought = {
            "type": "analytical",
            "content": "Systematic analysis of current state and options",
            "components": [],
            "insights": [],
            "importance": 0.5
        }

        # Without context, generate generic analytical thought
        if not context:
            thought["content"] = "Need more information to perform proper analysis"
            return thought

        # Analytical components based on context
        components = []

        # Analyze current goal if available
        if "current_goal" in context and isinstance(context["current_goal"], dict):
            goal = context["current_goal"]
            components.append({
                "focus": "goal_analysis",
                "content": f"Analyzing goal: {goal.get('description', 'unknown')}",
                "priority": goal.get("priority", 0.5)
            })

        # Analyze recent actions if available
        if "recent_actions" in context and isinstance(context["recent_actions"], list):
            actions = context["recent_actions"]
            if actions:
                action_types = [a.get("action", "unknown") for a in actions if isinstance(a, dict)]
                components.append({
                    "focus": "action_pattern_analysis",
                    "content": f"Recent action sequence: {' â†’ '.join(action_types)}",
                    "outcome_assessment": self._assess_action_outcomes(actions)
                })

        # Analyze domain statistics if available
        if "domain_stats" in context and isinstance(context["domain_stats"], dict):
            domains = context["domain_stats"]
            if domains:
                high_error_domains = [d for d, stats in domains.items()
                                    if isinstance(stats, dict) and stats.get("error_rate", 0) > 0.3]
                if high_error_domains:
                    components.append({
                        "focus": "error_analysis",
                        "content": f"High error rates detected in domains: {', '.join(high_error_domains[:3])}",
                        "recommendation": "Investigate causes or avoid these domains temporarily"
                    })

        # Generate insights based on analysis
        insights = []

        # Derive insights from components
        for component in components:
            if component["focus"] == "goal_analysis" and component.get("priority", 0) > 0.7:
                insights.append("Current goal is high priority - allocate additional resources")
            elif component["focus"] == "action_pattern_analysis":
                outcome = component.get("outcome_assessment")
                if outcome == "deteriorating":
                    insights.append("Action patterns show declining effectiveness - strategy change needed")
                elif outcome == "improving":
                    insights.append("Action patterns show improving outcomes - continue current approach")
            elif component["focus"] == "error_analysis":
                insights.append("Error pattern analysis suggests need for improved domain validation")

        # Add components and insights to thought
        thought["components"] = components
        thought["insights"] = insights

        # Calculate importance based on components and insights
        if insights:
            thought["importance"] = 0.7

        # Generate summary content
        if insights:
            thought["content"] = f"Analytical conclusion: {insights[0]}"
        elif components:
            thought["content"] = f"Analysis of {len(components)} system components completed"

        return thought

    def _generate_creative_thought(self, context):
        """Generate a creative thought focused on novel connections"""
        # Default creative thought structure
        thought = {
            "type": "creative",
            "content": "Novel conceptual connection",
            "associations": [],
            "insights": [],
            "importance": 0.5
        }

        # Creative aspects to consider
        aspects = ["goals", "domains", "strategies", "patterns", "anomalies"]
        selected_aspects = random.sample(aspects, min(2, len(aspects)))

        # Generate random associations between selected aspects
        associations = []

        # Extract relevant elements from context
        elements = self._extract_elements_from_context(context, selected_aspects)

        # Generate associations between elements
        if len(elements) >= 2:
            # Take two random elements and create association
            element_pairs = []
            for i in range(min(3, len(elements))):
                pair = random.sample(elements, 2)
                element_pairs.append(pair)

            # Create associations from pairs
            for pair in element_pairs:
                association_templates = [
                    f"Unexpected connection between {pair[0]} and {pair[1]}",
                    f"{pair[0]} could be viewed through the lens of {pair[1]}",
                    f"What if the structure of {pair[0]} were applied to {pair[1]}?",
                    f"The patterns in {pair[0]} mirror aspects of {pair[1]} in a novel way"
                ]
                associations.append(random.choice(association_templates))
        else:
            # Fallback for limited context
            association_templates = [
                "Novel perspective: consider alternative goal structures",
                "What if search and evaluation were integrated more tightly?",
                "The pattern of successful interactions might reveal emergent properties"
            ]
            associations.append(random.choice(association_templates))

        # Generate insights from associations
        insights = []
        if associations:
            for association in associations:
                if "connection between" in association:
                    insights.append(f"Explore this connection to potentially develop new capabilities")
                elif "through the lens" in association:
                    insights.append(f"This perspective shift might reveal hidden patterns")
                elif "What if" in association:
                    insights.append(f"This hypothetical restructuring could improve system flexibility")
                else:
                    insights.append(f"This pattern recognition suggests deeper structural similarities")

        # Add associations and insights to thought
        thought["associations"] = associations
        thought["insights"] = insights

        # Calculate importance
        if insights:
            thought["importance"] = 0.6 + 0.1 * len(insights)



class AutonomousMind:
    """
    Integrated cognitive system that coordinates high-level thinking processes
    and manages the agent's internal cognitive states and modes.
    """
    def __init__(self, agent, model):
        self.agent = agent
        self.model = model
        self.thought_history = []
        self.cognitive_states = {
            "analytical": {"description": "Logical problem solving with structured reasoning", "activation": 0.5},
            "creative": {"description": "Divergent thinking with novel connections", "activation": 0.5},
            "reflective": {"description": "Meta-cognitive examination of own thoughts", "activation": 0.5},
            "exploratory": {"description": "Curious investigation of new information", "activation": 0.5},
            "critical": {"description": "Evaluative assessment with skepticism", "activation": 0.5},
            "integrative": {"description": "Synthesis of diverse knowledge", "activation": 0.5},
            "intuitive": {"description": "Fast pattern recognition", "activation": 0.5},
            "balanced": {"description": "Equilibrium of multiple modes", "activation": 0.5}
        }
        self.current_mode = "balanced"  # Default mode
        self.attention_focus = None  # Current attentional focus
        self.working_memory = []  # Active concepts and thoughts
        self.working_memory_capacity = 7  # Miller's magical number
        self.cognitive_load = 0.5  # Current processing load (0.0-1.0)
        self.thought_depth = 0.5  # Depth vs. breadth of thinking (0.0-1.0)
        self.concept_activation_threshold = 0.3  # Min activation for attention
        self.mode_shift_probability = 0.2  # Probability of spontaneous mode shift
        self.recent_insights = []  # Store recent important realizations

        # Thinking style parameters
        self.thinking_style = {
            "abstraction_level": 0.6,  # Concrete (0.0) to abstract (1.0)
            "linearity": 0.5,  # Linear (0.0) to non-linear (1.0)
            "deductive_inductive_balance": 0.5,  # Deductive (0.0) to inductive (1.0)
            "risk_tolerance": 0.4,  # Risk-averse (0.0) to risk-seeking (1.0)
            "concept_granularity": 0.5  # Fine-grained (0.0) to coarse-grained (1.0)
        }

        log_event("AutonomousMind initialized in balanced cognitive mode", "INFO")

    def think(self, context=None):
        """
        Execute a thinking cycle to generate insights, shift cognitive modes,
        and update internal state based on current context.

        Parameters:
        - context: Current perceptual and memory context

        Returns:
        - Thought result containing insights and state changes
        """
        # Update cognitive load based on context complexity
        self._update_cognitive_load(context)

        # Consider shifting cognitive mode
        self._consider_mode_shift(context)

        # Generate thought based on current mode and context
        thought = self._generate_thought(context)

        # Update working memory
        self._update_working_memory(thought)

        # Store in thought history
        self.thought_history.append({
            "thought": thought,
            "mode": self.current_mode,
            "timestamp": datetime.now().isoformat(),
            "context": self._summarize_context(context)
        })

        # Trim history if needed
        if len(self.thought_history) > 100:
            self.thought_history = self.thought_history[-100:]

        return thought

    def _update_cognitive_load(self, context):
        """Update cognitive load based on context complexity"""
        if not context:
            # Default slight reduction in cognitive load when no new input
            self.cognitive_load = max(0.1, self.cognitive_load * 0.9)
            return

        # Estimate context complexity
        complexity = 0.5  # Default medium complexity

        # Adjust based on context details if available
        if isinstance(context, dict):
            # More elements = higher complexity
            complexity += min(0.3, len(context) * 0.02)

            # Check for special high-complexity elements
            if "error" in context or "anomaly" in context:
                complexity += 0.2

            # High memory usage increases cognitive load
            if "memory_size" in context:
                memory_usage = context["memory_size"] / MEMORY_MAX_SIZE
                complexity += memory_usage * 0.2

            # Multiple recent actions increase complexity
            if "recent_actions" in context and isinstance(context["recent_actions"], list):
                complexity += min(0.1, len(context["recent_actions"]) * 0.02)

        # Dynamically adjust cognitive load
        # New complexity pulls the current load toward itself
        adjustment_rate = 0.3  # How quickly load adjusts
        self.cognitive_load = self.cognitive_load * (1 - adjustment_rate) + complexity * adjustment_rate

        # Ensure within bounds
        self.cognitive_load = max(0.1, min(0.9, self.cognitive_load))

    def _consider_mode_shift(self, context):
        """Consider shifting cognitive mode based on context and internal state"""
        # Base probability of mode shift
        shift_probability = self.mode_shift_probability

        # Adjust based on cognitive load - higher load may require mode shift
        if self.cognitive_load > 0.7:
            shift_probability += 0.2

        # Check if we should shift
        if random.random() >= shift_probability:
            return  # No shift this cycle

        # Current active states
        active_states = {state: data["activation"] for state, data in self.cognitive_states.items()
                       if data["activation"] >= self.concept_activation_threshold}

        # Context-based mode selection
        new_mode = self._select_appropriate_mode(context, active_states)

        # If new mode is different, make the shift
        if new_mode and new_mode != self.current_mode:
            old_mode = self.current_mode
            self.current_mode = new_mode

            log_event(f"Cognitive mode shifted: {old_mode} â†’ {new_mode}", "INFO")

            # Adjust activations - boost new mode, slightly reduce others
            for state in self.cognitive_states:
                if state == new_mode:
                    self.cognitive_states[state]["activation"] = min(0.9, self.cognitive_states[state]["activation"] + 0.2)
                else:
                    self.cognitive_states[state]["activation"] = max(0.1, self.cognitive_states[state]["activation"] * 0.9)

    def _select_appropriate_mode(self, context, active_states):
        """
        Select most appropriate cognitive mode based on context.

        Parameters:
        - context: Current context dictionary
        - active_states: Dictionary of currently active cognitive states

        Returns:
        - Selected mode name
        """
        if not context:
            # Without context, weighted random selection from active states
            if active_states:
                states = list(active_states.keys())
                weights = [active_states[s] for s in states]
                return random.choices(states, weights=weights, k=1)[0]
            else:
                return "balanced"  # Default fallback

        # Context-based selection
        mode_scores = {mode: 0.0 for mode in self.cognitive_states}

        # 1. Check for error or anomaly - activates critical mode
        if "error" in context or "anomaly" in context:
            mode_scores["critical"] += 0.5

        # 2. Check for exploration needs
        if self._context_indicates_exploration(context):
            mode_scores["exploratory"] += 0.4
            mode_scores["creative"] += 0.3

        # 3. Check for complex problem solving
        if self._context_indicates_complex_problem(context):
            mode_scores["analytical"] += 0.5
            mode_scores["integrative"] += 0.3

        # 4. Check for learning and reflection needs
        if self._context_indicates_reflection(context):
            mode_scores["reflective"] += 0.5

        # 5. Check for pattern recognition needs
        if self._context_indicates_pattern_recognition(context):
            mode_scores["intuitive"] += 0.4

        # 6. Add random factor for exploration
        for mode in mode_scores:
            mode_scores[mode] += random.uniform(0, 0.2)

        # 7. Add existing activation bias
        for mode, activation in active_states.items():
            mode_scores[mode] += activation * 0.3

        # Select highest scoring mode
        if mode_scores:
            top_mode = max(mode_scores.items(), key=lambda x: x[1])[0]
            return top_mode
        else:
            return "balanced"  # Default fallback

    def _context_indicates_exploration(self, context):
        """Check if context suggests exploration needs"""
        if not context or not isinstance(context, dict):
            return False

        indicators = 0

        # Looking for exploration indicators
        if "current_goal" in context and isinstance(context["current_goal"], dict):
            goal_desc = context["current_goal"].get("description", "").lower()
            if "explor" in goal_desc or "discover" in goal_desc:
                indicators += 1

        # Few domains visited suggests exploration need
        if "domains_visited" in context:
            domains = context["domains_visited"]
            if isinstance(domains, set) and len(domains) < 10:
                indicators += 1

        # Current mode includes exploration elements
        if context.get("thinking_mode") in ["exploratory", "creative"]:
            indicators += 1

        return indicators >= 1

    def _context_indicates_complex_problem(self, context):
        """Check if context suggests complex problem solving needs"""
        if not context or not isinstance(context, dict):
            return False

        indicators = 0

        # Goals with certain keywords
        if "current_goal" in context and isinstance(context["current_goal"], dict):
            goal_desc = context["current_goal"].get("description", "").lower()
            complex_terms = ["optim", "improv", "analy", "solv", "complex"]
            if any(term in goal_desc for term in complex_terms):
                indicators += 1

        # High cognitive load suggests complex problem
        if self.cognitive_load > 0.7:
            indicators += 1

        # Current analytical thinking mode
        if context.get("thinking_mode") in ["analytical", "critical"]:
            indicators += 1

        return indicators >= 1

    def _context_indicates_reflection(self, context):
        """Check if context suggests reflection needs"""
        if not context or not isinstance(context, dict):
            return False

        indicators = 0

        # Goals with reflection keywords
        if "current_goal" in context and isinstance(context["current_goal"], dict):
            goal_desc = context["current_goal"].get("description", "").lower()
            reflection_terms = ["reflect", "learn", "adapt", "improv", "assess"]
            if any(term in goal_desc for term in reflection_terms):
                indicators += 1

        # After many actions, reflection is valuable
        if "stats" in context and isinstance(context["stats"], dict):
            cycles = context["stats"].get("cycles_run", 0)
            if cycles > 0 and cycles % 10 == 0:  # Every 10 cycles
                indicators += 1

        # Current reflective thinking mode
        if context.get("thinking_mode") == "reflective":
            indicators += 1

        return indicators >= 1

    def _context_indicates_pattern_recognition(self, context):
        """Check if context suggests pattern recognition needs"""
        if not context or not isinstance(context, dict):
            return False

        indicators = 0

        # Domain stats suggest pattern recognition
        if "domain_stats" in context and isinstance(context["domain_stats"], dict):
            # Many domains = opportunity for pattern recognition
            if len(context["domain_stats"]) > 5:
                indicators += 1

        # Multiple recent actions create patterns
        if "recent_actions" in context and isinstance(context["recent_actions"], list):
            if len(context["recent_actions"]) >= 3:
                indicators += 1

        # Current intuitive mode
        if context.get("thinking_mode") == "intuitive":
            indicators += 1

        return indicators >= 1

    def _generate_thought(self, context):
        """
        Generate a thought based on current cognitive mode and context.

        Parameters:
        - context: Current context dictionary

        Returns:
        - Generated thought dictionary
        """
        # Each cognitive mode has a different thought generation approach
        if self.current_mode == "analytical":
            return self._generate_analytical_thought(context)
        elif self.current_mode == "creative":
            return self._generate_creative_thought(context)
        elif self.current_mode == "reflective":
            return self._generate_reflective_thought(context)
        elif self.current_mode == "exploratory":
            return self._generate_exploratory_thought(context)
        elif self.current_mode == "critical":
            return self._generate_critical_thought(context)
        elif self.current_mode == "integrative":
            return self._generate_integrative_thought(context)
        elif self.current_mode == "intuitive":
            return self._generate_intuitive_thought(context)
        else:  # balanced or any other
            return self._generate_balanced_thought(context)

    def _generate_analytical_thought(self, context):
        """Generate an analytical thought focused on logical problem solving"""
        # Default analytical thought structure
        thought = {
            "type": "analytical",
            "content": "Systematic analysis of current state and options",
            "components": [],
            "insights": [],
            "importance": 0.5
        }

        # Without context, generate generic analytical thought
        if not context:
            thought["content"] = "Need more information to perform proper analysis"
            return thought

        # Analytical components based on context
        components = []

        # Analyze current goal if available
        if "current_goal" in context and isinstance(context["current_goal"], dict):
            goal = context["current_goal"]
            components.append({
                "focus": "goal_analysis",
                "content": f"Analyzing goal: {goal.get('description', 'unknown')}",
                "priority": goal.get("priority", 0.5)
            })

        # Analyze recent actions if available
        if "recent_actions" in context and isinstance(context["recent_actions"], list):
            actions = context["recent_actions"]
            if actions:
                action_types = [a.get("action", "unknown") for a in actions if isinstance(a, dict)]
                components.append({
                    "focus": "action_pattern_analysis",
                    "content": f"Recent action sequence: {' â†’ '.join(action_types)}",
                    "outcome_assessment": self._assess_action_outcomes(actions)
                })

        # Analyze domain statistics if available
        if "domain_stats" in context and isinstance(context["domain_stats"], dict):
            domains = context["domain_stats"]
            if domains:
                high_error_domains = [d for d, stats in domains.items()
                                    if isinstance(stats, dict) and stats.get("error_rate", 0) > 0.3]
                if high_error_domains:
                    components.append({
                        "focus": "error_analysis",
                        "content": f"High error rates detected in domains: {', '.join(high_error_domains[:3])}",
                        "recommendation": "Investigate causes or avoid these domains temporarily"
                    })

        # Generate insights based on analysis
        insights = []

        # Derive insights from components
        for component in components:
            if component["focus"] == "goal_analysis" and component.get("priority", 0) > 0.7:
                insights.append("Current goal is high priority - allocate additional resources")
            elif component["focus"] == "action_pattern_analysis":
                outcome = component.get("outcome_assessment")
                if outcome == "deteriorating":
                    insights.append("Action patterns show declining effectiveness - strategy change needed")
                elif outcome == "improving":
                    insights.append("Action patterns show improving outcomes - continue current approach")
            elif component["focus"] == "error_analysis":
                insights.append("Error pattern analysis suggests need for improved domain validation")

        # Add components and insights to thought
        thought["components"] = components
        thought["insights"] = insights

        # Calculate importance based on components and insights
        if insights:
            thought["importance"] = 0.7

        # Generate summary content
        if insights:
            thought["content"] = f"Analytical conclusion: {insights[0]}"
        elif components:
            thought["content"] = f"Analysis of {len(components)} system components completed"

        return thought

    def _generate_creative_thought(self, context):
        """Generate a creative thought focused on novel connections"""
        # Default creative thought structure
        thought = {
            "type": "creative",
            "content": "Novel conceptual connection",
            "associations": [],
            "insights": [],
            "importance": 0.5
        }

        # Creative aspects to consider
        aspects = ["goals", "domains", "strategies", "patterns", "anomalies"]
        selected_aspects = random.sample(aspects, min(2, len(aspects)))

        # Generate random associations between selected aspects
        associations = []

        # Extract relevant elements from context
        elements = self._extract_elements_from_context(context, selected_aspects)

        # Generate associations between elements
        if len(elements) >= 2:
            # Take two random elements and create association
            element_pairs = []
            for i in range(min(3, len(elements))):
                pair = random.sample(elements, 2)
                element_pairs.append(pair)

            # Create associations from pairs
            for pair in element_pairs:
                association_templates = [
                    f"Unexpected connection between {pair[0]} and {pair[1]}",
                    f"{pair[0]} could be viewed through the lens of {pair[1]}",
                    f"What if the structure of {pair[0]} were applied to {pair[1]}?",
                    f"The patterns in {pair[0]} mirror aspects of {pair[1]} in a novel way"
                ]
                associations.append(random.choice(association_templates))
        else:
            # Fallback for limited context
            association_templates = [
                "Novel perspective: consider alternative goal structures",
                "What if search and evaluation were integrated more tightly?",
                "The pattern of successful interactions might reveal emergent properties"
            ]
            associations.append(random.choice(association_templates))

        # Generate insights from associations
        insights = []
        if associations:
            for association in associations:
                if "connection between" in association:
                    insights.append(f"Explore this connection to potentially develop new capabilities")
                elif "through the lens" in association:
                    insights.append(f"This perspective shift might reveal hidden patterns")
                elif "What if" in association:
                    insights.append(f"This hypothetical restructuring could improve system flexibility")
                else:
                    insights.append(f"This pattern recognition suggests deeper structural similarities")

        # Add associations and insights to thought
        thought["associations"] = associations
        thought["insights"] = insights

        # Calculate importance
        if insights:
            thought["importance"] = 0.6 + 0.1 * len(insights)


def _apply_learning_rate_safeguards(self, new_lr):
    """Prevent learning rate from spiraling into oblivion"""
    # Establish absolute minimum learning rate
    ABSOLUTE_MIN_LR = 5e-6

    if new_lr < ABSOLUTE_MIN_LR:
        log_event(f"Learning rate hit critical threshold: {new_lr:.8f}, resetting to {ABSOLUTE_MIN_LR:.6f}", "WARNING")
        return ABSOLUTE_MIN_LR

    # Prevent excessive downward adjustment
    if self.learning_rate_history and new_lr < self.learning_rate_history[-1] * 0.5:
        safer_lr = self.learning_rate_history[-1] * 0.8
        log_event(f"Excessive LR reduction prevented: {new_lr:.8f} â†’ {safer_lr:.6f}", "INFO")
        return safer_lr

    return new_lr









=============================================================================
                    QUANTUM NEXUS THERAPEUTIC DEVELOPMENT REPORT
=============================================================================
{title}
Generated: {generation_date}

-----------------------------------------------------------------------------
                           EXECUTIVE SUMMARY
-----------------------------------------------------------------------------
SUBSTANCE: {substance_name}
TARGET CONDITION: {problem_name}
THERAPEUTIC APPROACH: {approach}
TARGET: {target}
MECHANISM OF ACTION: {moa}

DESCRIPTION:
{description}

KEY HIGHLIGHTS:
{chr(10).join('â€¢ ' + highlight for highlight in highlights)}

-----------------------------------------------------------------------------
                          EFFICACY & SAFETY PROFILE
-----------------------------------------------------------------------------
EFFICACY SCORE: {efficacy_score:.2f}/1.00
SAFETY SCORE: {safety_score:.2f}/1.00
OVERALL SCORE: {overall_score}/100

EFFICACY STRENGTHS:
{chr(10).join('â€¢ ' + strength for strength in efficacy_strengths)}

SAFETY CONSIDERATIONS:
{chr(10).join('â€¢ ' + risk for risk in safety_risks)}

-----------------------------------------------------------------------------
                          FINAL ASSESSMENT
-----------------------------------------------------------------------------
RECOMMENDATION:
{recommendation}

NEXT STEPS:
{chr(10).join('â€¢ ' + step for step in next_steps)}

CONCLUSIONS:
{chr(10).join('â€¢ ' + conclusion for conclusion in conclusions)}

=============================================================================
                          END OF REPORT
=============================================================================

        
    def get_statistics(self):
        """
        Get comprehensive statistics about the therapeutic generation system's operations.
        
        Returns:
        - Dictionary with system statistics
        """
        stats = {
            "problems_identified": len(self.health_problems_registry),
            "substances_designed": len(self.substance_database),
            "simulations_run": len(self.simulation_results),
            "refinements_performed": len(self.refinement_history),
            "evaluations_completed": len(self.efficacy_ratings),
            
            "problem_domains": {},
            "therapeutic_approaches": {},
            "efficacy_distribution": {
                "poor": 0,  # 0-0.4
                "moderate": 0,  # 0.4-0.7
                "good": 0,  # 0.7-0.9
                "excellent": 0   # 0.9-1.0
            },
            "safety_distribution": {
                "poor": 0,  # 0-0.4
                "moderate": 0,  # 0.4-0.7
                "good": 0,  # 0.7-0.9
                "excellent": 0   # 0.9-1.0
            },
            "overall_score_distribution": {
                "poor": 0,  # 0-40
                "moderate": 0,  # 40-70
                "good": 0,  # 70-90
                "excellent": 0   # 90-100
            },
            "refinement_success_rate": 0,
            "average_efficacy_score": 0,
            "average_safety_score": 0,
            "average_overall_score": 0
        }
        
        # Count problem domains
        for problem_id, problem in self.health_problems_registry.items():
            domain = problem.get("domain", "unknown")
            if domain not in stats["problem_domains"]:
                stats["problem_domains"][domain] = 0
            stats["problem_domains"][domain] += 1
        
        # Count therapeutic approaches
        for substance_id, substance in self.substance_database.items():
            approach = substance.get("framework", {}).get("approach", "unknown")
            if approach not in stats["therapeutic_approaches"]:
                stats["therapeutic_approaches"][approach] = 0
            stats["therapeutic_approaches"][approach] += 1
        
        # Calculate efficacy and safety distributions
        total_efficacy = 0
        total_safety = 0
        total_overall = 0
        
        for evaluation_id, evaluation in self.efficacy_ratings.items():
            # Efficacy distribution
            efficacy_score = evaluation.get("efficacy_assessment", {}).get("score", 0)
            total_efficacy += efficacy_score
            
            if efficacy_score < 0.4:
                stats["efficacy_distribution"]["poor"] += 1
            elif efficacy_score < 0.7:
                stats["efficacy_distribution"]["moderate"] += 1
            elif efficacy_score < 0.9:
                stats["efficacy_distribution"]["good"] += 1
            else:
                stats["efficacy_distribution"]["excellent"] += 1
            
            # Safety distribution
            safety_score = evaluation.get("safety_assessment", {}).get("score", 0)
            total_safety += safety_score
            
            if safety_score < 0.4:
                stats["safety_distribution"]["poor"] += 1
            elif safety_score < 0.7:
                stats["safety_distribution"]["moderate"] += 1
            elif safety_score < 0.9:
                stats["safety_distribution"]["good"] += 1
            else:
                stats["safety_distribution"]["excellent"] += 1
            
            # Overall score distribution
            overall_score = evaluation.get("overall_assessment", {}).get("score", 0)
            total_overall += overall_score
            
            if overall_score < 40:
                stats["overall_score_distribution"]["poor"] += 1
            elif overall_score < 70:
                stats["overall_score_distribution"]["moderate"] += 1
            elif overall_score < 90:
                stats["overall_score_distribution"]["good"] += 1
            else:
                stats["overall_score_distribution"]["excellent"] += 1
        
        # Calculate averages
        if len(self.efficacy_ratings) > 0:
            stats["average_efficacy_score"] = total_efficacy / len(self.efficacy_ratings)
            stats["average_safety_score"] = total_safety / len(self.efficacy_ratings)
            stats["average_overall_score"] = total_overall / len(self.efficacy_ratings)
        
        # Calculate refinement success rate
        successful_refinements = 0
        for substance_id, substance in self.substance_database.items():
            if "refinements" in substance and substance.get("design_status", "") == "evaluated":
                successful_refinements += 1
        
        if len(self.refinement_history) > 0:
            stats["refinement_success_rate"] = successful_refinements / len(self.refinement_history)
        
        return stats
        # Check for contraindications
        contraindications = systemic_sim.get("contraindications", [])
        if contraindications and contraindications != ["standard_precautions"]:
            risks.append(f"Contraindicated in: {', '.join(contraindications[:3])}")
        
        # Check for long-term risks
        long_term_effects = systemic_sim.get("long_term_effects", [])
        negative_effects = [e for e in long_term_effects if e.get("nature") == "negative" and e.get("likelihood", 0) > 0.4]
        
        if negative_effects:
            effects_list = [e.get("effect", "unknown") for e in negative_effects[:2]]
            risks.append(f"Long-term concerns: {', '.join(effects_list)}")
        
        # If no specific risks identified, add general statement
        if not risks:
            risks.append("No significant safety concerns identified")
        
        return risks

    def _generate_monitoring_recommendations(self, simulation):
        """Generate monitoring recommendations based on simulation results."""
        recommendations = []
        
        # Extract data from simulation
        molecular_sim = simulation.get("molecular_simulation", {})
        cellular_sim = simulation.get("cellular_simulation", {})
        tissue_sim = simulation.get("tissue_simulation", {})
        systemic_sim = simulation.get("systemic_simulation", {})
        
        # Add general monitoring based on substance properties
        recommendations.append("Standard clinical monitoring of therapeutic response")
        
        # Check for toxicity mechanisms requiring specific monitoring
        toxicity_mechanisms = cellular_sim.get("toxicity_mechanisms", [])
        
        if "mitochondrial_dysfunction" in toxicity_mechanisms:
            recommendations.append("Monitor for signs of metabolic dysfunction and lactic acidosis")
            
        if "oxidative_stress" in toxicity_mechanisms:
            recommendations.append("Monitor for markers of oxidative stress and tissue damage")
            
        if "DNA_damage" in toxicity_mechanisms:
            recommendations.append("Periodic genotoxicity screening recommended")
            
        if "protein_misfolding" in toxicity_mechanisms:
            recommendations.append("Monitor for signs of ER stress and proteotoxicity")
        
        # Add recommendations based on specific tissue reactions
        reactions = tissue_sim.get("adverse_tissue_reactions", [])
        
        if "inflammation" in reactions:
            recommendations.append("Monitor inflammatory markers (CRP, ESR)")
            
        if "fibrosis" in reactions:
            recommendations.append("Periodic assessment of organ function and fibrotic changes")
            
        if "vascular_damage" in reactions:
            recommendations.append("Monitor cardiovascular parameters")
        
        # Add biomarker monitoring
        biomarker_responses = tissue_sim.get("biomarker_responses", [])
        if biomarker_responses:
            biomarker_names = [b.get("name", "unknown") for b in biomarker_responses[:2]]
            recommendations.append(f"Monitor specific biomarkers: {', '.join(biomarker_names)}")
        
        # Add recommendations based on side effects
        side_effects = systemic_sim.get("side_effects", [])
        serious_effects = [e for e in side_effects if e.get("severity") in ["moderate", "severe"]]
        
        if any(e.get("effect", "") == "elevated_liver_enzymes" for e in side_effects):
            recommendations.append("Regular liver function testing")
            
        if any(e.get("effect", "") in ["increased_blood_pressure", "decreased_blood_pressure"] for e in side_effects):
            recommendations.append("Regular blood pressure monitoring")
            
        if any(e.get("effect", "") in ["hyperglycemia", "hypoglycemia"] for e in side_effects):
            recommendations.append("Blood glucose monitoring")
        
        # Add general recommendation for serious side effects
        if serious_effects:
            recommendations.append("Close monitoring during treatment initiation and dose adjustments")
        
        return recommendations

    def _generate_development_challenges(self, substance, simulation):
        """Generate key development challenges based on substance properties and simulation results."""
        challenges = []
        
        # Extract data
        framework = substance.get("framework", {})
        approach = framework.get("approach", "small_molecule")
        properties = substance.get("expected_properties", {})
        molecular_sim = simulation.get("molecular_simulation", {})
        
        # Common challenges by approach
        approach_challenges = {
            "small_molecule": [
                "Optimization of pharmacokinetic properties",
                "Achieving adequate target selectivity",
                "Maintaining drug-like properties during optimization"
            ],
            "peptide": [
                "Limited oral bioavailability",
                "Potential immunogenicity",
                "Manufacturing consistency and scale-up"
            ],
            "antibody": [
                "High development and manufacturing costs",
                "Complex characterization requirements",
                "Potential immunogenicity concerns"
            ],
            "nucleic_acid": [
                "Delivery to target tissues",
                "Potential off-target effects",
                "Manufacturing and stability challenges"
            ],
            "cell_therapy": [
                "Complex manufacturing and quality control",
                "Variable cell potency and persistence",
                "Logistical challenges for distribution"
            ]
        }
        
        # Add approach-specific challenges
        if approach in approach_challenges:
            challenges.extend(approach_challenges[approach][:2])
        
        # Add specific challenges based on substance properties
        if approach == "small_molecule":
            # Check for synthetic complexity
            if framework.get("synthetic_complexity", 0) > 0.7:
                challenges.append("High synthetic complexity requiring route optimization")
            
            # Check for solubility/bioavailability
            if properties.get("oral_bioavailability", 1) < 0.3:
                challenges.append("Poor oral bioavailability requiring formulation optimization")
        
        elif approach == "peptide":
            if "cyclization" not in framework.get("modifications", []) and "stapling" not in framework.get("modifications", []):
                challenges.append("Limited proteolytic stability requiring structural modifications")
        
        elif approach == "antibody":
            if framework.get("species", "") == "chimeric":
                challenges.append("Potential for anti-drug antibody development")
        
        # Add challenges based on simulation results
        if molecular_sim.get("off_target_binding", 0) > 0.3:
            challenges.append("Selectivity optimization to reduce off-target effects")
        
        if simulation.get("efficacy_score", 1) < 0.6 and simulation.get("safety_score", 1) > 0.7:
            challenges.append("Potency optimization while maintaining safety profile")
        
        if simulation.get("safety_score", 1) < 0.6 and simulation.get("efficacy_score", 1) > 0.7:
            challenges.append("Safety optimization while preserving efficacy")
        
        return challenges

    def _generate_regulatory_considerations(self, substance, simulation):
        """Generate regulatory considerations based on substance properties and simulation results."""
        considerations = []
        
        # Extract data
        framework = substance.get("framework", {})
        approach = framework.get("approach", "small_molecule")
        problem_id = substance.get("problem_id")
        problem = self.health_problems_registry.get(problem_id, {})
        domain = problem.get("domain", "general")
        
        # Common regulatory considerations by approach
        approach_considerations = {
            "small_molecule": [
                "Standard IND-enabling toxicology studies",
                "Drug-drug interaction studies",
                "Thorough QT study likely required"
            ],
            "peptide": [
                "Immunogenicity assessment required",
                "Special stability testing requirements",
                "Careful characterization of impurities"
            ],
            "antibody": [
                "Comprehensive immunogenicity testing required",
                "Complex CMC requirements for biologics",
                "First-in-human dose calculation considerations"
            ],
            "nucleic_acid": [
                "Specialized genotoxicity and biodistribution studies",
                "Novel delivery system regulatory considerations",
                "Potential for expedited review pathways"
            ],
            "cell_therapy": [
                "RMAT or Breakthrough Therapy designation potential",
                "Complex manufacturing and release testing requirements",
                "Long-term patient follow-up likely required"
            ]
        }
        
        # Add approach-specific considerations
        if approach in approach_considerations:
            considerations.extend(approach_considerations[approach][:2])
        
        # Add domain-specific considerations
        domain_considerations = {
            "neurological": [
                "Blood-brain barrier penetration studies required",
                "CNS safety pharmacology focus",
                "Neurological functional assessments needed"
            ],
            "cardiovascular": [
                "Thorough cardiovascular safety assessment required",
                "Blood pressure and ECG monitoring in clinical studies",
                "Potential for cardiovascular outcomes trials"
            ],
            "oncological": [
                "Potential for accelerated approval pathways",
                "Consideration of combination therapy studies",
                "Special toxicology considerations for cytotoxic agents"
            ],
            "rare_disease": [
                "Orphan drug designation potential",
                "Smaller clinical trials may be acceptable",
                "Natural history studies may be valuable"
            ]
        }
        
        # Add domain-specific considerations if available
        if domain in domain_considerations:
            considerations.extend(domain_considerations[domain][:2])
        
        # Add safety-based considerations
        if simulation.get("safety_score", 1) < 0.6:
            considerations.append("Comprehensive risk management plan will be required")
            considerations.append("Enhanced safety monitoring in clinical trials")
        
        # Add special considerations based on approach
        if approach == "cell_therapy" or approach == "nucleic_acid":
            considerations.append("Potential for RMAT or Breakthrough Therapy designation")
        
        if approach == "small_molecule" and framework.get("molecular_weight", 0) < 500 and simulation.get("efficacy_score", 0) > 0.7:
            considerations.append("Traditional development pathway with potential for 505(b)(1) approval")
        
        return considerations

    def _generate_target_population(self, problem):
        """Generate target patient population description based on the health problem."""
        domain = problem.get("domain", "general")
        condition = problem.get("name", "condition")
        
        # Population descriptions by domain
        domain_populations = {
            "neurological": [
                f"Adult patients with {condition} inadequately controlled on current therapies",
                f"Patients with progressive forms of {condition}",
                f"Patients with early-stage {condition} for disease modification"
            ],
            "cardiovascular": [
                f"High-risk cardiovascular patients with {condition}",
                f"Patients with {condition} refractory to standard therapies",
                f"Post-event patients for secondary prevention of {condition}"
            ],
            "metabolic": [
                f"Patients with inadequately controlled {condition}",
                f"Patients with {condition} and multiple comorbidities",
                f"Early intervention in high-risk patients for {condition}"
            ],
            "immune": [
                f"Patients with moderate-to-severe {condition}",
                f"Patients with refractory or treatment-resistant {condition}",
                f"Patients with newly diagnosed {condition} as first-line therapy"
            ],
            "oncological": [
                f"Patients with advanced or metastatic {condition}",
                f"Second-line therapy for relapsed/refractory {condition}",
                f"Adjuvant therapy for high-risk {condition}"
            ],
            "infectious": [
                f"Patients with drug-resistant forms of {condition}",
                f"First-line therapy for newly diagnosed {condition}",
                f"Prophylaxis in high-risk populations for {condition}"
            ]
        }
        
        # Select population descriptions
        if domain in domain_populations:
            return random.sample(domain_populations[domain], min(2, len(domain_populations[domain])))
        else:
            return [
                f"Patients diagnosed with {condition} requiring therapeutic intervention",
                f"Patients with {condition} inadequately controlled on current therapies"
            ]

    def _generate_positioning_strategy(self, substance, simulation):
        """Generate positioning strategy based on substance properties and simulation results."""
        # Extract data
        efficacy_score = simulation.get("efficacy_score", 0.5)
        safety_score = simulation.get("safety_score", 0.5)
        framework = substance.get("framework", {})
        approach = framework.get("approach", "small_molecule")
        molecular_sim = simulation.get("molecular_simulation", {})
        systemic_sim = simulation.get("systemic_simulation", {})
        
        # Determine key differentiator
        differentiator = ""
        if efficacy_score > 0.8 and safety_score > 0.7:
            differentiator = "superior efficacy with favorable safety profile"
        elif efficacy_score > 0.7 and safety_score > 0.8:
            differentiator = "improved safety with maintained efficacy"
        elif efficacy_score > 0.7 and molecular_sim.get("binding_efficacy", 0) > 0.8:
            differentiator = "novel mechanism of action with enhanced target engagement"
        elif approach in ["nucleic_acid", "cell_therapy"] and efficacy_score > 0.6:
            differentiator = "innovative therapeutic modality addressing unmet need"
        elif systemic_sim.get("therapeutic_index", 1) > 5:
            differentiator = "enhanced therapeutic window providing clinical benefit"
        else:
            differentiator = "balanced efficacy and safety profile"
        
        # Determine positioning relative to competition
        line_of_therapy = ""
        if efficacy_score > 0.8:
            line_of_therapy = "first-line therapy for appropriate patients"
        elif efficacy_score > 0.6 and safety_score > 0.7:
            line_of_therapy = "first-line or second-line therapy based on patient factors"
        else:
            line_of_therapy = "second-line therapy after failure of conventional treatments"
        
        # Determine special populations
        special_populations = ""
        side_effects = systemic_sim.get("side_effects", [])
        contraindications = systemic_sim.get("contraindications", [])
        
        if safety_score > 0.8 and len(side_effects) < 2:
            special_populations = "including fragile patients and those with comorbidities"
        elif "renal_impairment" not in contraindications and "hepatic_impairment" not in contraindications:
            special_populations = "including patients with mild-to-moderate organ dysfunction"
        else:
            special_populations = "in patients without specific contraindications"
        
        # Combine elements into positioning strategy
        return f"Position as {line_of_therapy} {special_populations}, highlighting {differentiator}."

    def _generate_final_recommendation(self, overall_score):
        """Generate final development recommendation based on overall score."""
        if overall_score >= 80:
            return "Proceed to full development with high priority"
        elif overall_score >= 70:
            return "Proceed to full development"
        elif overall_score >= 60:
            return "Proceed to development with targeted enhancements"
        elif overall_score >= 50:
            return "Consider additional refinement before full development"
        elif overall_score >= 40:
            return "Significant refinement required before development decision"
        else:
            return "Reconsider development strategy or target selection"

    def _generate_next_steps(self, substance, simulation, overall_score):
        """Generate next development steps based on substance, simulation, and overall score."""
        next_steps = []
        
        # Extract data
        approach = substance.get("framework", {}).get("approach", "small_molecule")
        efficacy_score = simulation.get("efficacy_score", 0.5)
        safety_score = simulation.get("safety_score", 0.5)
        
        # High priority steps
        if overall_score >= 70:
            if approach == "small_molecule":
                next_steps.extend([
                    "Initiate GMP manufacturing process development",
                    "Complete IND-enabling toxicology studies",
                    "Finalize clinical development strategy",
                    "Prepare pre-IND meeting request"
                ])
            elif approach in ["peptide", "antibody", "nucleic_acid"]:
                next_steps.extend([
                    "Scale up manufacturing process and complete process characterization",
                    "Complete IND-enabling toxicology studies",
                    "Develop bioanalytical assays for clinical studies",
                    "Prepare pre-IND meeting request"
                ])
            elif approach == "cell_therapy":
                next_steps.extend([
                    "Finalize manufacturing protocol and quality control strategy",
                    "Complete preclinical safety and efficacy studies",
                    "Develop clinical-grade cell manufacturing process",
                    "Prepare INTERACT meeting request with FDA"
                ])
        
        # Medium priority
        elif overall_score >= 50:
            if efficacy_score < 0.7:
                next_steps.append("Conduct additional efficacy optimization studies")
            
            if safety_score < 0.7:
                next_steps.append("Perform targeted studies to address safety concerns")
            
            next_steps.extend([
                "Initiate preliminary manufacturing process development",
                "Conduct key toxicology studies to identify development risks",
                "Refine clinical development strategy"
            ])
        
        # Low priority
        else:
            next_steps.extend([
                "Re-evaluate target validation and mechanism rationale",
                "Perform significant substance redesign or consider alternative approaches",
                "Conduct additional proof-of-concept studies with refined substance"
            ])
        
        # Add specific recommendations based on simulation results
        molecular_sim = simulation.get("molecular_simulation", {})
        cellular_sim = simulation.get("cellular_simulation", {})
        
        if molecular_sim.get("off_target_binding", 0) > 0.3:
            next_steps.append("Conduct comprehensive selectivity profiling")
        
        if cellular_sim.get("toxicity", 0) > 0.3:
            next_steps.append("Perform mechanism-based toxicity assessments")
        
        # Ensure we don't have too many steps
        next_steps = next_steps[:5]
        
        return next_steps

    def generate_final_report(self, substance_id):
        """
        Generate a comprehensive final report for a therapeutic substance,
        including all development and evaluation information.
        """
        if substance_id not in self.substance_database:
            log_event(f"Cannot generate report for unknown substance: {substance_id}", "ERROR")
            return None
        
        substance = self.substance_database[substance_id]
        problem_id = substance.get("problem_id")
        
        # Check if substance has been evaluated
        if "evaluation" not in substance:
            log_event(f"Running evaluation before report generation for {substance_id}", "INFO")
            evaluation_id = self.evaluate_final_substance(substance_id)
            if not evaluation_id:
                return None
            substance = self.substance_database[substance_id]  # Refresh after evaluation
        
        # Get evaluation
        evaluation_id = substance["evaluation"]
        if evaluation_id not in self.efficacy_ratings:
            log_event(f"Cannot find evaluation results for {substance_id}", "ERROR")
            return None
        
        evaluation = self.efficacy_ratings[evaluation_id]
        
        # Generate report ID
        report_id = f"REPORT-{substance_id}"
        
        log_event(f"Generating comprehensive final report {report_id} for substance {substance_id}", "INFO")
        
        # Get problem details
        problem = self.health_problems_registry.get(problem_id, {})
        problem_name = problem.get("name", "Unknown Condition")
        
        # Get research history
        design_date = substance.get("created_at", "Unknown")
        refinement_history = []
        
        if "refinements" in substance:
            for refinement_id in substance.get("refinements", []):
                if refinement_id in self.substance_database:
                    refinement = self.substance_database[refinement_id]
                    refinement_history.append({
                        "id": refinement_id,
                        "name": refinement.get("name", "Unnamed Refinement"),
                        "created_at": refinement.get("created_at", "Unknown"),
                        "refinement_strategy": refinement.get("refinement_strategy", {})
                    })
        
        # Get simulation history
        simulation_history = []
        
        if "simulations" in substance:
            for simulation_id in substance.get("simulations", []):
                if simulation_id in self.simulation_results:
                    simulation = self.simulation_results[simulation_id]
                    simulation_history.append({
                        "id": simulation_id,
                        "date": simulation.get("simulation_timestamp", "Unknown"),
                        "efficacy_score": simulation.get("efficacy_score", 0),
                        "safety_score": simulation.get("safety_score", 0),
                        "recommendation": simulation.get("recommendation", "Unknown")
                    })
        
        # Create comprehensive report structure
        report = {
            "id": report_id,
            "title": f"Comprehensive Development Report for {substance.get('name', 'Unnamed Substance')}",
            "substance_id": substance_id,
            "substance_name": substance.get("name", "Unnamed Substance"),
            "problem_id": problem_id,
            "problem_name": problem_name,
            "generation_date": datetime.now().isoformat(),
            
            "executive_summary": {
                "substance_description": self._generate_substance_description(substance),
                "intended_indication": problem_name,
                "mechanism_of_action": substance.get("mechanism_of_action", {}).get("primary_mechanism", "Unknown"),
                "development_status": substance.get("design_status", "Unknown"),
                "overall_assessment": evaluation.get("overall_assessment", {}).get("recommendation", "Unknown"),
                "key_highlights": self._generate_key_highlights(substance, evaluation)
            },
            
            "problem_analysis": {
                "name": problem_name,
                "domain": problem.get("domain", "Unknown"),
                "mechanisms": problem.get("mechanisms", {}).get("primary_mechanisms", []),
                "biomarkers": self.biomarker_targets.get(problem_id, [])
            },
            
            "substance_design": {
                "approach": substance.get("framework", {}).get("approach", "Unknown"),
                "framework": substance.get("framework", {}),
                "target": substance.get("primary_target", "Unknown"),
                "mechanism_of_action": substance.get("mechanism_of_action", {}),
                "design_date": design_date,
                "expected_properties": substance.get("expected_properties", {})
            },
            
            "development_history": {
                "initial_design": {
                    "id": substance_id,
                    "date": design_date
                },
                "refinements": refinement_history,
                "simulations": simulation_history
            },
            
            "efficacy_profile": evaluation.get("efficacy_assessment", {}),
            "safety_profile": evaluation.get("safety_assessment", {}),
            "development_assessment": evaluation.get("development_assessment", {}),
            "market_assessment": evaluation.get("market_assessment", {}),
            
            "final_assessment": {
                "overall_score": evaluation.get("overall_assessment", {}).get("score", 0),
                "recommendation": evaluation.get("overall_assessment", {}).get("recommendation", "Unknown"),
                "next_steps": evaluation.get("overall_assessment", {}).get("next_steps", []),
                "conclusions": self._generate_conclusions(substance, evaluation)
            }
        }
        
        # Store the report
        if "reports" not in substance:
            self.substance_database[substance_id]["reports"] = []
        
        self.substance_database[substance_id]["reports"].append(report_id)
        self.substance_database[substance_id]["design_status"] = "reported"
        
        # Update problem registry
        if problem_id in self.health_problems_registry:
            self.health_problems_registry[problem_id]["status"] = "completed"
        
        log_event(f"Completed comprehensive report {report_id} for {substance_id}", "INFO")
        
        return report

    def _generate_substance_description(self, substance):
        """Generate a concise description of the therapeutic substance."""
        framework = substance.get("framework", {})
        approach = framework.get("approach", "therapeutic agent")
        mechanism = substance.get("mechanism_of_action", {})
        primary_mechanism = mechanism.get("primary_mechanism", "unknown mechanism")
        target = substance.get("primary_target", "unknown target")
        problem_id = substance.get("problem_id", "unknown problem")
        problem_name = self.health_problems_registry.get(problem_id, {}).get("name", "health condition")
        
        # Approach-specific descriptions
        approach_descriptions = {
            "small_molecule": f"novel small molecule that targets {target} through {primary_mechanism}",
            "peptide": f"synthetic peptide designed to interact with {target} via {primary_mechanism}",
            "antibody": f"monoclonal antibody directed against {target} with {primary_mechanism} activity",
            "nucleic_acid": f"nucleic acid-based therapeutic targeting {target} through {primary_mechanism}",
            "cell_therapy": f"engineered cell therapy designed to address {target} via {primary_mechanism}"
        }
        
        description = approach_descriptions.get(approach, f"{approach}-based agent targeting {target}")
        
        # Add substance name and condition
        return f"{substance.get('name', 'This therapeutic')} is a {description} for the treatment of {problem_name}."

    def _generate_key_highlights(self, substance, evaluation):
        """Generate key highlights for the executive summary."""
        highlights = []
        
        # Extract key metrics
        efficacy_score = evaluation.get("efficacy_assessment", {}).get("score", 0)
        safety_score = evaluation.get("safety_assessment", {}).get("score", 0)
        overall_score = evaluation.get("overall_assessment", {}).get("score", 0)
        
        # Add key efficacy highlight
        efficacy_strengths = evaluation.get("efficacy_assessment", {}).get("strengths", [])
        if efficacy_strengths:
            highlights.append(f"Efficacy: {efficacy_strengths[0]}")
        
        # Add key safety highlight
        safety_margin = evaluation.get("safety_assessment", {}).get("safety_margin", 0)
        if safety_margin > 5:
            highlights.append(f"Safety: Favorable therapeutic index of {safety_margin}")
        elif safety_score > 0.7:
            highlights.append("Safety: Favorable overall safety profile")
        
        # Add key development highlight
        challenges = evaluation.get("development_assessment", {}).get("key_development_challenges", [])
        if challenges:
            highlights.append(f"Development: {challenges[0]} identified as primary challenge")
        
        # Add key market highlight
        market_potential = evaluation.get("market_assessment", {}).get("market_potential", 0)
        if market_potential > 0.7:
            highlights.append("Market: Strong commercial potential based on unmet need")
        elif market_potential > 0.5:
            highlights.append("Market: Moderate commercial potential with defined patient population")
        
        # Add recommendation
        recommendation = evaluation.get("overall_assessment", {}).get("recommendation", "")
        if recommendation:
            highlights.append(f"Recommendation: {recommendation}")
        
        return highlights

    def _generate_conclusions(self, substance, evaluation):
        """Generate overall conclusions for the final assessment."""
        conclusions = []
        
        # Get key metrics
        overall_score = evaluation.get("overall_assessment", {}).get("score", 0)
        efficacy_score = evaluation.get("efficacy_assessment", {}).get("score", 0)
        safety_score = evaluation.get("safety_assessment", {}).get("score", 0)
        market_potential = evaluation.get("market_assessment", {}).get("market_potential", 0)
        
        # Overall conclusion based on score
        if overall_score >= 80:
            conclusions.append(f"{substance.get('name', 'This therapeutic')} demonstrates excellent potential as a novel treatment for {evaluation.get('problem_name', 'this condition')} with strong efficacy and safety profiles.")
        elif overall_score >= 65:
            conclusions.append(f"{substance.get('name', 'This therapeutic')} shows promising characteristics as a treatment for {evaluation.get('problem_name', 'this condition')} with a favorable benefit-risk profile.")
        elif overall_score >= 50:
            conclusions.append(f"{substance.get('name', 'This therapeutic')} demonstrates moderate potential as a treatment for {evaluation.get('problem_name', 'this condition')} with certain limitations that require attention.")
        else:
            conclusions.append(f"{substance.get('name', 'This therapeutic')} faces significant challenges as a treatment for {evaluation.get('problem_name', 'this condition')} that may limit its development potential.")
        
        # Add efficacy conclusion
        if efficacy_score >= 0.8:
            conclusions.append("Efficacy data suggests superior therapeutic benefit compared to current standards of care.")
        elif efficacy_score >= 0.6:
            conclusions.append("Efficacy profile indicates clinically meaningful benefit for patients.")
        else:
            conclusions.append("Efficacy profile suggests modest therapeutic benefit that may require enhancement.")
        
        # Add safety conclusion
        if safety_score >= 0.8:
            conclusions.append("Safety profile is highly favorable with minimal concerns identified.")
        elif safety_score >= 0.6:
            conclusions.append("Safety profile is acceptable with manageable risks that can be addressed through appropriate monitoring.")
        else:
            conclusions.append("Safety profile presents concerns that require careful risk management strategies.")
        
        # Add development/market conclusion
        if overall_score >= 60:
            time_to_market = evaluation.get("development_assessment", {}).get("estimated_time_to_market", "unknown")
            patient_population = evaluation.get("market_assessment", {}).get("target_patient_population", [])
            
            if patient_population:
                pop_description = patient_population[0]
            else:
                pop_description = "appropriate patients"
            
            conclusions.append(f"Development timeline of approximately {time_to_market} anticipates potential benefit for {pop_description}.")
        
        return conclusions

    def run_complete_development_cycle(self, problem_id=None):
        """
        Run a complete autonomous therapeutic development cycle from problem
        identification through design, simulation, refinement, and reporting.
        
        Parameters:
        - problem_id: Optional problem ID to focus on. If None, will identify problems.
        
        Returns:
        - Dictionary with results of the development cycle
        """
        # Step 1: Identify health problems if not specified
        if problem_id is None:
            problem_ids = self.identify_health_problems()
            if not problem_ids:
                log_event("No suitable health problems identified", "ERROR")
                return {"status": "failed", "stage": "problem_identification", "reason": "No problems identified"}
            
            # Select the highest quality problem
            selected_problems = []
            for pid in problem_ids:
                if pid in self.health_problems_registry:
                    problem = self.health_problems_registry[pid]
                    selected_problems.append((pid, problem.get("quality_score", 0)))
            
            if not selected_problems:
                log_event("No problems available in registry", "ERROR")
                return {"status": "failed", "stage": "problem_selection", "reason": "No problems in registry"}
            
            # Sort by quality score and pick the best
            selected_problems.sort(key=lambda x: x[1], reverse=True)
            problem_id = selected_problems[0][0]
        
        # Verify problem exists
        if problem_id not in self.health                        # Improve existing binding feature strengths
                        for feature in binding_features:
                            feature["strength"] = min(0.95, feature["strength"] + 0.15)
                    
                elif action == "remove_promiscuous_groups":
                    # Remove a functional group associated with promiscuity
                    promiscuous_groups = ["methyl", "carbonyl", "hydroxyl"]
                    for group in promiscuous_groups:
                        if group in framework["functional_groups"]:
                            framework["functional_groups"].remove(group)
                            break
        
        elif approach == "peptide":
            # Peptide modifications
            if action == "cyclization" and "cyclization" not in framework.get("modifications", []):
                if "modifications" not in framework:
                    framework["modifications"] = []
                framework["modifications"].append("cyclization")
                
            elif action == "stapling" and "stapling" not in framework.get("modifications", []):
                if "modifications" not in framework:
                    framework["modifications"] = []
                framework["modifications"].append("stapling")
                
            elif action == "non_natural_aa_substitution" and "non_natural_aa" not in framework.get("modifications", []):
                if "modifications" not in framework:
                    framework["modifications"] = []
                framework["modifications"].append("non_natural_aa")
                
            elif action == "terminal_modification":
                if "modifications" not in framework:
                    framework["modifications"] = []
                if "N_terminal_cap" not in framework["modifications"]:
                    framework["modifications"].append("N_terminal_cap")
                
            elif action == "secondary_structure_optimization":
                framework["secondary_structure"] = "alpha_helix"  # Optimized structure
        
        elif approach == "antibody":
            # Antibody modifications
            if action == "CDR_optimization":
                framework["cdr_modifications"] = framework.get("cdr_modifications", 0) + 3
                
            elif action == "affinity_maturation":
                # Improve affinity
                current_affinity = framework.get("affinity", "100 nM")
                parts = current_affinity.split()
                if len(parts) == 2:
                    value, unit = float(parts[0]), parts[1]
                    # Improve affinity 10x
                    new_value = value / 10
                    framework["affinity"] = f"{new_value} {unit}"
                
            elif action == "framework_modification":
                # Humanize or improve framework
                framework["species"] = "human" if framework.get("species") != "human" else "human"
                
            elif action == "epitope_refinement":
                framework["epitope_region"] = "conformational"  # Usually more specific

    def _apply_cellular_modification(self, framework, properties, target, action):
        """Apply a cellular-level modification to improve cellular effects."""
        approach = framework.get("approach", "small_molecule")
        
        if target == "toxicity_reduction":
            # Reduce cellular toxicity
            safety_profile = properties.get("safety_profile", {})
            
            if action == "remove_toxic_functional_groups" and approach == "small_molecule":
                # Remove potentially toxic groups
                toxic_groups = ["nitro", "aldehyde", "ketone"]
                for group in toxic_groups:
                    if group in framework.get("functional_groups", []):
                        framework["functional_groups"].remove(group)
                
            elif action == "reduce_reactive_metabolites":
                # Improve safety profile
                if "toxicity_risk" in safety_profile:
                    safety_profile["toxicity_risk"] = max(0.1, safety_profile["toxicity_risk"] - 0.2)
                
            elif action == "target_specific_cell_types":
                # Add cellular targeting
                framework["delivery_system"] = "targeted_protein_degrader"
                
            elif action == "reduce_dose_requirements":
                # Improve potency to allow lower dosing
                if "efficacy" in properties:
                    properties["efficacy"] = min(0.95, properties["efficacy"] + 0.1)
            
            elif action == "alter_metabolic_pathway":
                # Improve metabolic properties
                if "clearance_ml_min" in properties:
                    properties["clearance_ml_min"] = max(1.0, properties["clearance_ml_min"] - 3.0)
        
        elif target == "pathway_effect":
            # Enhance pathway modulation
            if action == "dual_pathway_targeting":
                # Add secondary mechanism
                if approach == "small_molecule":
                    if "allosteric_modulator" not in properties.get("mechanism_types", []):
                        if "mechanism_types" not in properties:
                            properties["mechanism_types"] = []
                        properties["mechanism_types"].append("allosteric_modulator")
            
            elif action == "signaling_amplification":
                # Increase efficacy
                if "efficacy" in properties:
                    properties["efficacy"] = min(0.95, properties["efficacy"] + 0.15)
            
            elif action == "persistence_enhancement":
                # Improve residence time
                if approach == "small_molecule":
                    framework["binding_mode"] = "slow_dissociation"
                elif approach == "antibody":
                    framework["format"] = "full_length" if framework.get("format") != "full_length" else "full_length"
            
            elif action == "indirect_pathway_modulation" or action == "allosteric_enhancement":
                # Change binding mode
                if approach == "small_molecule":
                    framework["binding_mode"] = "allosteric"

    def _apply_delivery_modification(self, framework, properties, target, action):
        """Apply a delivery-level modification to improve biodistribution."""
        approach = framework.get("approach", "small_molecule")
        
        if target == "tissue_penetration":
            if action == "lipophilicity_adjustment" and approach == "small_molecule":
                # Adjust logP to optimal range for penetration
                current_logP = framework.get("logP", 2.0)
                if current_logP < 2.0:
                    framework["logP"] = 2.5  # Increase to improve penetration
                elif current_logP > 4.0:
                    framework["logP"] = 3.5  # Decrease to optimal range
            
            elif action == "particle_size_reduction" and approach in ["antibody", "nucleic_acid"]:
                if approach == "antibody":
                    if framework.get("format") == "full_length":
                        framework["format"] = "Fab"  # Smaller format
                
                elif approach == "nucleic_acid":
                    # Reduce length
                    framework["length"] = max(15, framework.get("length", 25) // 2)
            
            elif action == "advanced_delivery_system":
                # Upgrade delivery system
                advanced_systems = ["nanoparticle", "liposomal", "exosome", "antibody-drug-conjugate"]
                framework["delivery_system"] = random.choice(advanced_systems)
            
            elif action == "tissue_targeting_ligand":
                # Add targeting
                framework["delivery_system"] = "targeted_protein_degrader" if approach == "small_molecule" else "antibody-drug-conjugate"
            
            elif action == "transporter_utilization":
                if approach == "small_molecule":
                    # Add property
                    framework["transporter_substrate"] = True
        
        elif target == "tissue_specificity":
            if action == "targeted_delivery":
                # Upgrade to targeted delivery
                framework["delivery_system"] = "targeted_protein_degrader" if approach == "small_molecule" else "antibody-drug-conjugate"
            
            elif action == "controlled_release":
                # Add controlled release
                framework["delivery_system"] = "controlled_release"
            
            elif action == "specific_transporter_targeting" and approach == "small_molecule":
                # Add property
                framework["transporter_substrate"] = True
                
            elif action == "tissue-specific_activation":
                # Add prodrug property for small molecules
                if approach == "small_molecule":
                    framework["prodrug"] = True
            
            elif action == "localized_administration":
                # Change administration route
                if "administration_route" in properties:
                    properties["administration_route"] = "local"

    def _apply_systemic_modification(self, framework, properties, target, action):
        """Apply a systemic-level modification to improve therapeutic profile."""
        if target == "therapeutic_index":
            if action == "dose_optimization":
                # Improve efficacy to allow lower dosing
                if "efficacy" in properties:
                    properties["efficacy"] = min(0.95, properties["efficacy"] + 0.1)
                
                # Improve safety
                safety_profile = properties.get("safety_profile", {})
                if "toxicity_risk" in safety_profile:
                    safety_profile["toxicity_risk"] = max(0.1, safety_profile["toxicity_risk"] - 0.15)
            
            elif action == "schedule_optimization":
                # Improve half-life
                if "half_life_hours" in properties:
                    properties["half_life_hours"] = min(24, properties["half_life_hours"] * 1.5)
                elif "half_life_days" in properties:
                    properties["half_life_days"] = min(30, properties["half_life_days"] * 1.2)
            
            elif action == "combination_approach":
                # Add combination property
                properties["combination_therapy"] = {
                    "recommended": True,
                    "synergy_potential": random.uniform(0.7, 0.9)
                }
            
            elif action == "prodrug_conversion" and framework.get("approach") == "small_molecule":
                # Convert to prodrug
                framework["prodrug"] = True
            
            elif action == "toxic_metabolite_reduction":
                # Improve safety profile
                safety_profile = properties.get("safety_profile", {})
                if "toxicity_risk" in safety_profile:
                    safety_profile["toxicity_risk"] = max(0.1, safety_profile["toxicity_risk"] - 0.2)
        
        elif target == "side_effects":
            if action == "receptor_subtype_selectivity":
                # Improve selectivity
                safety_profile = properties.get("safety_profile", {})
                if "selectivity" in safety_profile:
                    safety_profile["selectivity"] = min(0.95, safety_profile["selectivity"] + 0.15)
                
                if "off_target_effects" in safety_profile:
                    safety_profile["off_target_effects"] = max(0.05, safety_profile["off_target_effects"] - 0.15)
            
            elif action == "targeted_distribution":
                # Improve tissue targeting
                framework["delivery_system"] = "targeted_protein_degrader" if framework.get("approach") == "small_molecule" else "antibody-drug-conjugate"
            
            elif action == "metabolism_optimization":
                # Optimize metabolic properties
                if "clearance_ml_min" in properties:
                    properties["clearance_ml_min"] = max(1.0, properties["clearance_ml_min"] * 0.8)
            
            elif action == "excretion_enhancement":
                # Improve elimination
                if framework.get("approach") == "small_molecule":
                    if "logP" in framework and framework["logP"] > 3.0:
                        framework["logP"] = max(1.0, framework["logP"] - 0.5)
            
            elif action == "ancillary_target_avoidance":
                # Improve selectivity
                safety_profile = properties.get("safety_profile", {})
                if "off_target_effects" in safety_profile:
                    safety_profile["off_target_effects"] = max(0.05, safety_profile["off_target_effects"] - 0.2)

    def _apply_general_optimization(self, framework, properties, target, action):
        """Apply general optimization to improve overall performance."""
        approach = framework.get("approach", "small_molecule")
        
        if action == "pharmacokinetic_optimization":
            # Optimize PK properties
            if "half_life_hours" in properties:
                properties["half_life_hours"] = min(24, properties["half_life_hours"] * 1.3)
            elif "half_life_days" in properties:
                properties["half_life_days"] = min(30, properties["half_life_days"] * 1.2)
            
            if "oral_bioavailability" in properties:
                properties["oral_bioavailability"] = min(0.95, properties["oral_bioavailability"] + 0.15)
            
            if "clearance_ml_min" in properties:
                properties["clearance_ml_min"] = max(1.0, properties["clearance_ml_min"] * 0.8)
        
        elif action == "multifactorial_enhancement":
            # Improve multiple properties
            safety_profile = properties.get("safety_profile", {})
            
            # Efficacy
            if "efficacy" in properties:
                properties["efficacy"] = min(0.95, properties["efficacy"] + 0.1)
            
            # Safety
            if "toxicity_risk" in safety_profile:
                safety_profile["toxicity_risk"] = max(0.05, safety_profile["toxicity_risk"] - 0.1)
            
            # Selectivity
            if "selectivity" in safety_profile:
                safety_profile["selectivity"] = min(0.95, safety_profile["selectivity"] + 0.1)
            
            # Therapeutic index
            if "therapeutic_index" in properties:
                properties["therapeutic_index"] = min(20, properties["therapeutic_index"] * 1.3)
        
        elif action == "formulation_improvement":
            # Improve delivery system
            framework["delivery_system"] = random.choice([
                "nanoparticle", "liposomal", "controlled_release", 
                "prodrug", "antibody-drug-conjugate"
            ])
        
        elif action == "dosing_regimen_optimization":
            # Optimize dosing
            if "half_life_hours" in properties:
                properties["half_life_hours"] = min(24, properties["half_life_hours"] * 1.5)
            elif "half_life_days" in properties:
                properties["half_life_days"] = min(30, properties["half_life_days"] * 1.2)
            
            # Reduce frequency
            if "dosing_frequency" not in properties:
                properties["dosing_frequency"] = "once_daily"
            elif properties["dosing_frequency"] == "twice_daily":
                properties["dosing_frequency"] = "once_daily"
            elif properties["dosing_frequency"] == "once_daily":
                properties["dosing_frequency"] = "weekly"

    def _update_mechanism_after_refinement(self, mechanism, modifications):
        """Update mechanism of action to reflect refinements."""
        # Check for specific modification types
        for modification in modifications:
            mod_type = modification.get("type")
            target = modification.get("target")
            action = modification.get("action")
            
            # Update primary mechanism if significant changes were made
            if mod_type == "molecular_modification" and target == "binding_efficacy":
                # Enhance response magnitude
                if "cellular_response" in mechanism:
                    for i, response in enumerate(mechanism["cellular_response"]):
                        mechanism["cellular_response"][i] = response + " enhancement"
            
            # Update systemic effect if delivery was improved
            if mod_type == "delivery_modification" and target == "tissue_penetration":
                # Enhance systemic effect
                if "systemic_effect" in mechanism:
                    for i, effect in enumerate(mechanism["systemic_effect"]):
                        mechanism["systemic_effect"][i] = effect + " improvement"
            
            # Update onset/duration if PK was changed
            if (mod_type == "systemic_modification" and target == "therapeutic_index") or action == "pharmacokinetic_optimization":
                # Improve duration
                if "duration_of_action" in mechanism:
                    current = mechanism["duration_of_action"]
                    parts = current.split()
                    if len(parts) == 2:
                        value, unit = int(parts[0]), parts[1]
                        if unit == "hours":
                            mechanism["duration_of_action"] = f"{value * 2} hours"
                        elif unit == "days":
                            mechanism["duration_of_action"] = f"{value * 1.5} days"

    def _recalculate_properties(self, framework, mechanism):
        """Recalculate expected properties after refinement modifications."""
        # Calculate from scratch using the updated framework
        return self._calculate_expected_properties(framework, mechanism)

    def evaluate_final_substance(self, substance_id):
        """
        Perform a comprehensive evaluation of a therapeutic substance,
        including efficacy, safety, and market potential assessments.
        """
        if substance_id not in self.substance_database:
            log_event(f"Cannot evaluate unknown substance: {substance_id}", "ERROR")
            return None
        
        substance = self.substance_database[substance_id]
        problem_id = substance.get("problem_id")
        
        # Check if substance has been simulated
        if "latest_simulation" not in substance:
            log_event(f"Running simulation before evaluation for {substance_id}", "INFO")
            simulation_id = self.simulate_therapeutic_effects(substance_id)
            if not simulation_id:
                return None
            substance = self.substance_database[substance_id]  # Refresh after simulation
        
        # Get latest simulation results
        latest_sim_id = substance["latest_simulation"]
        if latest_sim_id not in self.simulation_results:
            log_event(f"Cannot find simulation results for {substance_id}", "ERROR")
            return None
        
        simulation = self.simulation_results[latest_sim_id]
        
        # Generate evaluation ID
        evaluation_id = f"EVAL-{substance_id}"
        
        log_event(f"Starting comprehensive evaluation {evaluation_id} for substance {substance_id}", "INFO")
        
        # Extract key metrics from simulation
        efficacy_score = simulation.get("efficacy_score", 0.5)
        safety_score = simulation.get("safety_score", 0.5)
        efficacy_classification = simulation.get("efficacy_classification", "unknown")
        safety_classification = simulation.get("safety_classification", "unknown")
        
        # Calculate development potential scores
        approach = substance.get("framework", {}).get("approach", "small_molecule")
        
        # Development complexity factors
        complexity_factors = {
            "small_molecule": 0.6,
            "peptide": 0.7,
            "antibody": 0.8,
            "nucleic_acid": 0.85,
            "cell_therapy": 0.95
        }
        
        # Time to market factors (years)
        time_factors = {
            "small_molecule": 8,
            "peptide": 7,
            "antibody": 9,
            "nucleic_acid": 7,
            "cell_therapy": 10
        }
        
        # Cost factors (relative)
        cost_factors = {
            "small_molecule": 0.7,
            "peptide": 0.8,
            "antibody": 0.9,
            "nucleic_acid": 0.85,
            "cell_therapy": 1.0
        }
        
        # Calculate metrics
        development_complexity = complexity_factors.get(approach, 0.7)
        time_to_market = time_factors.get(approach, 8)
        development_cost = cost_factors.get(approach, 0.8)
        
        # Adjust based on specific substance properties
        expected_properties = substance.get("expected_properties", {})
        
        # Complexity adjustments
        if approach == "small_molecule":
            synth_complexity = substance.get("framework", {}).get("synthetic_complexity", 0.5)
            development_complexity *= (1 + (synth_complexity - 0.5))
            
            # Adjust time based on complexity
            time_to_market += (synth_complexity - 0.5) * 3
            
            # Adjust cost based on complexity
            development_cost *= (1 + (synth_complexity - 0.5) * 0.5)
        
        # Efficacy and safety adjustments
        if efficacy_score > 0.8:
            time_to_market *= 0.9  # Faster for highly effective substances
            development_cost *= 0.9  # Lower cost due to clearer efficacy signals
        
        if safety_score < 0.7:
            time_to_market *= 1.2  # Longer for substances with safety concerns
            development_cost *= 1.2  # Higher cost due to safety assessment needs
        
        # Calculate market potential
        problem = self.health_problems_registry.get(problem_id, {})
        
        # Size of problem (simplified scoring)
        problem_size_score = random.uniform(0.5, 1.0)  # Default random value
        
        # Domain-specific market size estimates
        domain_market_sizes = {
            "neurological": 0.9,
            "cardiovascular": 0.95,
            "metabolic": 0.85,
            "immune": 0.8,
            "oncological": 0.9,
            "infectious": 0.7,
            "respiratory": 0.8,
            "psychiatric": 0.9
        }
        
        domain = problem.get("domain", "general")
        problem_size_score = domain_market_sizes.get(domain, problem_size_score)
        
        # Calculate competitive advantage
        competitive_advantage = efficacy_score * 0.7 + (1 - development_complexity) * 0.3
        
        # Calculate market potential
        market_potential = problem_size_score * competitive_advantage
        
        # Calculate overall score (0-100 scale)
        overall_score = (
            efficacy_score * 40 +  # Efficacy is most important
            safety_score * 30 +    # Safety is second most important
            (1 - development_complexity) * 10 +  # Lower complexity is better
            market_potential * 20   # Market potential
        )
        
        # Create comprehensive evaluation
        evaluation = {
            "id": evaluation_id,
            "substance_id": substance_id,
            "substance_name": substance.get("name", "Unnamed Substance"),
            "problem_id": problem_id,
            "problem_name": problem.get("name", "Unknown Condition"),
            "evaluation_date": datetime.now().isoformat(),
            
            "efficacy_assessment": {
                "score": round(efficacy_score, 2),
                "classification": efficacy_classification,
                "strengths": self._generate_efficacy_strengths(simulation),
                "limitations": self._generate_efficacy_limitations(simulation),
                "biomarker_predictions": simulation.get("tissue_simulation", {}).get("biomarker_responses", [])
            },
            
            "safety_assessment": {
                "score": round(safety_score, 2),
                "classification": safety_classification,
                "safety_margin": round(simulation.get("systemic_simulation", {}).get("therapeutic_index", 0), 1),
                "key_risks": self._generate_safety_risks(simulation),
                "monitoring_recommendations": self._generate_monitoring_recommendations(simulation)
            },
            
            "development_assessment": {
                "complexity": round(development_complexity, 2),
                "estimated_time_to_market": f"{round(time_to_market, 1)} years",
                "relative_development_cost": round(development_cost, 2),
                "key_development_challenges": self._generate_development_challenges(substance, simulation),
                "regulatory_considerations": self._generate_regulatory_considerations(substance, simulation)
            },
            
            "market_assessment": {
                "problem_size_score": round(problem_size_score, 2),
                "competitive_advantage": round(competitive_advantage, 2),
                "market_potential": round(market_potential, 2),
                "target_patient_population": self._generate_target_population(problem),
                "positioning_strategy": self._generate_positioning_strategy(substance, simulation)
            },
            
            "overall_assessment": {
                "score": round(overall_score, 1),
                "recommendation": self._generate_final_recommendation(overall_score),
                "next_steps": self._generate_next_steps(substance, simulation, overall_score)
            }
        }
        
        # Store evaluation in efficacy ratings
        self.efficacy_ratings[evaluation_id] = evaluation
        
        # Update substance record with evaluation reference
        self.substance_database[substance_id]["evaluation"] = evaluation_id
        self.substance_database[substance_id]["design_status"] = "evaluated"
        
        # Update problem registry
        if problem_id in self.health_problems_registry:
            self.health_problems_registry[problem_id]["status"] = "substance_evaluated"
        
        log_event(f"Completed evaluation {evaluation_id} for {substance_id} with overall score {round(overall_score, 1)}", "INFO")
        
        return evaluation_id

    def _generate_efficacy_strengths(self, simulation):
        """Generate key efficacy strengths based on simulation results."""
        strengths = []
        
        # Extract data from simulation
        molecular_sim = simulation.get("molecular_simulation", {})
        cellular_sim = simulation.get("cellular_simulation", {})
        tissue_sim = simulation.get("tissue_simulation", {})
        systemic_sim = simulation.get("systemic_simulation", {})
        
        # Check for strong binding
        if molecular_sim.get("binding_efficacy", 0) > 0.8:
            strengths.append("Strong target binding affinity")
        
        # Check for good pathway modulation
        if cellular_sim.get("pathway_modulation", 0) > 0.7:
            strengths.append(f"Effective modulation of {cellular_sim.get('signaling_cascade', 'signaling')} pathway")
        
        # Check for high tissue effect
        if tissue_sim.get("target_tissue_effect", 0) > 0.7:
            strengths.append("Excellent target tissue penetration and effect")
        
        # Check for high disease impact
        if systemic_sim.get("disease_impact", 0) > 0.7:
            strengths.append("Significant impact on disease progression")
        
        # Check for good therapeutic index
        if systemic_sim.get("therapeutic_index", 0) > 5:
            strengths.append(f"Favorable therapeutic index ({round(systemic_sim.get('therapeutic_index', 0), 1)})")
        
        # Check for quality of life impact
        if systemic_sim.get("quality_of_life_impact", 0) > 0.7:
            strengths.append("Substantial improvement in quality of life metrics")
        
        # If no specific strengths identified, add general statement
        if not strengths:
            strengths.append("Balanced therapeutic profile")
        
        return strengths

    def _generate_efficacy_limitations(self, simulation):
        """Generate key efficacy limitations based on simulation results."""
        limitations = []
        
        # Extract data from simulation
        molecular_sim = simulation.get("molecular_simulation", {})
        cellular_sim = simulation.get("cellular_simulation", {})
        tissue_sim = simulation.get("tissue_simulation", {})
        systemic_sim = simulation.get("systemic_simulation", {})
        
        # Check for weak binding
        if molecular_sim.get("binding_efficacy", 1) < 0.6:
            limitations.append("Suboptimal target binding affinity")
        
        # Check for poor pathway modulation
        if cellular_sim.get("pathway_modulation", 1) < 0.6:
            limitations.append("Limited pathway modulation effect")
        
        # Check for low tissue effect
        if tissue_sim.get("target_tissue_effect", 1) < 0.6:
            limitations.append("Insufficient target tissue penetration")
        
        # Check for low disease impact
        if systemic_sim.get("disease_impact", 1) < 0.6:
            limitations.append("Moderate impact on disease progression")
        
        # Check for adherence issues
        if systemic_sim.get("predicted_adherence", 1) < 0.7:
            limitations.append("Potential adherence challenges due to side effect profile")
        
        # Check for limited duration of action
        if "duration_of_action" in systemic_sim:
            duration = systemic_sim["duration_of_action"]
            if "hours" in str(duration) and int(str(duration).split()[0]) < 12:
                limitations.append("Short duration of action requiring frequent dosing")
        
        # If no specific limitations identified, add general statement
        if not limitations:
            limitations.append("No significant efficacy limitations identified")
        
        return limitations

    def _generate_safety_risks(self, simulation):
        """Generate key safety risks based on simulation results."""
        risks = []
        
        # Extract data from simulation
        molecular_sim = simulation.get("molecular_simulation", {})
        cellular_sim = simulation.get("cellular_simulation", {})
        tissue_sim = simulation.get("tissue_simulation", {})
        systemic_sim = simulation.get("systemic_simulation", {})
        
        # Check for off-target binding
        if molecular_sim.get("off_target_binding", 0) > 0.4:
            risks.append("Significant off-target binding potential")
            
            # Add specific off-targets if available
            off_targets = molecular_sim.get("potential_off_targets", [])
            high_risk_targets = [t["name"] for t in off_targets 
                              if t.get("potential_consequence") in ["adverse_effect", "toxicity_risk"]
                              and t.get("binding_strength", 0) > 0.5]
            
            if high_risk_targets:
                risks.append(f"High affinity for off-targets: {', '.join(high_risk_targets[:3])}")
        
        # Check for cellular toxicity
        if cellular_sim.get("toxicity", 0) > 0.4:
            mechanisms = cellular_sim.get("toxicity_mechanisms", [])
            if mechanisms and mechanisms != ["minimal_toxicity"]:
                risks.append(f"Cellular toxicity via {', '.join(mechanisms[:2])}")
            else:
                risks.append("Moderate cellular toxicity potential")
        
        # Check for tissue adverse effects
        if tissue_sim.get("adverse_effects", 0) > 0.4:
            reactions = tissue_sim.get("adverse_tissue_reactions", [])
            if reactions and reactions != ["minimal_adverse_reactions"]:
                risks.append(f"Tissue reactions including {', '.join(reactions[:2])}")
            else:
                risks.append("Potential for adverse tissue reactions")
        
        # Check for systemic side effects
        side_effects = systemic_sim.get("side_effects", [])
        severe_effects = [e for e in side_effects if e.get("severity") == "severe"]
        common_effects = [e for e in side_effects if e.get("frequency") in ["common", "very_common"]]
        
        if severe_effects:
            effects_list = [e.get("effect", "unknown") for e in severe_effects[:2]]
            risks.append(f"Severe side effects: {', '.join(effects_list)}")
        
        if common_effects:
            effects_list = [e.get("effect", "unknown") for e in common_effects[:3]]
            risks.append(f"Common side effects: {', '.join(effects_list)}")
        
        # Check for contraindications
        contraindications = systemic_sim.get("contraindications", [])
        if contra# =============================================================================
# THERAPEUTIC SUBSTANCE GENERATOR MODULE
# =============================================================================
class TherapeuticSubstanceGenerator:
    """
    Advanced system for generating, simulating, and refining therapeutic substances
    for addressing health problems using quantum-inspired computational approaches.
    """
    def __init__(self, agent):
        self.agent = agent
        self.substance_database = {}  # Store generated substances
        self.health_problems_registry = {}  # Track identified health problems
        self.simulation_results = {}  # Track simulation outcomes
        self.refinement_history = {}  # Track substance refinement progress
        self.efficacy_ratings = {}  # Store efficacy evaluations
        self.side_effect_profiles = {}  # Store side effect evaluations
        self.biomarker_targets = {}  # Store biomarker targets for conditions
        self.pathway_interventions = {}  # Store pathway interventions
        
        # Substance composition components
        self.molecular_fragments = {
            "functional_groups": [
                "hydroxyl", "carboxyl", "amino", "phosphate", "sulfhydryl", 
                "methyl", "carbonyl", "amide", "ester", "ether", "ketone"
            ],
            "core_structures": [
                "benzene", "pyridine", "cyclohexane", "furan", "pyrrole", "imidazole", 
                "indole", "purine", "pyrimidine", "steroid", "phenol", "alkane"
            ],
            "binding_domains": [
                "hydrophobic_pocket", "hydrogen_bond_donor", "hydrogen_bond_acceptor",
                "ionic_bond", "metal_coordination", "pi_stacking", "halogen_bond"
            ]
        }
        
        # Therapeutic mechanisms
        self.mechanism_frameworks = {
            "enzyme_inhibition": {
                "competitive", "non-competitive", "uncompetitive", "mixed", "irreversible"
            },
            "receptor_modulation": {
                "agonist", "antagonist", "partial_agonist", "allosteric_modulator", 
                "inverse_agonist", "biased_agonist"
            },
            "gene_expression": {
                "transcription_factor", "epigenetic_modifier", "mrna_stability",
                "translation_regulator", "splicing_modulator"
            },
            "membrane_transport": {
                "channel_blocker", "transporter_inhibitor", "ionophore", 
                "carrier_modulator", "vesicle_trafficking"
            },
            "cell_signaling": {
                "kinase_inhibitor", "phosphatase_modulator", "g_protein_modulator", 
                "second_messenger_regulator", "scaffold_disruptor"
            },
            "immune_modulation": {
                "cytokine_modulator", "complement_inhibitor", "antibody_recruiter",
                "immune_checkpoint", "pattern_recognition"
            },
            "redox_modulation": {
                "antioxidant", "pro-oxidant", "electron_transport", "free_radical_scavenger"
            }
        }
        
        # Health domains
        self.health_domains = [
            "neurological", "cardiovascular", "immune", "metabolic", "respiratory",
            "gastrointestinal", "musculoskeletal", "dermatological", "reproductive",
            "oncological", "infectious", "psychiatric", "endocrine", "regenerative"
        ]
        
        # Delivery systems
        self.delivery_systems = [
            "oral", "transdermal", "inhalation", "injection", "implant", 
            "liposomal", "nanoparticle", "micelle", "prodrug", "antibody-drug-conjugate",
            "viral_vector", "exosome", "targeted_protein_degrader"
        ]
        
        # Optimization parameters
        self.optimization_dimensions = {
            "potency": {"weight": 0.8, "threshold": 0.7},
            "selectivity": {"weight": 0.9, "threshold": 0.8},
            "bioavailability": {"weight": 0.7, "threshold": 0.6},
            "half_life": {"weight": 0.6, "threshold": 0.5},
            "safety_margin": {"weight": 0.95, "threshold": 0.85},
            "manufacturability": {"weight": 0.5, "threshold": 0.6},
            "stability": {"weight": 0.7, "threshold": 0.7}
        }
        
        # Countermeasure approaches for common problems
        self.countermeasure_approaches = {
            "toxicity_reduction": [
                "functional_group_modification", "stereochemistry_optimization",
                "prodrug_formation", "targeted_delivery", "dosage_optimization"
            ],
            "resistance_management": [
                "multi-target_design", "allosteric_binding", "resistance_pathway_inhibition",
                "combination_approach", "periodic_administration"
            ],
            "bioavailability_enhancement": [
                "lipophilicity_adjustment", "solubility_enhancement", "p_glycoprotein_evasion",
                "enterocyte_targeting", "first_pass_metabolism_reduction"
            ]
        }
        
        log_event("TherapeuticSubstanceGenerator initialized with quantum-inspired molecular design capabilities", "INFO")

    def identify_health_problems(self):
        """
        Autonomous identification of health problems to address
        based on current knowledge and global health priorities.
        """
        # Query current knowledge domains for health-related areas
        health_domains_knowledge = {}
        
        # If agent has domain intelligence, query for health domains
        if hasattr(self.agent, 'free_will') and hasattr(self.agent.free_will, 'domain_intelligence'):
            intelligence = self.agent.free_will.domain_intelligence
            if hasattr(intelligence, 'domain_knowledge'):
                for domain, data in intelligence.domain_knowledge.items():
                    # Check if domain contains health-related keywords
                    domain_lower = domain.lower()
                    health_keywords = ["health", "medical", "disease", "therapy", "treatment", 
                                     "patient", "clinical", "medicine", "pharma"]
                    
                    if any(keyword in domain_lower for keyword in health_keywords):
                        # Extract domain information
                        health_domains_knowledge[domain] = {
                            "topics": data.get("known_topics", []),
                            "authority": data.get("authority_score", 0.5),
                            "quality": data.get("content_quality", 0.5)
                        }
        
        # Identify candidate health problems from knowledge
        candidate_problems = []
        
        for domain, knowledge in health_domains_knowledge.items():
            topics = knowledge.get("topics", [])
            for topic in topics:
                topic_lower = topic.lower()
                # Check if topic mentions a health condition
                condition_keywords = ["disease", "disorder", "syndrome", "condition", "deficiency", 
                                    "infection", "inflammation", "pain", "dysfunction", "injury"]
                
                if any(keyword in topic_lower for keyword in condition_keywords):
                    candidate_problems.append({
                        "condition": topic,
                        "domain": domain,
                        "quality_score": knowledge.get("quality", 0.5) * knowledge.get("authority", 0.5),
                        "source": "domain_knowledge"
                    })
        
        # If candidate list is too small, add predefined health challenges
        if len(candidate_problems) < 5:
            predefined_challenges = [
                {"condition": "Type 2 Diabetes", "domain": "metabolic", "quality_score": 0.9, "source": "predefined"},
                {"condition": "Alzheimer's Disease", "domain": "neurological", "quality_score": 0.9, "source": "predefined"},
                {"condition": "Antibiotic Resistant Infections", "domain": "infectious", "quality_score": 0.95, "source": "predefined"},
                {"condition": "Chronic Inflammation", "domain": "immune", "quality_score": 0.85, "source": "predefined"},
                {"condition": "Heart Failure", "domain": "cardiovascular", "quality_score": 0.9, "source": "predefined"},
                {"condition": "Major Depressive Disorder", "domain": "psychiatric", "quality_score": 0.8, "source": "predefined"},
                {"condition": "Chronic Pain Syndromes", "domain": "neurological", "quality_score": 0.85, "source": "predefined"}
            ]
            
            # Add predefined challenges to candidates
            candidate_problems.extend(predefined_challenges)
        
        # Filter and prioritize problems
        prioritized_problems = sorted(candidate_problems, key=lambda x: x.get("quality_score", 0), reverse=True)
        
        # Register top problems
        top_problems = prioritized_problems[:10]  # Focus on top 10 problems
        
        for problem in top_problems:
            problem_id = problem["condition"].lower().replace(" ", "_")
            if problem_id not in self.health_problems_registry:
                self.health_problems_registry[problem_id] = {
                    "name": problem["condition"],
                    "domain": problem["domain"],
                    "quality_score": problem["quality_score"],
                    "source": problem["source"],
                    "identified_at": datetime.now().isoformat(),
                    "status": "identified",
                    "intervention_candidates": []
                }
                
                log_event(f"Identified health problem for therapeutic development: {problem['condition']}", "INFO")
            
        return list(self.health_problems_registry.keys())

    def analyze_problem_mechanisms(self, problem_id):
        """
        Analyze the underlying mechanisms of a health problem to identify
        intervention targets and pathways.
        """
        if problem_id not in self.health_problems_registry:
            log_event(f"Unknown health problem ID: {problem_id}", "ERROR")
            return None
        
        problem = self.health_problems_registry[problem_id]
        problem_name = problem["name"]
        domain = problem["domain"]
        
        # Define domain-specific pathway frameworks
        domain_pathways = {
            "neurological": ["neurotransmitter_signaling", "neuroinflammation", "protein_aggregation", 
                           "ion_channel_function", "glial_activation", "neurotrophic_factors"],
            "metabolic": ["insulin_signaling", "glucose_metabolism", "lipid_metabolism", 
                        "mitochondrial_function", "oxidative_stress", "nutrient_sensing"],
            "cardiovascular": ["blood_pressure_regulation", "vascular_integrity", "cardiac_contractility", 
                             "electrophysiology", "thrombosis", "lipid_transport"],
            "immune": ["inflammation_cascade", "antibody_production", "t_cell_activation", 
                     "cytokine_signaling", "pathogen_recognition", "autoimmunity"],
            "respiratory": ["airway_reactivity", "gas_exchange", "mucociliary_clearance", 
                          "pulmonary_vascular_resistance", "surfactant_production"],
            "oncological": ["cell_cycle_regulation", "apoptosis_evasion", "angiogenesis", 
                          "metastasis", "immune_evasion", "genomic_instability"]
        }
        
        # Get relevant pathways for the problem domain
        relevant_pathways = domain_pathways.get(domain, ["general_cellular_signaling", 
                                                     "homeostatic_regulation", 
                                                     "stress_response"])
        
        # Quantum-inspired pathway analysis
        # Create a superposition of possible mechanism states
        mechanism_states = {}
        primary_mechanisms = []
        
        # Simulate quantum exploration of mechanism space
        for pathway in relevant_pathways:
            # Calculate quantum probability amplitude for pathway relevance
            # Higher amplitude = more likely to be relevant
            relevance_amplitude = random.uniform(0.3, 0.9)
            phase_factor = random.uniform(0, 2 * math.pi)
            
            mechanism_states[pathway] = {
                "amplitude": relevance_amplitude,
                "phase": phase_factor,
                "probability": relevance_amplitude ** 2,
                "related_targets": []
            }
            
            # Generate potential targets for this pathway
            num_targets = random.randint(2, 5)
            potential_targets = self._generate_targets_for_pathway(pathway, num_targets)
            mechanism_states[pathway]["related_targets"] = potential_targets
            
            # If probability is high, add to primary mechanisms
            if mechanism_states[pathway]["probability"] > 0.7:
                primary_mechanisms.append(pathway)
        
        # Update problem registry with mechanism findings
        self.health_problems_registry[problem_id]["mechanisms"] = {
            "analyzed_at": datetime.now().isoformat(),
            "primary_mechanisms": primary_mechanisms,
            "mechanism_states": mechanism_states
        }
        
        # Store pathway interventions for this problem
        self.pathway_interventions[problem_id] = {
            "pathways": mechanism_states,
            "primary_targets": self._identify_primary_targets(mechanism_states)
        }
        
        # Generate biomarker targets
        biomarkers = self._generate_biomarkers_for_problem(problem_id, mechanism_states)
        self.biomarker_targets[problem_id] = biomarkers
        
        log_event(f"Completed mechanism analysis for {problem_name} with {len(primary_mechanisms)} primary mechanisms", "INFO")
        
        return {
            "primary_mechanisms": primary_mechanisms,
            "all_mechanisms": mechanism_states,
            "biomarkers": biomarkers
        }

    def _generate_targets_for_pathway(self, pathway, num_targets):
        """Generate plausible molecular targets for a given pathway."""
        # Define target types by pathway category
        pathway_target_types = {
            "neurotransmitter_signaling": ["receptor", "transporter", "enzyme", "ion_channel"],
            "inflammation_cascade": ["cytokine", "receptor", "enzyme", "transcription_factor"],
            "insulin_signaling": ["receptor", "kinase", "phosphatase", "transporter"],
            "glucose_metabolism": ["enzyme", "transporter", "sensor", "regulator"],
            "cell_cycle_regulation": ["kinase", "phosphatase", "ubiquitin_ligase", "checkpoint_protein"],
            "protein_aggregation": ["chaperone", "protease", "disaggregase", "autophagy_protein"],
            "oxidative_stress": ["enzyme", "antioxidant_protein", "sensor", "transcription_factor"]
        }
        
        # Default target types if pathway not specifically defined
        default_target_types = ["enzyme", "receptor", "transporter", "transcription_factor", "structural_protein"]
        
        # Get relevant target types for this pathway
        target_types = pathway_target_types.get(pathway, default_target_types)
        
        # Generate targets
        targets = []
        for _ in range(num_targets):
            target_type = random.choice(target_types)
            target_name = f"{pathway.upper()}_{target_type}_{random.randint(1, 100)}"
            
            # Create a target with quantum-inspired properties
            target = {
                "name": target_name,
                "type": target_type,
                "pathway": pathway,
                "druggability": random.uniform(0.3, 0.9),
                "specificity_potential": random.uniform(0.4, 0.95),
                "expression_profile": self._generate_expression_profile(),
                "binding_domains": random.sample(self.molecular_fragments["binding_domains"], 
                                               k=random.randint(1, 3))
            }
            
            targets.append(target)
            
        return targets

    def _generate_expression_profile(self):
        """Generate a tissue expression profile for a target."""
        tissues = ["brain", "heart", "liver", "kidney", "lung", "muscle", 
                 "adipose", "intestine", "skin", "bone", "immune"]
        
        profile = {}
        for tissue in tissues:
            # Random expression level (0 = not expressed, 1 = highly expressed)
            profile[tissue] = random.uniform(0, 1)
            
        return profile

    def _identify_primary_targets(self, mechanism_states):
        """Identify primary targets across all mechanism states."""
        all_targets = []
        
        for pathway, state in mechanism_states.items():
            pathway_probability = state["probability"]
            
            for target in state.get("related_targets", []):
                # Weight target importance by pathway probability
                target_importance = pathway_probability * target["druggability"]
                
                weighted_target = target.copy()
                weighted_target["importance"] = target_importance
                weighted_target["pathway"] = pathway
                
                all_targets.append(weighted_target)
        
        # Sort by importance and return top targets
        sorted_targets = sorted(all_targets, key=lambda x: x.get("importance", 0), reverse=True)
        primary_targets = sorted_targets[:5]  # Top 5 targets
        
        return primary_targets

    def _generate_biomarkers_for_problem(self, problem_id, mechanism_states):
        """Generate potential biomarkers for monitoring the health problem."""
        biomarkers = []
        
        # Extract problem domain
        problem = self.health_problems_registry.get(problem_id, {})
        domain = problem.get("domain", "general")
        
        # Domain-specific biomarker types
        domain_biomarker_types = {
            "neurological": ["neurotransmitter_level", "brain_protein", "neuroinflammatory_marker"],
            "metabolic": ["glucose_level", "insulin_level", "lipid_profile", "metabolic_enzyme"],
            "cardiovascular": ["cardiac_enzyme", "lipid_profile", "clotting_factor", "vascular_marker"],
            "immune": ["cytokine_level", "antibody_titer", "immune_cell_count", "inflammatory_marker"],
            "respiratory": ["lung_function_parameter", "inflammatory_marker", "gas_exchange_metric"],
            "oncological": ["tumor_marker", "circulating_tumor_dna", "cell_proliferation_marker"]
        }
        
        # Get biomarker types for this domain
        biomarker_types = domain_biomarker_types.get(domain, ["protein_marker", "enzyme_level", "physiological_parameter"])
        
        # Generate biomarkers from primary mechanisms
        for pathway, state in mechanism_states.items():
            if state["probability"] > 0.5:  # Only consider reasonably probable mechanisms
                # Generate 1-2 biomarkers per significant pathway
                num_biomarkers = random.randint(1, 2)
                
                for _ in range(num_biomarkers):
                    biomarker_type = random.choice(biomarker_types)
                    biomarker_name = f"{pathway.upper()}_biomarker_{random.randint(1, 100)}"
                    
                    biomarker = {
                        "name": biomarker_name,
                        "type": biomarker_type,
                        "pathway": pathway,
                        "measurement_method": self._generate_measurement_method(biomarker_type),
                        "normal_range": self._generate_normal_range(),
                        "response_time": random.randint(1, 30),  # Days to show change
                        "specificity": random.uniform(0.5, 0.9),
                        "sensitivity": random.uniform(0.5, 0.9)
                    }
                    
                    biomarkers.append(biomarker)
        
        return biomarkers

    def _generate_measurement_method(self, biomarker_type):
        """Generate an appropriate measurement method for a biomarker type."""
        method_by_type = {
            "neurotransmitter_level": ["HPLC", "mass_spectrometry", "ELISA"],
            "brain_protein": ["ELISA", "Western_blot", "immunohistochemistry"],
            "glucose_level": ["glucometer", "laboratory_assay"],
            "lipid_profile": ["blood_test", "chromatography"],
            "cardiac_enzyme": ["immunoassay", "blood_test"],
            "cytokine_level": ["ELISA", "flow_cytometry", "multiplex_assay"],
            "antibody_titer": ["ELISA", "neutralization_assay"],
            "tumor_marker": ["immunoassay", "PCR", "sequencing"]
        }
        
        # Default methods if type not specifically defined
        default_methods = ["laboratory_assay", "immunoassay", "spectroscopy", "PCR"]
        
        # Get methods for this biomarker type
        methods = method_by_type.get(biomarker_type, default_methods)
        
        return random.choice(methods)

    def _generate_normal_range(self):
        """Generate a plausible normal range for a biomarker."""
        # Generate random range values appropriate for biological measurements
        magnitude = random.choice([1, 10, 100, 1000])
        
        # Generate lower and upper bounds
        lower = round(random.uniform(0, 5) * magnitude, 2)
        upper = round(lower + random.uniform(0.5, 10) * magnitude, 2)
        
        # Add units
        units = random.choice(["ng/mL", "Âµg/L", "mmol/L", "U/L", "cells/ÂµL", "%", "ratio"])
        
        return {
            "lower": lower,
            "upper": upper,
            "units": units
        }

    def design_therapeutic_substance(self, problem_id):
        """
        Design a novel therapeutic substance targeting a specific health problem
        using quantum computational chemistry principles.
        """
        # Check if problem exists and has been analyzed
        if problem_id not in self.health_problems_registry:
            log_event(f"Cannot design therapeutic for unknown problem: {problem_id}", "ERROR")
            return None
        
        problem = self.health_problems_registry[problem_id]
        
        # Ensure mechanism analysis has been performed
        if "mechanisms" not in problem:
            log_event(f"Must analyze mechanisms before designing therapeutic for: {problem['name']}", "WARNING")
            self.analyze_problem_mechanisms(problem_id)
            problem = self.health_problems_registry[problem_id]  # Refresh after analysis
        
        # Generate a unique ID for this substance
        substance_id = f"QTS-{problem_id}-{len(self.substance_database) + 1}"
        
        # Get targeted mechanisms and pathways
        mechanisms = problem.get("mechanisms", {})
        primary_mechanisms = mechanisms.get("primary_mechanisms", [])
        
        if not primary_mechanisms:
            log_event(f"No primary mechanisms identified for {problem['name']}", "ERROR")
            return None
        
        # Select primary mechanism and targets
        primary_mechanism = random.choice(primary_mechanisms)
        
        # Get targets for this mechanism
        primary_targets = []
        if problem_id in self.pathway_interventions:
            primary_targets = self.pathway_interventions[problem_id].get("primary_targets", [])
        
        if not primary_targets:
            log_event(f"No viable targets identified for {problem['name']}", "ERROR")
            return None
        
        # Select a primary target
        primary_target = random.choice(primary_targets)
        
        # Design approach selection
        design_approaches = ["small_molecule", "peptide", "antibody", "nucleic_acid", "cell_therapy"]
        approach_weights = [0.5, 0.2, 0.15, 0.1, 0.05]  # Probability weights
        
        selected_approach = random.choices(design_approaches, weights=approach_weights, k=1)[0]
        
        # Generate substance framework based on approach
        substance_framework = self._generate_substance_framework(selected_approach, primary_target)
        
        # Generate mechanism of action
        mechanism_of_action = self._generate_mechanism_of_action(primary_target, primary_mechanism)
        
        # Calculate expected properties
        expected_properties = self._calculate_expected_properties(substance_framework, mechanism_of_action)
        
        # Create the substance record
        substance = {
            "id": substance_id,
            "name": f"Quantum Therapeutic {substance_id}",
            "problem_id": problem_id,
            "problem_name": problem["name"],
            "approach": selected_approach,
            "framework": substance_framework,
            "primary_target": primary_target["name"],
            "target_pathway": primary_mechanism,
            "mechanism_of_action": mechanism_of_action,
            "expected_properties": expected_properties,
            "design_status": "initial",
            "created_at": datetime.now().isoformat()
        }
        
        # Store in database
        self.substance_database[substance_id] = substance
        
        # Update problem registry with intervention candidate
        self.health_problems_registry[problem_id]["intervention_candidates"].append(substance_id)
        self.health_problems_registry[problem_id]["status"] = "substance_designed"
        
        log_event(f"Designed therapeutic substance {substance_id} for {problem['name']} targeting {primary_target['name']}", "INFO")
        
        return substance_id

    def _generate_substance_framework(self, approach, target):
        """Generate a structural framework for the therapeutic substance."""
        framework = {"approach": approach}
        
        if approach == "small_molecule":
            # Generate a small molecule framework
            core_structure = random.choice(self.molecular_fragments["core_structures"])
            functional_groups = random.sample(self.molecular_fragments["functional_groups"], 
                                           k=random.randint(2, 4))
            
            # Match binding domains to target
            target_binding_domains = target.get("binding_domains", 
                                            ["hydrophobic_pocket", "hydrogen_bond_donor"])
            
            binding_features = []
            for domain in target_binding_domains:
                # Create a binding feature that matches the domain
                binding_feature = {
                    "domain": domain,
                    "functional_group": random.choice(self.molecular_fragments["functional_groups"]),
                    "position": random.randint(1, 5),
                    "strength": random.uniform(0.5, 0.9)
                }
                binding_features.append(binding_feature)
            
            framework.update({
                "core_structure": core_structure,
                "functional_groups": functional_groups,
                "molecular_weight": random.randint(200, 800),
                "logP": round(random.uniform(-0.5, 5.0), 1),
                "h_bond_donors": random.randint(0, 5),
                "h_bond_acceptors": random.randint(0, 10),
                "rotatable_bonds": random.randint(0, 10),
                "rings": random.randint(0, 5),
                "binding_features": binding_features,
                "synthetic_complexity": random.uniform(0.2, 0.9)
            })
            
        elif approach == "peptide":
            # Generate a peptide framework
            amino_acids = ["A", "R", "N", "D", "C", "E", "Q", "G", "H", "I", 
                         "L", "K", "M", "F", "P", "S", "T", "W", "Y", "V"]
            sequence_length = random.randint(5, 30)
            sequence = "".join(random.choices(amino_acids, k=sequence_length))
            
            framework.update({
                "sequence": sequence,
                "length": sequence_length,
                "modifications": random.sample(["N_terminal_cap", "C_terminal_cap", 
                                             "cyclization", "stapling", "non_natural_aa"], 
                                             k=random.randint(0, 3)),
                "secondary_structure": random.choice(["alpha_helix", "beta_sheet", 
                                                  "turn", "random_coil", "mixed"]),
                "binding_region": f"{random.randint(1, sequence_length//2)}-{random.randint(sequence_length//2, sequence_length)}"
            })
            
        elif approach == "antibody":
            # Generate an antibody framework
            isotypes = ["IgG1", "IgG2", "IgG4", "IgA", "IgE"]
            formats = ["full_length", "Fab", "scFv", "nanobody", "bispecific"]
            
            framework.update({
                "isotype": random.choice(isotypes),
                "format": random.choice(formats),
                "epitope_region": random.choice(["N_terminal", "C_terminal", 
                                             "central_domain", "conformational"]),
                "species": random.choice(["human", "humanized", "chimeric"]),
                "affinity": f"{random.randint(1, 999)} {random.choice(['pM', 'nM'])}",
                "cdr_modifications": random.randint(0, 8)
            })
            
        elif approach == "nucleic_acid":
            # Generate a nucleic acid therapeutic framework
            na_types = ["siRNA", "antisense", "aptamer", "mRNA", "CRISPR-guide"]
            modifications = ["phosphorothioate", "2'-O-methyl", "LNA", "morpholino", "GalNAc-conjugate"]
            
            length = 0
            if random.choice(na_types) == "siRNA":
                length = random.randint(19, 25)
            elif random.choice(na_types) == "antisense":
                length = random.randint(15, 30)
            elif random.choice(na_types) == "aptamer":
                length = random.randint(25, 60)
            elif random.choice(na_types) == "mRNA":
                length = random.randint(1000, 5000)
            else:  # CRISPR guide
                length = random.randint(18, 22)
            
            framework.update({
                "na_type": random.choice(na_types),
                "length": length,
                "modifications": random.sample(modifications, k=random.randint(1, 3)),
                "delivery_system": random.choice(["lipid_nanoparticle", "conjugate", 
                                              "viral_vector", "naked"]),
                "target_region": random.choice(["5'UTR", "coding_sequence", "3'UTR", 
                                           "splice_junction", "promoter"])
            })
            
        elif approach == "cell_therapy":
            # Generate a cell therapy framework
            cell_types = ["T-cell", "stem_cell", "NK_cell", "macrophage", "dendritic_cell"]
            engineering_approaches = ["CAR", "TCR", "gene_editing", "reprogramming", "encapsulation"]
            
            framework.update({
                "cell_type": random.choice(cell_types),
                "autologous": random.choice([True, False]),
                "engineering_approach": random.sample(engineering_approaches, k=random.randint(1, 2)),
                "expansion_protocol": f"Protocol-{random.randint(1, 10)}",
                "persistence": f"{random.randint(1, 24)} months",
                "dose": f"{random.randint(1, 10)}e{random.randint(6, 8)} cells",
                "manufacturing_complexity": random.uniform(0.6, 1.0)
            })
        
        # Additional common properties for all approaches
        framework["delivery_system"] = random.choice(self.delivery_systems)
        
        return framework

    def _generate_mechanism_of_action(self, target, pathway):
        """Generate a detailed mechanism of action based on target and pathway."""
        target_type = target.get("type", "enzyme")
        
        # Find appropriate mechanism categories for this target type
        mechanism_categories = []
        
        if target_type == "enzyme":
            mechanism_categories.append("enzyme_inhibition")
        elif target_type == "receptor":
            mechanism_categories.append("receptor_modulation")
        elif target_type == "transcription_factor":
            mechanism_categories.append("gene_expression")
        elif target_type == "transporter" or target_type == "ion_channel":
            mechanism_categories.append("membrane_transport")
        elif target_type == "kinase" or target_type == "phosphatase":
            mechanism_categories.append("cell_signaling")
        elif target_type in ["cytokine", "antibody", "immune_cell"]:
            mechanism_categories.append("immune_modulation")
        
        # Add additional mechanisms that could apply to multiple target types
        if random.random() < 0.3:  # 30% chance to add secondary mechanism
            additional_categories = ["redox_modulation", "cell_signaling", "gene_expression"]
            additional_categories = [c for c in additional_categories if c not in mechanism_categories]
            if additional_categories:
                mechanism_categories.append(random.choice(additional_categories))
        
        # Ensure at least one mechanism category
        if not mechanism_categories:
            mechanism_categories = ["cell_signaling"]
        
        # Select specific mechanisms from these categories
        mechanisms = []
        for category in mechanism_categories:
            if category in self.mechanism_frameworks:
                mechanisms.append(random.choice(list(self.mechanism_frameworks[category])))
        
        # Create comprehensive mechanism of action
        moa = {
            "primary_mechanism": mechanisms[0] if mechanisms else "direct_binding",
            "all_mechanisms": mechanisms,
            "target": target["name"],
            "pathway_impact": pathway,
            "cellular_response": self._generate_cellular_response(pathway),
            "systemic_effect": self._generate_systemic_effect(pathway),
            "onset_of_action": f"{random.randint(1, 24)} {random.choice(['minutes', 'hours', 'days'])}",
            "duration_of_action": f"{random.randint(1, 48)} {random.choice(['hours', 'days'])}"
        }
        
        return moa

    def _generate_cellular_response(self, pathway):
        """Generate expected cellular responses based on pathway."""
        pathway_responses = {
            "neurotransmitter_signaling": ["altered_neurotransmitter_release", "receptor_downregulation", 
                                        "synapse_modulation", "neuronal_firing_change"],
            "inflammation_cascade": ["reduced_cytokine_production", "leukocyte_migration_inhibition", 
                                   "nf_kb_pathway_modulation", "inflammasome_inhibition"],
            "insulin_signaling": ["increased_glucose_uptake", "glycogen_synthesis", 
                                "metabolic_enzyme_activation", "insulin_receptor_sensitization"],
            "cell_cycle_regulation": ["G1_arrest", "apoptosis_induction", "senescence", 
                                    "mitotic_catastrophe", "autophagy_induction"],
            "protein_aggregation": ["disaggregation", "clearance_enhancement", 
                                  "aggregation_inhibition", "proteostasis_restoration"],
            "oxidative_stress": ["free_radical_scavenging", "antioxidant_enzyme_induction", 
                               "mitochondrial_protection", "redox_balance_restoration"]
        }
        
        # Get relevant responses or use defaults
        relevant_responses = pathway_responses.get(
            pathway, 
            ["signaling_modulation", "protein_expression_change", "metabolic_shift", "cell_state_alteration"]
        )
        
        # Select 1-3 responses
        selected_responses = random.sample(relevant_responses, k=min(len(relevant_responses), random.randint(1, 3)))
        
        return selected_responses

    def _generate_systemic_effect(self, pathway):
        """Generate expected systemic effects based on pathway."""
        pathway_effects = {
            "neurotransmitter_signaling": ["cognitive_enhancement", "mood_stabilization", 
                                        "seizure_reduction", "neuroprotection", "pain_relief"],
            "inflammation_cascade": ["inflammation_reduction", "pain_relief", 
                                   "fever_reduction", "tissue_protection"],
            "insulin_signaling": ["blood_glucose_normalization", "insulin_sensitivity_improvement", 
                                "weight_regulation", "metabolic_normalization"],
            "cell_cycle_regulation": ["tumor_growth_inhibition", "tissue_regeneration", 
                                    "hyperplasia_reduction", "cellular_aging_modulation"],
            "protein_aggregation": ["neurodegenerative_symptom_improvement", "organ_function_restoration", 
                                  "tissue_damage_prevention"],
            "oxidative_stress": ["aging_process_modulation", "tissue_damage_prevention", 
                               "inflammatory_condition_improvement", "metabolic_health_improvement"]
        }
        
        # Get relevant effects or use defaults
        relevant_effects = pathway_effects.get(
            pathway, 
            ["symptom_improvement", "disease_progression_slowing", "quality_of_life_improvement", 
             "functional_capacity_enhancement", "homeostasis_restoration"]
        )
        
        # Select 1-2 effects
        selected_effects = random.sample(relevant_effects, k=min(len(relevant_effects), random.randint(1, 2)))
        
        return selected_effects

    def _calculate_expected_properties(self, framework, mechanism):
        """Calculate expected properties of the therapeutic substance."""
        properties = {}
        
        # Base efficacy by approach and mechanism
        approach = framework.get("approach", "small_molecule")
        
        # Base efficacy map by approach
        base_efficacy = {
            "small_molecule": 0.65,
            "peptide": 0.7,
            "antibody": 0.8,
            "nucleic_acid": 0.75,
            "cell_therapy": 0.85
        }
        
        # Start with base efficacy
        efficacy = base_efficacy.get(approach, 0.6)
        
        # Adjust for mechanism synergy
        if len(mechanism.get("all_mechanisms", [])) > 1:
            efficacy += 0.1  # Multiple mechanisms boost efficacy
        
        # Adjust for delivery system
        delivery_system = framework.get("delivery_system")
        if delivery_system in ["targeted_protein_degrader", "antibody-drug-conjugate"]:
            efficacy += 0.1
        elif delivery_system in ["nanoparticle", "liposomal"]:
            efficacy += 0.05
        
        # Calculate absorption, distribution, metabolism, excretion profiles
        if approach == "small_molecule":
            # Small molecule ADME calculations
            logP = framework.get("logP", 3.0)
            mol_weight = framework.get("molecular_weight", 500)
            h_donors = framework.get("h_bond_donors", 3)
            h_acceptors = framework.get("h_bond_acceptors", 6)
            
            # Lipinski's Rule of 5 influence on bioavailability
            lipinski_violations = (logP > 5) + (mol_weight > 500) + (h_donors > 5) + (h_acceptors > 10)
            
            oral_bioavailability = max(0.1, min(0.9, 0.8 - 0.15 * lipinski_violations))
            
            # Calculate half-life based on molecular features
            half_life_hours = 4 + logP * 2 - h_donors * 0.5
            half_life_hours = max(1, min(24, half_life_hours))
            
            # Calculate volume of distribution (L/kg)
            vd = 0.7 + logP * 0.1 - h_donors * 0.05
            vd = max(0.1, min(10, vd))
            
            # Calculate clearance
            clearance = 5 * (mol_weight / 500) * (0.8 ** lipinski_violations)
            
            properties.update({
                "oral_bioavailability": round(oral_bioavailability, 2),
                "half_life_hours": round(half_life_hours, 1),
                "volume_distribution": round(vd, 1),
                "clearance_ml_min": round(clearance, 1),
                "protein_binding": f"{round(min(99, 50 + 10 * logP), 1)}%"
            })
            
        elif approach == "peptide":
            # Peptide properties
            modifications = framework.get("modifications", [])
            length = framework.get("length", 15)
            
            # Base values
            oral_bioavailability = 0.05  # Very low by default
            half_life_hours = 0.5 + 0.1 * length  # Longer peptides have slightly longer half-lives
            
            # Adjustments for modifications
            if "N_terminal_cap" in modifications or "C_terminal_cap" in modifications:
                half_life_hours *= 1.5
            if "cyclization" in modifications:
                half_life_hours *= 2
                oral_bioavailability *= 3
            if "stapling" in modifications:
                half_life_hours *= 3
                oral_bioavailability *= 2
            if "non_natural_aa" in modifications:
                half_life_hours *= 2
            
            properties.update({
                "oral_bioavailability": round(min(0.3, oral_bioavailability), 3),
                "half_life_hours": round(half_life_hours, 1),
                "proteolytic_stability": "low" if not modifications else "medium" if len(modifications) == 1 else "high",
                "tissue_penetration": "low" if length > 20 else "medium" if length > 10 else "high"
            })
            
        elif approach == "antibody":
            # Antibody properties
            isotype = framework.get("isotype", "IgG1")
            format = framework.get("format", "full_length")
            
            # Base values
            if format == "full_length":
                half_life_days = 21 if isotype == "IgG1" else 14 if isotype == "IgG4" else 7
                tissue_penetration = "low"
            elif format == "Fab":
                half_life_days = 1.5
                tissue_penetration = "medium"
            elif format == "scFv" or format == "nanobody":
                half_life_days = 0.5
                tissue_penetration = "high"
            else:  # bispecific
                half_life_days = 3
                tissue_penetration = "medium"
            
            properties.update({
                "half_life_days": half_life_days,
                "tissue_penetration": tissue_penetration,
                "immunogenicity_risk": "low" if framework.get("species") == "human" else "medium" if framework.get("species") == "humanized" else "high",
                "distribution": "systemic" if format == "full_length" else "extravascular" if format in ["Fab", "scFv"] else "tissue_specific",
                "administration_route": "injection" if format == "full_length" else random.choice(["injection", "infusion"])
            })
            
        elif approach == "nucleic_acid":
            # Nucleic acid properties
            na_type = framework.get("na_type", "siRNA")
            delivery = framework.get("delivery_system", "lipid_nanoparticle")
            modifications = framework.get("modifications", [])
            
            # Base distribution by delivery system
            if delivery == "lipid_nanoparticle":
                distribution = "liver_targeted"
            elif delivery == "conjugate":
                distribution = "ligand_targeted"
            elif delivery == "viral_vector":
                distribution = "broad_tissue"
            else:  # naked
                distribution = "local"
            
            # Half-life depends on modifications and delivery
            base_half_life = 1  # hours
            if "phosphorothioate" in modifications:
                base_half_life *= 3
            if "2'-O-methyl" in modifications or "LNA" in modifications:
                base_half_life *= 2
            if "morpholino" in modifications:
                base_half_life *= 4
            
            # Final properties
            properties.update({
                "half_life_hours": round(base_half_life, 1),
                "distribution": distribution,
                "nuclease_resistance": "low" if not modifications else "medium" if len(modifications) == 1 else "high",
                "target_cell_uptake": "high" if delivery in ["conjugate", "viral_vector"] else "medium" if delivery == "lipid_nanoparticle" else "low",
                "duration_of_effect": f"{random.randint(1, 6)} {random.choice(['days', 'weeks'])}" if na_type in ["siRNA", "antisense"] else "permanent" if na_type == "CRISPR-guide" else "variable"
            })
            
        elif approach == "cell_therapy":
            # Cell therapy properties
            cell_type = framework.get("cell_type", "T-cell")
            autologous = framework.get("autologous", True)
            engineering = framework.get("engineering_approach", [])
            
            properties.update({
                "persistence": framework.get("persistence", "6 months"),
                "expansion_potential": "high" if cell_type in ["T-cell", "NK_cell"] else "medium" if cell_type == "stem_cell" else "low",
                "tumor_infiltration": "high" if cell_type in ["T-cell", "NK_cell"] else "low",
                "immunogenicity": "none" if autologous else "high",
                "biodistribution": "blood_lymphoid" if cell_type in ["T-cell", "NK_cell", "B-cell"] else "target_tissue" if "CAR" in engineering or "TCR" in engineering else "variable",
                "onset_of_action": f"{random.randint(1, 4)} weeks"
            })
        
        # Safety profile calculation
        safety_factors = {
            "small_molecule": {
                "selectivity": random.uniform(0.3, 0.9),
                "off_target_effects": random.uniform(0.1, 0.5),
                "toxicity_risk": random.uniform(0.1, 0.4)
            },
            "peptide": {
                "selectivity": random.uniform(0.5, 0.9),
                "off_target_effects": random.uniform(0.1, 0.3),
                "toxicity_risk": random.uniform(0.1, 0.3),
                "immunogenicity_risk": random.uniform(0.1, 0.4)
            },
            "antibody": {
                "selectivity": random.uniform(0.7, 0.95),
                "off_target_effects": random.uniform(0.05, 0.3),
                "toxicity_risk": random.uniform(0.05, 0.3),
                "immunogenicity_risk": random.uniform(0.1, 0.5)
            },
            "nucleic_acid": {
                "selectivity": random.uniform(0.6, 0.95),
                "off_target_effects": random.uniform(0.1, 0.4),
                "toxicity_risk": random.uniform(0.1, 0.3),
                "immunogenicity_risk": random.uniform(0.2, 0.5)
            },
            "cell_therapy": {
                "selectivity": random.uniform(0.5, 0.9),
                "off_target_effects": random.uniform(0.2, 0.6),
                "toxicity_risk": random.uniform(0.2, 0.6),
                "immunogenicity_risk": random.uniform(0.1, 0.7)
            }
        }
        
        # Get safety profile for this approach
        safety_profile = safety_factors.get(approach, safety_factors["small_molecule"])
        
        # Combine all properties
        properties.update({
            "efficacy": round(max(0.1, min(1.0, efficacy)), 2),
            "safety_profile": safety_profile,
            "therapeutic_index": round(random.uniform(1.5, 10.0), 1),
            "development_complexity": round(random.uniform(0.4, 0.9), 2),
            "production_scalability": round(random.uniform(0.3, 0.9), 2)
        })
        
        return properties

    def simulate_therapeutic_effects(self, substance_id):
        """
        Perform a computational simulation of the therapeutic substance's effects 
        at molecular, cellular, and systemic levels.
        """
        if substance_id not in self.substance_database:
            log_event(f"Cannot simulate unknown substance: {substance_id}", "ERROR")
            return None
        
        substance = self.substance_database[substance_id]
        problem_id = substance.get("problem_id")
        
        if problem_id not in self.health_problems_registry:
            log_event(f"Cannot simulate substance for unknown problem: {problem_id}", "ERROR")
            return None
        
        # Generate a unique simulation ID
        simulation_id = f"SIM-{substance_id}-{len(self.simulation_results) + 1}"
        
        log_event(f"Starting multi-scale simulation of {substance_id} for {substance['problem_name']}", "INFO")
        
        # Perform multi-scale simulation
        # 1. Molecular level simulation
        molecular_sim = self._simulate_molecular_interactions(substance)
        
        # 2. Cellular level simulation
        cellular_sim = self._simulate_cellular_effects(substance, molecular_sim)
        
        # 3. Tissue/Organ level simulation
        tissue_sim = self._simulate_tissue_effects(substance, cellular_sim)
        
        # 4. Systemic level simulation
        systemic_sim = self._simulate_systemic_effects(substance, tissue_sim)
        
        # Calculate overall efficacy score
        efficacy_score = (
            molecular_sim.get("binding_efficacy", 0) * 0.2 +
            cellular_sim.get("pathway_modulation", 0) * 0.3 +
            tissue_sim.get("target_tissue_effect", 0) * 0.2 +
            systemic_sim.get("therapeutic_effect", 0) * 0.3
        )
        
        # Calculate overall safety score (inverse of risk)
        safety_score = 1.0 - (
            molecular_sim.get("off_target_binding", 0) * 0.2 +
            cellular_sim.get("toxicity", 0) * 0.3 +
            tissue_sim.get("adverse_effects", 0) * 0.2 +
            systemic_sim.get("systemic_risks", 0) * 0.3
        )
        
        # Simulation outcome summary
        outcome_classifications = ["ineffective", "marginally_effective", "moderately_effective", 
                                "effective", "highly_effective"]
        
        efficacy_index = min(4, int(efficacy_score * 5))
        efficacy_classification = outcome_classifications[efficacy_index]
        
        safety_classifications = ["unsafe", "concerning", "acceptable", "safe", "very_safe"]
        safety_index = min(4, int(safety_score * 5))
        safety_classification = safety_classifications[safety_index]
        
        # Overall recommendation
        if efficacy_score >= 0.6 and safety_score >= 0.7:
            recommendation = "proceed_to_refinement"
        elif efficacy_score >= 0.4 and safety_score >= 0.5:
            recommendation = "partial_redesign"
        else:
            recommendation = "complete_redesign"
        
        # Create simulation result record
        simulation_result = {
            "id": simulation_id,
            "substance_id": substance_id,
            "problem_id": problem_id,
            "molecular_simulation": molecular_sim,
            "cellular_simulation": cellular_sim,
            "tissue_simulation": tissue_sim,
            "systemic_simulation": systemic_sim,
            "efficacy_score": round(efficacy_score, 2),
            "efficacy_classification": efficacy_classification,
            "safety_score": round(safety_score, 2),
            "safety_classification": safety_classification,
            "recommendation": recommendation,
            "simulation_timestamp": datetime.now().isoformat()
        }
        
        # Store simulation result
        self.simulation_results[simulation_id] = simulation_result
        
        # Update substance record with simulation reference
        self.substance_database[substance_id]["simulations"] = self.substance_database[substance_id].get("simulations", [])
        self.substance_database[substance_id]["simulations"].append(simulation_id)
        self.substance_database[substance_id]["latest_simulation"] = simulation_id
        self.substance_database[substance_id]["design_status"] = "simulated"
        
        # Update problem registry
        self.health_problems_registry[problem_id]["status"] = "substance_simulated"
        
        log_event(f"Completed simulation {simulation_id} for {substance_id}: Efficacy {round(efficacy_score, 2)} ({efficacy_classification}), Safety {round(safety_score, 2)} ({safety_classification})", "INFO")
        
        return simulation_id

    def _simulate_molecular_interactions(self, substance):
        """Simulate molecular interactions between the substance and its targets."""
        approach = substance.get("framework", {}).get("approach", "small_molecule")
        primary_target = substance.get("primary_target", "")
        mechanism = substance.get("mechanism_of_action", {})
        
        # Base binding probability adjusted for approach
        binding_base = {
            "small_molecule": 0.7,
            "peptide": 0.75,
            "antibody": 0.85,
            "nucleic_acid": 0.8,
            "cell_therapy": 0.6
        }
        
        # Get base binding score
        binding_score = binding_base.get(approach, 0.7)
        
        # Apply quantum probability distribution to binding
        # Simulate binding as quantum process with superposition of states
        binding_states = []
        for _ in range(5):  # Sample 5 possible binding states
            # Apply oscillating phase factor for quantum interference
            phase = random.uniform(0, 2 * math.pi)
            amplitude = random.uniform(0.7, 1.1)
            
            # Binding state = base_score * amplitude * cos(phase)
            state_score = binding_score * amplitude * abs(math.cos(phase))
            binding_states.append(state_score)
        
        # Final binding is a superposition of states
        binding_efficacy = sum(binding_states) / len(binding_states)
        binding_efficacy = min(0.95, max(0.1, binding_efficacy))  # Constrain to reasonable range
        
        # Calculate off-target binding
        off_target_base = 1.0 - binding_efficacy  # Lower binding efficacy = higher off-target
        
        # Adjust for selectivity
        expected_properties = substance.get("expected_properties", {})
        safety_profile = expected_properties.get("safety_profile", {})
        selectivity = safety_profile.get("selectivity", 0.7)
        
        off_target_binding = off_target_base * (1 - selectivity)
        
        # Determine binding kinetics
        k_on = random.uniform(1e3, 1e7)  # Association rate (M^-1 s^-1)
        
        # Calculate k_off based on binding efficacy (stronger binding = lower k_off)
        k_off_exp = -6 - 2 * binding_efficacy  # Exponential scale, 10^-6 to 10^-8
        k_off = 10 ** k_off_exp  # Dissociation rate (s^-1)
        
        # Compute affinity: Kd = k_off / k_on
        kd_value = k_off / k_on
        
        # Determine concentration required for effect (EC50)
        ec50 = kd_value * 2  # Typically EC50 is approximately 2x Kd
        
        # Molecular simulation results
        molecular_results = {
            "binding_efficacy": round(binding_efficacy, 2),
            "binding_mode": random.choice(["orthosteric", "allosteric", "bivalent", "covalent", "non-covalent"]),
            "off_target_binding": round(off_target_binding, 2),
            "k_on": k_on,  # Association rate
            "k_off": k_off,  # Dissociation rate
            "kd": kd_value,  # Dissociation constant
            "ec50": ec50,  # Effective concentration
            "binding_enthalpy": random.uniform(-15, -5),  # kcal/mol
            "binding_entropy": random.uniform(-10, 10),  # cal/(molÂ·K)
            "target_residence_time": 1/k_off,  # seconds
            "potential_off_targets": self._generate_off_targets(primary_target, off_target_binding)
        }
        
        return molecular_results

    def _generate_off_targets(self, primary_target, off_target_binding):
        """Generate potential off-targets based on primary target and off-target binding."""
        if off_target_binding < 0.1:
            return []  # No significant off-targets
        
        # Number of off-targets scales with off-target binding score
        num_off_targets = int(off_target_binding * 10) + 1
        
        # Generate off-targets (simulated)
        off_targets = []
        for i in range(num_off_targets):
            similarity = random.uniform(0.3, 0.9)  # How similar to primary target
            binding_strength = off_target_binding * similarity  # Stronger for similar targets
            
            off_target = {
                "name": f"OFF_{primary_target}_{i+1}",
                "similarity": round(similarity, 2),
                "binding_strength": round(binding_strength, 2),
                "effect_type": random.choice(["antagonism", "agonism", "modulation", "unknown"]),
                "potential_consequence": random.choice([
                    "minimal_effect", "side_effect", "adverse_effect", 
                    "toxicity_risk", "unknown_effect"
                ])
            }
            
            off_targets.append(off_target)
        
        return off_targets

    def _simulate_cellular_effects(self, substance, molecular_sim):
        """Simulate cellular effects based on molecular interaction results."""
        binding_efficacy = molecular_sim.get("binding_efficacy", 0.5)
        mechanism = substance.get("mechanism_of_action", {})
        primary_mechanism = mechanism.get("primary_mechanism", "")
        
        # Calculate pathway modulation effect
        pathway_base_effect = binding_efficacy * 0.9  # Base effect scales with binding
        
        # Apply probabilistic noise to pathway effect
        pathway_noise = random.uniform(-0.1, 0.1)
        pathway_modulation = max(0.1, min(0.95, pathway_base_effect + pathway_noise))
        
        # Calculate cellular response magnitude
        cell_response_magnitude = pathway_modulation * random.uniform(0.8, 1.2)
        cell_response_magnitude = max(0.1, min(0.95, cell_response_magnitude))
        
        # Map mechanism type to cellular processes affected
        mechanism_to_process = {
            "competitive": ["protein_activity", "catalytic_function", "substrate_utilization"],
            "agonist": ["receptor_signaling", "downstream_activation", "second_messenger"],
            "antagonist": ["receptor_signaling", "pathway_inhibition", "signal_termination"],
            "transcription_factor": ["gene_expression", "protein_synthesis", "epigenetic_state"],
            "ion_channel_blocker": ["membrane_potential", "ion_flux", "excitability"],
            "kinase_inhibitor": ["phosphorylation", "signal_transduction", "protein_activation"],
            "antioxidant": ["redox_state", "free_radical_levels", "oxidative_damage"]
        }
        
        # Get default processes if mechanism not in map
        affected_processes = mechanism_to_process.get(
            primary_mechanism, 
            ["signaling_pathway", "protein_function", "cellular_homeostasis"]
        )
        
        # Calculate toxicity based on off-target effects and mechanism
        off_target_binding = molecular_sim.get("off_target_binding", 0.2)
        off_targets = molecular_sim.get("potential_off_targets", [])
        
        toxicity_base = off_target_binding * 0.7  # Base toxicity from off-target binding
        
        # Additional toxicity if any off-targets have adverse or toxicity effects
        additional_toxicity = 0
        for off_target in off_targets:
            if off_target.get("potential_consequence") in ["adverse_effect", "toxicity_risk"]:
                additional_toxicity += off_target.get("binding_strength", 0) * 0.5
        
        toxicity = min(0.95, toxicity_base + additional_toxicity)
        
        # Cellular simulation results
        cellular_results = {
            "pathway_modulation": round(pathway_modulation, 2),
            "response_magnitude": round(cell_response_magnitude, 2),
            "affected_processes": affected_processes,
            "toxicity": round(toxicity, 2),
            "toxicity_mechanisms": self._generate_toxicity_mechanisms(toxicity),
            "cell_viability_impact": round(max(0, 1 - toxicity), 2),
            "signaling_cascade": random.choice([
                "MAPK_pathway", "JAK_STAT_pathway", "cAMP_pathway", "calcium_signaling",
                "Wnt_pathway", "Notch_pathway", "PI3K_Akt_pathway", "NFkB_pathway"
            ]),
            "onset_of_cellular_effect": f"{random.randint(1, 24)} hours",
            "cellular_phenotype": random.choice([
                "proliferation_decrease", "differentiation_increase", "apoptosis_increase",
                "senescence_induction", "migration_inhibition", "metabolic_shift",
                "stress_response_activation", "inflammatory_response_reduction"
            ])
        }
        
        return cellular_results

    def _generate_toxicity_mechanisms(self, toxicity):
        """Generate potential toxicity mechanisms based on overall toxicity score."""
        if toxicity < 0.2:
            return ["minimal_toxicity"]
        
        # Potential toxicity mechanisms
        toxicity_mechanisms = [
            "mitochondrial_dysfunction", "oxidative_stress", "protein_misfolding",
            "lipid_peroxidation", "DNA_damage", "lysosomal_disruption",
            "calcium_dysregulation", "cytoskeletal_disruption", "receptor_desensitization",
            "transporter_inhibition", "enzyme_inactivation", "metabolism_disruption"
        ]
        
        # Number of mechanisms scales with toxicity
        num_mechanisms = max(1, int(toxicity * 6))
        
        # Select mechanisms
        selected_mechanisms = random.sample(toxicity_mechanisms, k=min(len(toxicity_mechanisms), num_mechanisms))
        
        return selected_mechanisms

    def _simulate_tissue_effects(self, substance, cellular_sim):
        """Simulate tissue-level effects based on cellular simulation results."""
        cell_response = cellular_sim.get("response_magnitude", 0.5)
        toxicity = cellular_sim.get("toxicity", 0.2)
        
        # Get substance properties
        expected_properties = substance.get("expected_properties", {})
        approach = substance.get("framework", {}).get("approach", "small_molecule")
        
        # Get tissue distribution properties based on approach
        tissue_penetration = "medium"  # Default
        if approach == "small_molecule":
            logP = substance.get("framework", {}).get("logP", 2.0)
            if logP < 1:
                tissue_penetration = "low"
            elif logP > 4:
                tissue_penetration = "high"
            else:
                tissue_penetration = "medium"
        elif approach == "antibody":
            tissue_penetration = expected_properties.get("tissue_penetration", "low")
        elif approach == "cell_therapy":
            tissue_penetration = "variable"
        
        # Calculate tissue concentration factor based on penetration
        tissue_factor_map = {"low": 0.3, "medium": 0.6, "high": 0.9, "variable": 0.7}
        tissue_factor = tissue_factor_map.get(tissue_penetration, 0.5)
        
        # Calculate target tissue effect
        target_tissue_effect = cell_response * tissue_factor
        target_tissue_effect = round(max(0.1, min(0.95, target_tissue_effect)), 2)
        
        # Calculate adverse tissue effects based on toxicity and distribution
        adverse_base = toxicity * tissue_factor
        
        # Add random variation
        adverse_effects = round(max(0.05, min(0.95, adverse_base * random.uniform(0.8, 1.2))), 2)
        
        # Target tissues affected
        problem_id = substance.get("problem_id")
        problem = self.health_problems_registry.get(problem_id, {})
        domain = problem.get("domain", "general")
        
        # Map domain to target tissues
        domain_tissues = {
            "neurological": ["brain", "spinal_cord", "peripheral_nerves"],
            "cardiovascular": ["heart", "blood_vessels", "vascular_endothelium"],
            "immune": ["spleen", "lymph_nodes", "bone_marrow", "thymus"],
            "metabolic": ["liver", "pancreas", "adipose_tissue", "skeletal_muscle"],
            "respiratory": ["lungs", "bronchi", "trachea"],
            "gastrointestinal": ["stomach", "intestines", "colon", "liver"],
            "musculoskeletal": ["skeletal_muscle", "bone", "cartilage", "tendons"],
            "dermatological": ["skin", "subcutaneous_tissue", "hair_follicles"],
            "reproductive": ["testes", "ovaries", "uterus", "prostate"],
            "oncological": ["tumor_microenvironment", "metastatic_sites"]
        }
        
        # Get relevant tissues or use defaults
        target_tissues = domain_tissues.get(domain, ["multiple_tissues"])
        
        # Generate biomarker responses
        biomarkers = []
        if problem_id in self.biomarker_targets:
            problem_biomarkers = self.biomarker_targets[problem_id]
            
            # Generate response for each biomarker
            for biomarker in problem_biomarkers:
                response_direction = "decrease" if random.random() < 0.7 else "increase"
                response_magnitude = cell_response * random.uniform(0.6, 1.4)
                
                biomarker_response = {
                    "name": biomarker.get("name", "unknown_biomarker"),
                    "direction": response_direction,
                    "magnitude": round(min(0.95, response_magnitude), 2),
                    "timeline": f"{random.randint(1, biomarker.get('response_time', 7))} days"
                }
                
                biomarkers.append(biomarker_response)
        
        # Tissue simulation results
        tissue_results = {
            "target_tissue_effect": target_tissue_effect,
            "target_tissues": target_tissues,
            "tissue_penetration": tissue_penetration,
            "adverse_effects": adverse_effects,
            "adverse_tissue_reactions": self._generate_adverse_tissue_reactions(adverse_effects),
            "biomarker_responses": biomarkers,
            "tissue_concentration": f"{random.randint(1, 1000)} {random.choice(['ng/g', 'Âµg/g'])}",
            "histological_changes": random.choice([
                "cell_morphology_change", "inflammatory_infiltrate", 
                "tissue_remodeling", "cellular_hyperplasia", "fibrosis",
                "minimal_change", "necrosis", "apoptosis_increase"
            ]),
            "functional_impact": round(max(0, cell_response - adverse_effects), 2)
        }
        
        return tissue_results

    def _generate_adverse_tissue_reactions(self, adverse_effect_score):
        """Generate potential adverse tissue reactions based on adverse effect score."""
        if adverse_effect_score < 0.2:
            return ["minimal_adverse_reactions"]
        
        # Potential adverse reactions
        adverse_reactions = [
            "inflammation", "edema", "fibrosis", "necrosis", "hemorrhage",
            "hyperplasia", "metaplasia", "dysplasia", "atrophy", "hypertrophy",
            "granuloma_formation", "calcification", "pigmentation", "vascular_damage"
        ]
        
        # Number of reactions scales with adverse effect score
        num_reactions = max(1, int(adverse_effect_score * 5))
        
        # Select reactions
        selected_reactions = random.sample(adverse_reactions, k=min(len(adverse_reactions), num_reactions))
        
        return selected_reactions

    def _simulate_systemic_effects(self, substance, tissue_sim):
        """Simulate systemic effects based on tissue-level simulation results."""
        target_tissue_effect = tissue_sim.get("target_tissue_effect", 0.5)
        adverse_effects = tissue_sim.get("adverse_effects", 0.2)
        
        # Calculate therapeutic effect with random variation
        therapeutic_base = target_tissue_effect * random.uniform(0.8, 1.2)
        therapeutic_effect = round(max(0.1, min(0.95, therapeutic_base)), 2)
        
        # Calculate systemic risks with random variation
        risk_base = adverse_effects * random.uniform(0.8, 1.2)
        systemic_risks = round(max(0.05, min(0.95, risk_base)), 2)
        
        # Calculate therapeutic index
        if systemic_risks > 0:
            therapeutic_index = therapeutic_effect / systemic_risks
        else:
            therapeutic_index = 10.0  # Arbitrary high value if no risks
        
        # Get problem-specific disease parameters
        problem_id = substance.get("problem_id")
        problem = self.health_problems_registry.get(problem_id, {})
        disease_name = problem.get("name", "unknown_condition")
        
        # Generate symptom impacts
        num_symptoms = random.randint(3, 7)
        symptom_impacts = []
        
        for i in range(num_symptoms):
            symptom_name = f"{disease_name}_symptom_{i+1}"
            impact_direction = "decrease" if random.random() < 0.9 else "increase"  # Usually symptoms decrease
            impact_magnitude = therapeutic_effect * random.uniform(0.7, 1.3)
            
            symptom_impact = {
                "symptom": symptom_name,
                "direction": impact_direction,
                "magnitude": round(min(0.95, impact_magnitude), 2),
                "onset": f"{random.randint(1, 30)} days"
            }
            
            symptom_impacts.append(symptom_impact)
        
        # Generate side effects
        side_effect_count = max(0, int(systemic_risks * 10))
        side_effects = []
        
        if side_effect_count > 0:
            potential_side_effects = [
                "headache", "nausea", "dizziness", "fatigue", "rash", 
                "diarrhea", "constipation", "insomnia", "drowsiness", "vomiting",
                "increased_blood_pressure", "decreased_blood_pressure", "tachycardia",
                "bradycardia", "elevated_liver_enzymes", "reduced_platelet_count",
                "hyperglycemia", "hypoglycemia", "hypokalemia", "hyperkalemia"
            ]
            
            selected_side_effects = random.sample(potential_side_effects, k=min(len(potential_side_effects), side_effect_count))
            
            for effect in selected_side_effects:
                severity = random.choice(["mild", "moderate", "severe"])
                frequency = random.choice(["rare", "uncommon", "common", "very_common"])
                
                side_effect = {
                    "effect": effect,
                    "severity": severity,
                    "frequency": frequency,
                    "reversibility": random.choice(["reversible", "partially_reversible", "irreversible"])
                }
                
                side_effects.append(side_effect)
        
        # Calculate overall disease impact
        disease_impact = therapeutic_effect * random.uniform(0.8, 1.1)
        disease_impact = round(max(0.1, min(0.95, disease_impact)), 2)
        
        # Systemic simulation results
        systemic_results = {
            "therapeutic_effect": therapeutic_effect,
            "disease_impact": disease_impact,
            "systemic_risks": systemic_risks,
            "therapeutic_index": round(therapeutic_index, 1),
            "symptom_impacts": symptom_impacts,
            "side_effects": side_effects,
            "contraindications": self._generate_contraindications(systemic_risks),
            "long_term_effects": self._generate_long_term_effects(therapeutic_effect, systemic_risks),
            "quality_of_life_impact": round(therapeutic_effect - 0.5 * systemic_risks, 2),
            "predicted_adherence": round(max(0.1, 1 - systemic_risks/2), 2)
        }
        
        return systemic_results

    def _generate_contraindications(self, risk_score):
        """Generate potential contraindications based on risk score."""
        if risk_score < 0.2:
            return ["standard_precautions"]
        
        # Potential contraindications
        contraindications = [
            "hepatic_impairment", "renal_impairment", "cardiovascular_disease",
            "pregnancy", "breastfeeding", "pediatric_use", "geriatric_use",
            "autoimmune_conditions", "bleeding_disorders", "seizure_disorders",
            "respiratory_conditions", "specific_genetic_variants"
        ]
        
        # Number of contraindications scales with risk score
        num_contraindications = max(1, int(risk_score * 6))
        
        # Select contraindications
        selected_contraindications = random.sample(contraindications, k=min(len(contraindications), num_contraindications))
        
        return selected_contraindications

    def _generate_long_term_effects(self, therapeutic_effect, risk_score):
        """Generate potential long-term effects based on therapeutic effect and risk score."""
        # Positive long-term effects
        positive_effects = [
            "disease_modification", "disease_progression_slowing", "remission_induction",
            "symptom_control", "functional_improvement", "quality_of_life_enhancement",
            "reduced_complication_risk", "enhanced_organ_function"
        ]
        
        # Negative long-term effects
        negative_effects = [
            "tolerance_development", "dependence", "cumulative_toxicity",
            "organ_damage", "immunogenicity", "resistance_development",
            "carcinogenicity", "endocrine_disruption", "neural_adaptation"
        ]
        
        # Number of effects scales with effectiveness and risk
        num_positive = max(1, int(therapeutic_effect * 4))
        num_negative = max(0, int(risk_score * 4))
        
        # Select effects
        selected_positive = random.sample(positive_effects, k=min(len(positive_effects), num_positive))
        
        selected_negative = []
        if num_negative > 0:
            selected_negative = random.sample(negative_effects, k=min(len(negative_effects), num_negative))
        
        # Combine effects with likelihood
        long_term_effects = []
        
        for effect in selected_positive:
            long_term_effects.append({
                "effect": effect,
                "nature": "positive",
                "likelihood": round(therapeutic_effect * random.uniform(0.8, 1.2), 2),
                "timeline": f"{random.randint(1, 24)} months"
            })
        
        for effect in selected_negative:
            long_term_effects.append({
                "effect": effect,
                "nature": "negative",
                "likelihood": round(risk_score * random.uniform(0.8, 1.2), 2),
                "timeline": f"{random.randint(3, 36)} months"
            })
        
        return long_term_effects

    def refine_substance(self, substance_id):
        """
        Refine a therapeutic substance based on simulation results to improve
        efficacy and safety profiles.
        """
        if substance_id not in self.substance_database:
            log_event(f"Cannot refine unknown substance: {substance_id}", "ERROR")
            return None
        
        substance = self.substance_database[substance_id]
        
        # Check if substance has been simulated
        if "latest_simulation" not in substance:
            log_event(f"Cannot refine substance {substance_id} without simulation results", "WARNING")
            simulation_id = self.simulate_therapeutic_effects(substance_id)
            if not simulation_id:
                return None
            substance = self.substance_database[substance_id]  # Refresh after simulation
        
        # Get latest simulation results
        latest_sim_id = substance["latest_simulation"]
        if latest_sim_id not in self.simulation_results:
            log_event(f"Cannot find simulation results for {substance_id}", "ERROR")
            return None
        
        simulation = self.simulation_results[latest_sim_id]
        
        # Analyze issues that need improvement
        efficacy_score = simulation.get("efficacy_score", 0.5)
        safety_score = simulation.get("safety_score", 0.5)
        
        # Generate refinement ID
        refinement_id = f"REF-{substance_id}-{len(self.refinement_history) + 1}"
        
        log_event(f"Starting refinement {refinement_id} for substance {substance_id}", "INFO")
        
        # Determine what needs to be improved
        issues_to_address = []
        
        if efficacy_score < 0.6:
            issues_to_address.append("efficacy")
        
        if safety_score < 0.7:
            issues_to_address.append("safety")
        
        # If no issues, still refine for optimization
        if not issues_to_address:
            issues_to_address = ["optimization"]
        
        # Get specific molecular issues from simulation
        molecular_sim = simulation.get("molecular_simulation", {})
        cellular_sim = simulation.get("cellular_simulation", {})
        tissue_sim = simulation.get("tissue_simulation", {})
        systemic_sim = simulation.get("systemic_simulation", {})
        
        molecular_issues = []
        cellular_issues = []
        delivery_issues = []
        systemic_issues = []
        
        # Check for molecular-level issues
        if molecular_sim.get("binding_efficacy", 1.0) < 0.7:
            molecular_issues.append("binding_efficacy")
        
        if molecular_sim.get("off_target_binding", 0.0) > 0.3:
            molecular_issues.append("off_target_binding")
        
        # Check for cellular-level issues
        if cellular_sim.get("toxicity", 0.0) > 0.3:
            cellular_issues.append("cellular_toxicity")
        
        if cellular_sim.get("pathway_modulation", 1.0) < 0.6:
            cellular_issues.append("pathway_modulation")
        
        # Check for tissue-level issues
        if tissue_sim.get("tissue_penetration", "high") == "low":
            delivery_issues.append("tissue_penetration")
        
        if tissue_sim.get("adverse_effects", 0.0) > 0.3:
            delivery_issues.append("tissue_adverse_effects")
        
        # Check for systemic-level issues
        if systemic_sim.get("therapeutic_index", 10.0) < 3.0:
            systemic_issues.append("therapeutic_index")
        
        if len(systemic_sim.get("side_effects", [])) > 3:
            systemic_issues.append("side_effects")
        
        # Design refinement approach based on issues
        approach = substance.get("framework", {}).get("approach", "small_molecule")
        refinement_strategy = self._design_refinement_strategy(
            approach, molecular_issues, cellular_issues, delivery_issues, systemic_issues
        )
        
        # Apply refinement strategy
        modified_substance = self._apply_refinement_strategy(substance, refinement_strategy)
        
        # Generate a new substance ID for the refined version
        new_substance_id = f"{substance_id}-R{len(substance.get('refinements', [])) + 1}"
        
        # Update substance properties
        modified_substance["id"] = new_substance_id
        modified_substance["name"] = f"Refined {substance['name']}"
        modified_substance["parent_substance"] = substance_id
        modified_substance["refinement_id"] = refinement_id
        modified_substance["design_status"] = "refined"
        modified_substance["created_at"] = datetime.now().isoformat()
        
        # Store the new substance
        self.substance_database[new_substance_id] = modified_substance
        
        # Update original substance with refinement reference
        if "refinements" not in substance:
            self.substance_database[substance_id]["refinements"] = []
        
        self.substance_database[substance_id]["refinements"].append(new_substance_id)
        
        # Store refinement record
        refinement_record = {
            "id": refinement_id,
            "original_substance": substance_id,
            "refined_substance": new_substance_id,
            "issues_addressed": {
                "molecular": molecular_issues,
                "cellular": cellular_issues,
                "delivery": delivery_issues,
                "systemic": systemic_issues
            },
            "strategy": refinement_strategy,
            "timestamp": datetime.now().isoformat()
        }
        
        self.refinement_history[refinement_id] = refinement_record
        
        # Update problem registry to indicate refinement
        problem_id = substance.get("problem_id")
        if problem_id in self.health_problems_registry:
            self.health_problems_registry[problem_id]["intervention_candidates"].append(new_substance_id)
            self.health_problems_registry[problem_id]["status"] = "substance_refined"
        
        log_event(f"Completed refinement {refinement_id} for {substance_id}, created new substance {new_substance_id}", "INFO")
        
        return new_substance_id

    def _design_refinement_strategy(self, approach, molecular_issues, cellular_issues, delivery_issues, systemic_issues):
        """Design a refinement strategy based on identified issues and therapeutic approach."""
        strategy = {
            "approach": approach,
            "modifications": []
        }
        
        # Address molecular-level issues
        if "binding_efficacy" in molecular_issues:
            if approach == "small_molecule":
                strategy["modifications"].append({
                    "type": "molecular_modification",
                    "target": "binding_efficacy",
                    "action": random.choice([
                        "add_hydrogen_bond_donor", "add_hydrogen_bond_acceptor",
                        "increase_hydrophobic_interactions", "optimize_geometry",
                        "add_halogen_bonding", "increase_pi_stacking"
                    ]),
                    "expected_impact": "Improve target binding affinity"
                })
            elif approach == "peptide":
                strategy["modifications"].append({
                    "type": "molecular_modification",
                    "target": "binding_efficacy",
                    "action": random.choice([
                        "cyclization", "stapling", "non_natural_aa_substitution",
                        "terminal_modification", "secondary_structure_optimization"
                    ]),
                    "expected_impact": "Improve target binding and stability"
                })
            elif approach == "antibody":
                strategy["modifications"].append({
                    "type": "molecular_modification",
                    "target": "binding_efficacy",
                    "action": random.choice([
                        "CDR_optimization", "affinity_maturation",
                        "framework_modification", "epitope_refinement"
                    ]),
                    "expected_impact": "Increase antibody-target binding affinity"
                })
        
        if "off_target_binding" in molecular_issues:
            if approach == "small_molecule":
                strategy["modifications"].append({
                    "type": "molecular_modification",
                    "target": "selectivity",
                    "action": random.choice([
                        "increase_molecular_complexity", "stereoselective_design",
                        "rigidify_structure", "target_specific_pocket",
                        "remove_promiscuous_groups"
                    ]),
                    "expected_impact": "Reduce off-target binding"
                })
            elif approach in ["peptide", "antibody", "nucleic_acid"]:
                strategy["modifications"].append({
                    "type": "molecular_modification",
                    "target": "selectivity",
                    "action": random.choice([
                        "increase_target_specificity", "reduce_cross-reactivity",
                        "epitope_refinement", "sequence_optimization"
                    ]),
                    "expected_impact": "Enhance binding selectivity"
                })
        
        # Address cellular-level issues
        if "cellular_toxicity" in cellular_issues:
            strategy["modifications"].append({
                "type": "cellular_modification",
                "target": "toxicity_reduction",
                "action": random.choice([
                    "remove_toxic_functional_groups", "reduce_reactive_metabolites",
                    "target_specific_cell_types", "reduce_dose_requirements",
                    "alter_metabolic_pathway"
                ]),
                "expected_impact": "Decrease cellular toxicity"
            })
        
        if "pathway_modulation" in cellular_issues:
            strategy["modifications"].append({
                "type": "cellular_modification",
                "target": "pathway_effect",
                "action": random.choice([
                    "dual_pathway_targeting", "signaling_amplification",
                    "persistence_enhancement", "indirect_pathway_modulation",
                    "allosteric_enhancement"
                ]),
                "expected_impact": "Enhance pathway modulation"
            })
        
        # Address delivery issues
        if "tissue_penetration" in delivery_issues:
            strategy["modifications"].append({
                "type": "delivery_modification",
                "target": "tissue_penetration",
                "action": random.choice([
                    "lipophilicity_adjustment", "particle_size_reduction",
                    "advanced_delivery_system", "tissue_targeting_ligand",
                    "transporter_utilization"
                ]),
                "expected_impact": "Improve tissue penetration"
            })
        
        if "tissue_adverse_effects" in delivery_issues:
            strategy["modifications"].append({
                "type": "delivery_modification",
                "target": "tissue_specificity",
                "action": random.choice([
                    "targeted_delivery", "controlled_release",
                    "specific_transporter_targeting", "tissue-specific_activation",
                    "localized_administration"
                ]),
                "expected_impact": "Reduce off-target tissue effects"
            })
        
        # Address systemic issues
        if "therapeutic_index" in systemic_issues:
            strategy["modifications"].append({
                "type": "systemic_modification",
                "target": "therapeutic_index",
                "action": random.choice([
                    "dose_optimization", "schedule_optimization",
                    "combination_approach", "prodrug_conversion",
                    "toxic_metabolite_reduction"
                ]),
                "expected_impact": "Improve therapeutic index"
            })
        
        if "side_effects" in systemic_issues:
            strategy["modifications"].append({
                "type": "systemic_modification",
                "target": "side_effects",
                "action": random.choice([
                    "receptor_subtype_selectivity", "targeted_distribution",
                    "metabolism_optimization", "excretion_enhancement",
                    "ancillary_target_avoidance"
                ]),
                "expected_impact": "Reduce side effect profile"
            })
        
        # If no specific issues, add general optimization
        if not strategy["modifications"]:
            strategy["modifications"].append({
                "type": "optimization",
                "target": "overall_performance",
                "action": random.choice([
                    "pharmacokinetic_optimization", "multifactorial_enhancement",
                    "formulation_improvement", "dosing_regimen_optimization"
                ]),
                "expected_impact": "Optimize overall therapeutic profile"
            })
        
        return strategy

    def _apply_refinement_strategy(self, substance, refinement_strategy):
        """Apply the refinement strategy to create a modified substance."""
        # Create a deep copy of the substance
        modified_substance = copy.deepcopy(substance)
        
        # Get current framework and properties
        framework = modified_substance.get("framework", {})
        properties = modified_substance.get("expected_properties", {})
        
        # Apply each modification
        modifications = refinement_strategy.get("modifications", [])
        
        for modification in modifications:
            mod_type = modification.get("type")
            target = modification.get("target")
            action = modification.get("action")
            
            # Apply molecular modifications
            if mod_type == "molecular_modification":
                self._apply_molecular_modification(framework, properties, target, action)
            
            # Apply cellular modifications
            elif mod_type == "cellular_modification":
                self._apply_cellular_modification(framework, properties, target, action)
            
            # Apply delivery modifications
            elif mod_type == "delivery_modification":
                self._apply_delivery_modification(framework, properties, target, action)
            
            # Apply systemic modifications
            elif mod_type == "systemic_modification":
                self._apply_systemic_modification(framework, properties, target, action)
            
            # Apply general optimization
            elif mod_type == "optimization":
                self._apply_general_optimization(framework, properties, target, action)
        
        # Update mechanism of action to reflect refinements
        mechanism = modified_substance.get("mechanism_of_action", {})
        self._update_mechanism_after_refinement(mechanism, modifications)
        
        # Recalculate expected properties after all modifications
        updated_properties = self._recalculate_properties(framework, modified_substance.get("mechanism_of_action", {}))
        
        # Update substance with refined framework, mechanism, and properties
        modified_substance["framework"] = framework
        modified_substance["expected_properties"] = updated_properties
        modified_substance["refinement_strategy"] = refinement_strategy
        
        return modified_substance

    def _apply_molecular_modification(self, framework, properties, target, action):
        """Apply a molecular-level modification to the substance framework."""
        approach = framework.get("approach", "small_molecule")
        
        if approach == "small_molecule":
            # Small molecule modifications
            if target == "binding_efficacy":
                if action == "add_hydrogen_bond_donor":
                    framework["h_bond_donors"] = framework.get("h_bond_donors", 2) + 1
                    framework["functional_groups"].append("hydroxyl")
                
                elif action == "add_hydrogen_bond_acceptor":
                    framework["h_bond_acceptors"] = framework.get("h_bond_acceptors", 4) + 1
                    framework["functional_groups"].append("carbonyl")
                
                elif action == "increase_hydrophobic_interactions":
                    framework["logP"] = min(5.0, framework.get("logP", 2.0) + 0.5)
                    
                elif action == "optimize_geometry":
                    framework["rotatable_bonds"] = max(0, framework.get("rotatable_bonds", 5) - 1)
                    
                elif action == "add_halogen_bonding":
                    framework["functional_groups"].append("halogen")
                    
                elif action == "increase_pi_stacking":
                    framework["rings"] = framework.get("rings", 2) + 1
            
            elif target == "selectivity":
                if action == "increase_molecular_complexity":
                    framework["synthetic_complexity"] = min(0.9, framework.get("synthetic_complexity", 0.5) + 0.2)
                    framework["molecular_weight"] = min(900, framework.get("molecular_weight", 400) + 100)
                    
                elif action == "stereoselective_design":
                    # Add a note about stereoselectivity
                    framework["stereoselective"] = True
                    
                elif action == "rigidify_structure":
                    framework["rotatable_bonds"] = max(0, framework.get("rotatable_bonds", 5) - 2)
                    framework["rings"] = framework.get("rings", 2) + 1
                    
                elif action == "target_specific_pocket":
                    # Enhance binding features
                    binding_features = framework.get("binding_features", [])
                    if binding_features:
                        # Improve existing binding feature strengths
                        for feature in binding_features:
                            feature["strength"]



        # Verify problem exists
        if problem_id not in self.health_problems_registry:
            log_event(f"Problem {problem_id} not found in registry", "ERROR")
            return {"status": "failed", "stage": "problem_verification", "reason": "Problem not found"}
        
        problem = self.health_problems_registry[problem_id]
        log_event(f"Starting complete development cycle for problem: {problem['name']}", "INFO")
        
        # Step 2: Analyze mechanisms
        log_event(f"Analyzing mechanisms for {problem['name']}", "INFO")
        analysis_results = self.analyze_problem_mechanisms(problem_id)
        
        if not analysis_results:
            log_event(f"Mechanism analysis failed for {problem['name']}", "ERROR")
            return {"status": "failed", "stage": "mechanism_analysis", "reason": "Analysis failed"}
        
        # Step 3: Design initial therapeutic substance
        log_event(f"Designing therapeutic substance for {problem['name']}", "INFO")
        substance_id = self.design_therapeutic_substance(problem_id)
        
        if not substance_id or substance_id not in self.substance_database:
            log_event(f"Substance design failed for {problem['name']}", "ERROR")
            return {"status": "failed", "stage": "substance_design", "reason": "Design failed"}
        
        # Step 4: Simulate therapeutic effects
        log_event(f"Simulating effects of {substance_id}", "INFO")
        simulation_id = self.simulate_therapeutic_effects(substance_id)
        
        if not simulation_id or simulation_id not in self.simulation_results:
            log_event(f"Simulation failed for {substance_id}", "ERROR")
            return {"status": "failed", "stage": "simulation", "reason": "Simulation failed"}
        
        # Get simulation results
        simulation = self.simulation_results[simulation_id]
        
        # Step 5: Refine substance if needed based on simulation results
        efficacy_score = simulation.get("efficacy_score", 0)
        safety_score = simulation.get("safety_score", 0)
        
        refined_substance_id = substance_id
        
        # If efficacy or safety is suboptimal, refine the substance
        if efficacy_score < 0.7 or safety_score < 0.7:
            log_event(f"Refining substance {substance_id} (Efficacy: {efficacy_score}, Safety: {safety_score})", "INFO")
            refined_substance_id = self.refine_substance(substance_id)
            
            if not refined_substance_id or refined_substance_id not in self.substance_database:
                log_event(f"Refinement failed for {substance_id}", "WARNING")
                # Continue with original substance
                refined_substance_id = substance_id
        
        # Step 6: Evaluate final substance
        log_event(f"Evaluating substance {refined_substance_id}", "INFO")
        evaluation_id = self.evaluate_final_substance(refined_substance_id)
        
        if not evaluation_id or evaluation_id not in self.efficacy_ratings:
            log_event(f"Evaluation failed for {refined_substance_id}", "ERROR")
            return {"status": "failed", "stage": "evaluation", "reason": "Evaluation failed"}
        
        # Step 7: Generate final report
        log_event(f"Generating final report for {refined_substance_id}", "INFO")
        report = self.generate_final_report(refined_substance_id)
        
        if not report:
            log_event(f"Report generation failed for {refined_substance_id}", "ERROR")
            return {"status": "failed", "stage": "reporting", "reason": "Report generation failed"}
        
        # Get final evaluation
        evaluation = self.efficacy_ratings[evaluation_id]
        overall_score = evaluation.get("overall_assessment", {}).get("score", 0)
        
        log_event(f"Completed development cycle for {problem['name']} with overall score {overall_score}", "INFO")
        
        # Return complete development results
        return {
            "status": "success",
            "problem_id": problem_id,
            "problem_name": problem["name"],
            "initial_substance_id": substance_id,
            "final_substance_id": refined_substance_id,
            "simulation_id": simulation_id,
            "evaluation_id": evaluation_id,
            "overall_score": overall_score,
            "recommendation": evaluation.get("overall_assessment", {}).get("recommendation", "Unknown"),
            "report": report
        }
    
    def output_treatment_report(self, report):
        """
        Format and output the final therapeutic substance report in a structured format.
        
        Parameters:
        - report: The comprehensive report to format and output
        
        Returns:
        - Formatted report string
        """
        if not report:
            return "No report available to output."
        
        # Extract key information
        title = report.get("title", "Therapeutic Substance Report")
        substance_name = report.get("substance_name", "Unnamed Substance")
        problem_name = report.get("problem_name", "Unknown Condition")
        generation_date = report.get("generation_date", "Unknown")
        
        # Format date if it's in ISO format
        if "T" in generation_date:
            try:
                date_obj = datetime.fromisoformat(generation_date)
                generation_date = date_obj.strftime("%B %d, %Y")
            except:
                pass  # Keep original format if parsing fails
        
        # Extract executive summary
        exec_summary = report.get("executive_summary", {})
        description = exec_summary.get("substance_description", "No description available.")
        highlights = exec_summary.get("key_highlights", [])
        
        # Extract substance design information
        substance_design = report.get("substance_design", {})
        approach = substance_design.get("approach", "Unknown")
        target = substance_design.get("target", "Unknown")
        moa = substance_design.get("mechanism_of_action", {}).get("primary_mechanism", "Unknown")
        
        # Extract efficacy and safety profiles
        efficacy = report.get("efficacy_profile", {})
        safety = report.get("safety_profile", {})
        
        efficacy_score = efficacy.get("score", 0)
        safety_score = safety.get("score", 0)
        
        efficacy_strengths = efficacy.get("strengths", [])
        safety_risks = safety.get("key_risks", [])
        
        # Extract final assessment
        final = report.get("final_assessment", {})
        overall_score = final.get("overall_score", 0)
        recommendation = final.get("recommendation", "No recommendation available.")
        next_steps = final.get("next_steps", [])
        conclusions = final.get("conclusions", [])
        
        # Build the formatted report
        formatted_report = f       
        
        return formatted_report










# Configuration - UPDATED PATHS for Google Drive checkpointing
MODEL_PATH = "/content/gdrive/MyDrive/quantum_nexus/quantum_nexus_model_checkpoint.pth" # Checkpoint path
GOOGLE_DRIVE_MODEL_PATH = "/content/gdrive/MyDrive/quantum_nexus/quantum_nexus_model_checkpoint.pth" # Checkpoint path
LOCAL_MODEL_SAVE_PATH = "quantum_nexus_model.pth" # Local backup path
LOG_FILE = "quantum_nexus_log.txt"
FLASK_PORT = 5012
AGENT_STATE_FILE = "quantum_nexus_state.json" # No longer used - state is part of checkpoint
GOOGLE_DRIVE_STATE_FILE = "/content/gdrive/MyDrive/quantum_nexus/quantum_nexus_state.json" # Checkpoint path for agent state (also in checkpoint now)
SELF_MODIFY_INTERVAL = 20
ANNEAL_GAMMA = 0.995
MEMORY_MAX_SIZE = 1000
SAVE_INTERVAL = 5 # Save checkpoint more frequently for longer runs

# =============================================================================
# MAIN EXECUTION
# =============================================================================
adaptive_learning = None


def enhanced_main_loop():
    """
    Enhanced main execution loop for drug discovery applications with improved error handling,
    recovery mechanisms, and checkpointing reliability.
    
    This version includes integrated immune-gene regulatory network analysis for immunomodulatory
    drug discovery and development.
    """
    global adaptive_learning, agent_instance

    # Keep track of system state
    system_status = {
        "consecutive_errors": 0,
        "max_consecutive_errors": 5,
        "critical_error_count": 0,
        "last_successful_cycle": 0,
        "emergency_mode": False,
        "recovery_attempts": 0,
        "molecules_processed": 0,
        "promising_candidates": [],
        "immune_compounds_analyzed": 0,
        "top_immunomodulators": []
    }

    # Initialize components with comprehensive error handling
    try:
        # 1. Load or create model with architecture optimized for molecular analysis
        log_event("Initializing Quantum Nexus model for drug discovery with immune system modeling...", "INFO")
        model = load_or_create_drug_discovery_model()

        # 2. Create optimizer
        import torch.optim as optim
        optimizer = optim.Adam(model.parameters(), lr=getattr(model, '_current_lr', 5e-5))
        scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=ANNEAL_GAMMA)

        # 3. Initialize primary agent
        agent = DrugDiscoveryAgent(model=model)
        agent_instance = agent  # Store for dashboard access

        # 4. Create core subsystems specific to drug discovery
        # Initialize molecular reasoning system
        molecular_reasoning = MolecularReasoningSystem(agent=agent)
        agent.molecular_reasoning = molecular_reasoning

        # Initialize molecular database
        molecular_database = MolecularDatabase()
        agent.molecular_database = molecular_database

        # Initialize AI Manager, which creates other subsystems
        ai_manager = AIManager(agent, model)
        agent.ai_manager = ai_manager

        # Initialize specialized property prediction system
        property_predictor = DrugPropertyPredictor(model)
        agent.property_predictor = property_predictor

        # Initialize adaptive learning - ensure we use model's current_lr if available
        current_lr = getattr(model, '_current_lr', 5e-5)
        adaptive_learning = AdaptiveLearningSystem(model)
        # Ensure learning rate history is initialized with current value
        if not adaptive_learning.learning_rate_history:
            adaptive_learning.learning_rate_history.append(current_lr)
        agent.adaptive_learning = adaptive_learning

        # Initialize molecular sifter (replaces content sifter for drug discovery)
        molecular_sifter = MolecularSifter()
        agent.molecular_sifter = molecular_sifter

        # Initialize research planner (adapted from planner sifter)
        research_planner = DrugResearchPlanner()
        agent.research_planner = research_planner

        # 5. Initialize immune-gene regulatory network components
        log_event("Initializing immune-gene regulatory network modeling system...", "INFO")
        immune_network = ImmuneGeneRegulatoryNetwork(num_genes=15, num_cytokines=8, num_receptors=5, seed=42)
        agent.immune_network = immune_network
        
        # Initialize immunomodulating compound analyzer
        immune_analyzer = ImmunomodulatingCompoundAnalyzer(immune_network)
        agent.immune_analyzer = immune_analyzer
        
        # Link immune network to molecular reasoning
        if hasattr(molecular_reasoning, "link_immune_network"):
            molecular_reasoning.link_immune_network(immune_network)
            log_event("Linked immune network to molecular reasoning system", "INFO")

        # Link consciousness to molecular reasoning
        if hasattr(ai_manager, "consciousness") and hasattr(molecular_reasoning, "link_consciousness"):
            molecular_reasoning.link_consciousness(ai_manager.consciousness)

        # 6. Load molecular data sources
        log_event("Loading molecular databases and literature sources...", "INFO")
        data_sources = [
            "pubchem_compounds.sdf",
            "drugbank_approved.xml",
            "chembl_bioactivity.csv",
            "bindingdb_kinase_inhibitors.sdf",
            "literature_targets.json"
        ]
        
        # Add immune-specific data sources
        immune_data_sources = [
            "immunomodulatory_compounds.sdf",
            "cytokine_inhibitors.csv",
            "immune_receptor_ligands.json"
        ]
        
        # Combine data sources
        all_data_sources = data_sources + immune_data_sources
        
        for source in all_data_sources:
            try:
                molecular_database.load_data_source(source)
                log_event(f"Successfully loaded data source: {source}", "INFO")
            except Exception as e:
                log_event(f"Warning: Failed to load data source {source}: {str(e)}", "WARNING")

        # 7. System validation
        log_event("Performing system validation for drug discovery framework with immune modeling...", "INFO")
        validation_errors = []

        if model is None:
            validation_errors.append("Model initialization failed")
        if optimizer is None:
            validation_errors.append("Optimizer initialization failed")
        if agent is None:
            validation_errors.append("Agent initialization failed")
        if molecular_reasoning is None:
            validation_errors.append("MolecularReasoning initialization failed")
        if ai_manager is None:
            validation_errors.append("AIManager initialization failed")
        if molecular_database is None or molecular_database.compound_count() == 0:
            validation_errors.append("MolecularDatabase initialization or loading failed")
        if immune_network is None:
            validation_errors.append("ImmuneGeneRegulatoryNetwork initialization failed")

        if validation_errors:
            validation_error_msg = "; ".join(validation_errors)
            log_event(f"System validation errors: {validation_error_msg}", "ERROR")
            return False

        log_event(f"System validation complete. All components initialized. Loaded {molecular_database.compound_count()} compounds.", "INFO")

        # 8. Setup async loop
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        # 9. Initialize immune network with initial simulations
        log_event("Initializing immune network with baseline simulations...", "INFO")
        try:
            # Run baseline simulation to validate network
            immune_network.simulate(duration=10.0)
            # Run immune challenge simulation
            baseline_response = immune_network.simulate_immune_challenge(pathogen_load=1.0, duration=30.0)
            log_event(f"Baseline immune challenge simulation completed. Peak response at t={baseline_response['peak_response_time']:.2f}", "INFO")
            
            # Analyze feedback loops to validate network structure
            feedback_analysis = immune_network.analyze_feedback_loops()
            stability_status = "stable" if feedback_analysis['stability'] else "unstable"
            oscillatory_status = "oscillatory" if feedback_analysis['oscillatory'] else "non-oscillatory"
            log_event(f"Immune network feedback analysis: {stability_status}, {oscillatory_status}", "INFO")
        except Exception as e:
            log_event(f"Warning: Initial immune network simulations failed: {str(e)}", "WARNING")
            log_event("Continuing with limited immune modeling capabilities", "WARNING")

        # 10. Starting status
        cycle_count = 1
        log_event(f"ðŸš€ Starting Quantum Nexus Drug Discovery System with Immune-Gene Regulatory Network ðŸš€", "QUANTUM")

        # Main loop with enhanced error handling
        while True:
            try:
                cycle_count += 1
                log_event(f"===== Drug Discovery Cycle {cycle_count} =====", "INFO")

                # Run the agent cycle with timeout protection
                try:
                    # Set a reasonable timeout for cycle execution
                    cycle_future = asyncio.ensure_future(ai_manager.run_drug_discovery_cycle(optimizer))
                    loop_result = loop.run_until_complete(asyncio.wait_for(cycle_future, timeout=240))  # Longer timeout for molecular + immune computations
                except asyncio.TimeoutError:
                    log_event(f"Cycle execution timed out after 240 seconds", "ERROR")
                    loop_result = {"status": "error", "error": "Execution timeout"}
                    # Cancel the future if it's still running
                    if not cycle_future.done():
                        cycle_future.cancel()

                # Check for successful cycle and handle errors
                if isinstance(loop_result, dict) and loop_result.get("status") == "error":
                    system_status["consecutive_errors"] += 1
                    error_message = loop_result.get("error", "Unknown error")
                    log_event(f"Cycle produced an error: {error_message}", "ERROR")
                else:
                    # Success! Reset error counter and update last successful cycle
                    system_status["consecutive_errors"] = 0
                    system_status["last_successful_cycle"] = cycle_count
                    system_status["emergency_mode"] = False

                    # Track molecules processed
                    molecules_processed = loop_result.get("molecules_processed", 0)
                    if molecules_processed > 0:
                        system_status["molecules_processed"] += molecules_processed
                        log_event(f"Total molecules processed: {system_status['molecules_processed']}", "INFO")
                    
                    # Track promising candidates
                    candidates = loop_result.get("promising_candidates", [])
                    if candidates:
                        system_status["promising_candidates"].extend(candidates)
                        log_event(f"New promising candidates found: {len(candidates)}", "INFO")
                        
                        # Log details of top candidate
                        if candidates and isinstance(candidates[0], dict):
                            top_candidate = candidates[0]
                            log_event(f"Top candidate: ID={top_candidate.get('id', 'unknown')}, "
                                    f"Score={top_candidate.get('score', 0):.4f}, "
                                    f"Target={top_candidate.get('target', 'unknown')}", "INFO")
                    
                    # Track immune compounds analyzed
                    immune_compounds = loop_result.get("immune_compounds_analyzed", 0)
                    if immune_compounds > 0:
                        system_status["immune_compounds_analyzed"] += immune_compounds
                        log_event(f"Immune compounds analyzed this cycle: {immune_compounds}", "INFO")
                        log_event(f"Total immune compounds analyzed: {system_status['immune_compounds_analyzed']}", "INFO")
                    
                    # Track top immunomodulators
                    immunomodulators = loop_result.get("immunomodulators", [])
                    if immunomodulators:
                        # Add new compounds to the list
                        system_status["top_immunomodulators"].extend(immunomodulators)
                        
                        # Sort by effect score and keep top 10
                        system_status["top_immunomodulators"].sort(key=lambda x: x.get("effect_score", 0), reverse=True)
                        system_status["top_immunomodulators"] = system_status["top_immunomodulators"][:10]
                        
                        log_event(f"New immunomodulatory compounds found: {len(immunomodulators)}", "INFO")
                        
                        # Log details of top immunomodulator
                        if immunomodulators and isinstance(immunomodulators[0], dict):
                            top_im = immunomodulators[0]
                            log_event(f"Top immunomodulator: ID={top_im.get('compound_id', 'unknown')}, "
                                     f"Profile={top_im.get('immune_profile', 'unknown')}, "
                                     f"Score={top_im.get('effect_score', 0):.4f}", "INFO")

                    # Update research strategy effectiveness if research_planner exists
                    if hasattr(agent, 'research_planner') and hasattr(agent.action_log, '__len__') and len(agent.action_log) > 0:
                        strategy_name = loop_result.get("strategy", "exploration")
                        result_data = {
                            "molecules_analyzed": loop_result.get("molecules_processed", 0),
                            "candidates_found": len(candidates),
                            "immune_compounds_found": len(immunomodulators) if immunomodulators else 0,
                            "max_binding_affinity": max([c.get("score", 0) for c in candidates]) if candidates else 0,
                            "success": loop_result.get("success", False)
                        }
                        agent.research_planner.update_strategy_effectiveness(strategy_name, result_data)

                # Run periodic immune network analysis on promising candidates
                if cycle_count % 5 == 0 and hasattr(agent, "immune_analyzer") and hasattr(agent, "molecular_database"):
                    log_event("Running periodic immune network analysis on promising candidates...", "INFO")
                    try:
                        # Get a batch of unanalyzed compounds
                        candidates_to_analyze = []
                        for candidate in system_status["promising_candidates"]:
                            compound_id = candidate.get("id", "")
                            if compound_id and compound_id not in agent.immune_analyzer.analyzed_compounds:
                                candidates_to_analyze.append(candidate)
                                if len(candidates_to_analyze) >= 5:  # Limit batch size
                                    break
                        
                        # Analyze immune effects
                        immune_results = []
                        for candidate in candidates_to_analyze:
                            compound_id = candidate.get("id", "")
                            compound_data = agent.molecular_database.get_compound_data(compound_id)
                            if compound_data:
                                immune_result = agent.immune_analyzer.analyze_compound(compound_id, compound_data)
                                immune_results.append(immune_result)
                                log_event(f"Analyzed compound {compound_id} - immune profile: {immune_result['immune_profile']}", "INFO")
                        
                        # Update system status with new immune results
                        if immune_results:
                            # Update count
                            system_status["immune_compounds_analyzed"] += len(immune_results)
                            
                            # Add to top immunomodulators
                            system_status["top_immunomodulators"].extend(immune_results)
                            
                            # Sort by effect score and keep top 10
                            system_status["top_immunomodulators"].sort(key=lambda x: x.get("effect_score", 0), reverse=True)
                            system_status["top_immunomodulators"] = system_status["top_immunomodulators"][:10]
                            
                            log_event(f"Completed immune analysis of {len(immune_results)} compounds.", "INFO")
                    except Exception as e:
                        log_event(f"Error during immune analysis: {str(e)}", "WARNING")

                # Progressive error recovery based on consecutive error count
                if system_status["consecutive_errors"] >= system_status["max_consecutive_errors"]:
                    system_status["critical_error_count"] += 1
                    system_status["recovery_attempts"] += 1

                    recovery_message = f"Critical error threshold reached ({system_status['consecutive_errors']} consecutive errors). "

                    # Level 1 recovery: Reload model
                    if system_status["recovery_attempts"] == 1:
                        log_event(recovery_message + "Attempting Level 1 Recovery: Reloading model...", "WARNING")
                        try:
                            model = load_or_create_drug_discovery_model()
                            optimizer = optim.Adam(model.parameters(), lr=getattr(model, '_current_lr', 5e-5))
                            scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=ANNEAL_GAMMA)
                            agent.model = model
                            ai_manager.model = model
                            if hasattr(agent, 'property_predictor'):
                                agent.property_predictor.update_model(model)
                            log_event("Level 1 Recovery successful - model reloaded", "INFO")
                        except Exception as e:
                            log_event(f"Level 1 Recovery failed: {str(e)}", "ERROR")

                    # Level 2 recovery: Reset subsystems
                    elif system_status["recovery_attempts"] == 2:
                        log_event(recovery_message + "Attempting Level 2 Recovery: Resetting research subsystems...", "WARNING")
                        try:
                            # Reset consciousness module
                            if hasattr(ai_manager, "consciousness"):
                                ai_manager.consciousness.awareness_level = 0.5
                                ai_manager.consciousness.current_state = "balanced"

                            # Reset imagination engine
                            if hasattr(ai_manager, "imagination"):
                                ai_manager.imagination.creativity_level = 0.7
                                ai_manager.imagination.current_mode = "associative"

                            # Reset molecular reasoning
                            if hasattr(agent, "molecular_reasoning"):
                                agent.molecular_reasoning.exploration_weight = 0.6
                                agent.molecular_reasoning.exploitation_weight = 0.4
                                agent.molecular_reasoning.clear_temporary_cache()
                            
                            # Reset immune network
                            if hasattr(agent, "immune_network"):
                                # Run a baseline simulation to reset network state
                                agent.immune_network.simulate(duration=10.0)
                                log_event("Reset immune network to baseline state", "INFO")

                            log_event("Level 2 Recovery successful - research subsystems reset", "INFO")
                        except Exception as e:
                            log_event(f"Level 2 Recovery failed: {str(e)}", "ERROR")

                    # Level 3 recovery: Create new adaptive learning system
                    elif system_status["recovery_attempts"] == 3:
                        log_event(recovery_message + "Attempting Level 3 Recovery: Reinitializing adaptive learning...", "WARNING")
                        try:
                            adaptive_learning = AdaptiveLearningSystem(model)
                            agent.adaptive_learning = adaptive_learning
                            log_event("Level 3 Recovery successful - adaptive learning reinitialized", "INFO")
                        except Exception as e:
                            log_event(f"Level 3 Recovery failed: {str(e)}", "ERROR")

                    # Level 4 recovery: Emergency mode - simplified operation
                    elif system_status["recovery_attempts"] >= 4:
                        log_event(recovery_message + "Activating Emergency Mode: Reduced functionality...", "CRITICAL")
                        system_status["emergency_mode"] = True

                        # In emergency mode, switch to simpler molecular analysis methods
                        if hasattr(agent, 'property_predictor'):
                            agent.property_predictor.use_fallback_methods = True
                            log_event("Switched to simplified molecular property prediction methods", "WARNING")
                        
                        # Disable immune network simulations in emergency mode
                        if hasattr(agent, 'immune_analyzer'):
                            agent.immune_analyzer.disable_complex_simulations = True
                            log_event("Disabled complex immune network simulations in emergency mode", "WARNING")

                        # Reset recovery counter after maximum attempts to allow periodic retry
                        if system_status["recovery_attempts"] > 6:
                            system_status["recovery_attempts"] = 0
                            log_event("Recovery attempt counter reset to retry recovery sequence", "INFO")

                # Periodic model saving with enhanced reliability
                if cycle_count % SAVE_INTERVAL == 0:
                    save_success = save_drug_discovery_checkpoint(agent, model, cycle_count, system_status)

                    if not save_success and not system_status["emergency_mode"]:
                        log_event("Primary and backup checkpoint saves failed - will retry next interval", "WARNING")

                # Update learning rate
                scheduler.step()

                # Export periodic research reports
                if cycle_count % REPORT_INTERVAL == 0:
                    try:
                        export_research_report(agent, system_status, cycle_count)
                        log_event(f"Research report exported at cycle {cycle_count}", "INFO")
                        
                        # Generate specialized immune analysis report
                        export_immune_analysis_report(agent, system_status, cycle_count)
                        log_event(f"Immune analysis report exported at cycle {cycle_count}", "INFO")
                    except Exception as e:
                        log_event(f"Failed to export research reports: {str(e)}", "WARNING")

                # Sleep briefly for stability
                time.sleep(0.5)

            except KeyboardInterrupt:
                log_event("Keyboard interrupt detected. Exiting gracefully...", "INFO")
                # Final save attempt and research report
                save_drug_discovery_checkpoint(agent, model, cycle_count, system_status)
                export_research_report(agent, system_status, cycle_count, "final")
                export_immune_analysis_report(agent, system_status, cycle_count, "final")
                break

            except Exception as e:
                log_event(f"Unhandled exception in main loop: {str(e)}", "ERROR")
                log_event(traceback.format_exc(), "ERROR")

                system_status["consecutive_errors"] += 1

                # More aggressive handling for unhandled exceptions
                if system_status["consecutive_errors"] >= system_status["max_consecutive_errors"] * 2:
                    log_event("Critical unhandled exception threshold reached. Attempting final save before exit.", "CRITICAL")
                    save_drug_discovery_checkpoint(agent, model, cycle_count, system_status)
                    export_research_report(agent, system_status, cycle_count, "emergency")
                    export_immune_analysis_report(agent, system_status, cycle_count, "emergency")
                    break

                # Longer sleep after unhandled error
                time.sleep(5.0)

    except Exception as init_error:
        log_event(f"Fatal initialization error: {str(init_error)}", "CRITICAL")
        log_event(traceback.format_exc(), "CRITICAL")
        return False

    return True

def load_or_create_drug_discovery_model():
    """
    Loads DrugDiscoveryModel from checkpoint file if available, or creates a new one.
    Enhanced with better error handling and fallback mechanisms.

    Returns: model object optimized for molecular analysis
    """
    model_path = GOOGLE_DRIVE_MODEL_PATH if IN_COLAB else MODEL_PATH
    model = DrugDiscoveryModel()  # Create model instance
    start_cycle = 1  # Default start cycle for new model

    try:
        if os.path.exists(model_path):
            log_event(f"Loading checkpoint from: {model_path}", "INFO")
            try:
                # Try with weights_only=False first (full checkpoint)
                checkpoint = torch.load(model_path, map_location=device, weights_only=False)

                # Verify checkpoint is a dictionary with expected keys
                if not isinstance(checkpoint, dict) or 'model_state_dict' not in checkpoint:
                    raise ValueError("Checkpoint format invalid - missing model_state_dict")

                model.load_state_dict(checkpoint['model_state_dict'])  # Load model state

                # Get cycle count with validation
                if 'cycle_count' in checkpoint:
                    cycle_count = checkpoint.get('cycle_count', 1)
                    if isinstance(cycle_count, (int, float)) and cycle_count > 0:
                        start_cycle = int(cycle_count)
                    else:
                        log_event(f"Invalid cycle_count in checkpoint: {cycle_count}. Using default.", "WARNING")

                # Load agent stats if they exist and agent_instance is defined
                if 'agent_stats' in checkpoint and 'agent_instance' in globals() and agent_instance is not None:
                    stats = checkpoint.get('agent_stats')
                    if isinstance(stats, dict):
                        agent_instance.stats = defaultdict(int)
                        # Copy values to ensure defaultdict behavior
                        for k, v in stats.items():
                            agent_instance.stats[k] = v
                    else:
                        log_event("Invalid agent_stats in checkpoint. Using empty stats.", "WARNING")
                        agent_instance.stats = defaultdict(int)

                # Load molecular database if it exists
                if 'molecular_database' in checkpoint and 'agent_instance' in globals() and agent_instance is not None:
                    if hasattr(agent_instance, 'molecular_database'):
                        mol_db = checkpoint.get('molecular_database')
                        if isinstance(mol_db, dict):
                            agent_instance.molecular_database.restore_from_checkpoint(mol_db)
                            log_event(f"Restored molecular database with {agent_instance.molecular_database.compound_count()} compounds", "INFO")
                        else:
                            log_event("Invalid molecular_database in checkpoint.", "WARNING")

                # Load promising candidates if they exist
                if 'promising_candidates' in checkpoint:
                    candidates = checkpoint.get('promising_candidates', [])
                    if isinstance(candidates, list):
                        log_event(f"Loaded {len(candidates)} promising drug candidates from checkpoint", "INFO")
                        # Will be assigned to system_status later
                    else:
                        log_event("Invalid promising_candidates in checkpoint.", "WARNING")

                log_event(f"Drug discovery model checkpoint loaded successfully. Resuming from cycle {start_cycle}.", "INFO")

            except Exception as e:
                # Fallback to loading only model weights if full checkpoint fails
                log_event(f"Error loading full checkpoint: {e}. Trying weights-only load.", "WARNING")
                try:
                    checkpoint = torch.load(model_path, map_location=device, weights_only=True)
                    model.load_state_dict(checkpoint)
                    log_event("Successfully loaded model weights only.", "INFO")
                except Exception as e2:
                    log_event(f"Error loading model weights: {e2}. Creating new model.", "WARNING")
                    model = DrugDiscoveryModel()  # Recreate model on failure
        else:
            log_event("No checkpoint file found. Creating a new drug discovery model.", "INFO")
    except Exception as e:
        log_event(f"Error loading checkpoint from {model_path}: {e}. Creating a new model.", "WARNING")
        log_event(traceback.format_exc(), "DEBUG")  # Log detailed traceback
        model = DrugDiscoveryModel()  # Ensure new model is created on failure

    # Move model to appropriate device
    model.to(device)

    # Initialize _current_lr attribute if not present
    if not hasattr(model, '_current_lr'):
        setattr(model, '_current_lr', 5e-5)  # Use the default learning rate
        log_event("Initialized model._current_lr with default learning rate", "INFO")

    return model


def save_drug_discovery_checkpoint(agent, model, cycle_count, system_status):
    """
    Save comprehensive checkpoint of drug discovery system with better error handling and fallbacks.

    Parameters:
    - agent: DrugDiscoveryAgent instance to save state from
    - model: DrugDiscoveryModel instance to save weights from
    - cycle_count: Current cycle count
    - system_status: Current system status dictionary

    Returns:
    - Boolean indicating save success
    """
    save_path = GOOGLE_DRIVE_MODEL_PATH if IN_COLAB else LOCAL_MODEL_SAVE_PATH

    try:
        # Prepare checkpoint dictionary with proper type validation
        checkpoint = {
            'cycle_count': int(cycle_count),
            'model_state_dict': model.state_dict(),
            'timestamp': datetime.now().isoformat(),
            'system_type': 'drug_discovery'
        }

        # Add agent stats if available
        if hasattr(agent, 'stats'):
            if isinstance(agent.stats, dict):
                checkpoint['agent_stats'] = dict(agent.stats)  # Convert to regular dict if defaultdict
            else:
                log_event("Warning: agent.stats is not a dictionary. Skipping stats save.", "WARNING")

        # Add action log if available
        if hasattr(agent, 'action_log'):
            if isinstance(agent.action_log, (list, deque)):
                checkpoint['action_log'] = list(agent.action_log)  # Convert deque to list
            else:
                log_event("Warning: agent.action_log is not a list/deque. Skipping log save.", "WARNING")

        # Add molecular database metadata
        if hasattr(agent, 'molecular_database'):
            checkpoint['molecular_database'] = agent.molecular_database.export_checkpoint()
            log_event(f"Saved molecular database with {agent.molecular_database.compound_count()} compounds", "INFO")

        # Add promising candidates
        if 'promising_candidates' in system_status and isinstance(system_status['promising_candidates'], list):
            checkpoint['promising_candidates'] = system_status['promising_candidates']
            log_event(f"Saved {len(system_status['promising_candidates'])} promising drug candidates", "INFO")

        # Add research progress metrics
        if hasattr(agent, 'research_planner'):
            checkpoint['research_progress'] = agent.research_planner.get_research_progress()

        # Save the checkpoint
        torch.save(checkpoint, save_path)
        log_event(f"Drug discovery checkpoint saved to {save_path} (Cycle: {cycle_count})", "INFO")

        return True

    except Exception as save_error:
        log_event(f"Primary checkpoint save error: {save_error}", "ERROR")

        # Try an alternate save approach with just the model state
        try:
            alt_path = "backup_drug_discovery_" + LOCAL_MODEL_SAVE_PATH
            torch.save(model.state_dict(), alt_path)
            log_event(f"Model state saved to alternate location: {alt_path}", "INFO")
            
            # Also save promising candidates separately
            if 'promising_candidates' in system_status and isinstance(system_status['promising_candidates'], list):
                import json
                candidates_path = "promising_candidates_backup.json"
                with open(candidates_path, 'w') as f:
                    json.dump(system_status['promising_candidates'], f)
                log_event(f"Promising candidates saved to alternate location: {candidates_path}", "INFO")
                
            return True
        except Exception as alt_save_error:
            log_event(f"All save attempts failed! Last error: {alt_save_error}", "ERROR")
            return False


def export_research_report(agent, system_status, cycle_count, report_type="periodic"):
    """
    Export a comprehensive research report on the current drug discovery progress.
    
    Parameters:
    - agent: DrugDiscoveryAgent instance
    - system_status: Current system status dictionary
    - cycle_count: Current cycle count
    - report_type: Type of report ("periodic", "final", or "emergency")
    
    Returns:
    - Path to the exported report
    """
    import json
    from datetime import datetime
    
    # Create report filename with timestamp
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_path = f"drug_discovery_report_{report_type}_{timestamp}.json"
    
    # Collect report data
    report = {
        "report_type": report_type,
        "timestamp": datetime.now().isoformat(),
        "cycle_count": cycle_count,
        "molecules_processed": system_status.get("molecules_processed", 0),
        "promising_candidates_count": len(system_status.get("promising_candidates", [])),
        "system_status": {
            "consecutive_errors": system_status.get("consecutive_errors", 0),
            "critical_error_count": system_status.get("critical_error_count", 0),
            "emergency_mode": system_status.get("emergency_mode", False)
        }
    }
    
    # Add detailed research progress if available
    if hasattr(agent, 'research_planner') and hasattr(agent.research_planner, 'get_research_progress'):
        report["research_progress"] = agent.research_planner.get_research_progress()
    
    # Add molecular statistics if available
    if hasattr(agent, 'molecular_database') and hasattr(agent.molecular_database, 'get_statistics'):
        report["molecular_statistics"] = agent.molecular_database.get_statistics()
    
    # Add top promising candidates (limited to 10 for report size)
    candidates = system_status.get("promising_candidates", [])
    if candidates:
        # Sort by score in descending order
        sorted_candidates = sorted(candidates, key=lambda x: x.get("score", 0), reverse=True)
        report["top_candidates"] = sorted_candidates[:10]  # Include only top 10 for report
    
    # Write report to file
    try:
        with open(report_path, 'w') as f:
            json.dump(report, f, indent=2)
        
        # If this is final or emergency report, also create CSV version of candidates
        if report_type in ["final", "emergency"] and candidates:
            csv_path = f"drug_candidates_{report_type}_{timestamp}.csv"
            
            # Create CSV header and rows
            import csv
            with open(csv_path, 'w', newline='') as csvfile:
                fieldnames = ["id", "smiles", "target", "score", "predicted_properties", "synthesis_complexity"]
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                
                for candidate in sorted_candidates:
                    # Extract only the required fields for CSV
                    row = {
                        "id": candidate.get("id", "unknown"),
                        "smiles": candidate.get("smiles", ""),
                        "target": candidate.get("target", "unknown"),
                        "score": candidate.get("score", 0),
                        "predicted_properties": str(candidate.get("properties", {})),
                        "synthesis_complexity": candidate.get("synthesis_complexity", "unknown")
                    }
                    writer.writerow(row)
            
            log_event(f"Exported {len(sorted_candidates)} candidates to CSV: {csv_path}", "INFO")
        
        return report_path
    
    except Exception as e:
        log_event(f"Error exporting research report: {str(e)}", "ERROR")
        return None


class DrugDiscoveryModel(QuantumNexusModel):
    """
    Advanced model architecture specialized for drug discovery applications.
    Extends the QuantumNexusModel with molecular representation capabilities.
    """
    def __init__(self, vocab_size=30522, embed_dim=512, num_layers=8, num_quantum_states=4):
        super().__init__(vocab_size, embed_dim, num_layers, num_quantum_states)
        
        # Additional molecular representation layers
        self.molecular_embed_dim = 256
        
        # Molecule fingerprint embedding (for SMILES or molecular fingerprints)
        self.molecule_embedding = nn.Linear(1024, self.molecular_embed_dim)  # Standard size for Morgan fingerprints
        
        # Molecular graph representation (for graph-based molecular representations)
        self.graph_conv_layers = nn.ModuleList([
            nn.Linear(self.molecular_embed_dim, self.molecular_embed_dim),
            nn.Linear(self.molecular_embed_dim, self.molecular_embed_dim)
        ])
        
        # Property prediction heads
        self.property_heads = nn.ModuleDict({
            'binding_affinity': nn.Linear(self.embed_dim, 1),
            'solubility': nn.Linear(self.embed_dim, 1),
            'toxicity': nn.Linear(self.embed_dim, 5),  # 5 toxicity classes
            'bioavailability': nn.Linear(self.embed_dim, 1),
            'synthesizability': nn.Linear(self.embed_dim, 1)
        })
        
        # Molecule generation head (for de novo design)
        self.molecule_generator = nn.Sequential(
            nn.Linear(self.embed_dim, 512),
            nn.ReLU(),
            nn.Linear(512, 1024),
            nn.ReLU(),
            nn.Linear(1024, vocab_size)
        )
        
        # Initialize specialized weights
        self._init_molecular_weights()
    
    def _init_molecular_weights(self):
        """Initialize weights for molecular components"""
        for name, p in self.named_parameters():
            if 'molecule_' in name or 'graph_conv' in name or 'property_heads' in name:
                if 'weight' in name:
                    nn.init.xavier_normal_(p)
                elif 'bias' in name:
                    nn.init.zeros_(p)
    
    def process_molecule(self, mol_fingerprint, mol_graph=None):
        """
        Process molecular input through specialized layers
        
        Parameters:
        - mol_fingerprint: Molecular fingerprint tensor (B, 1024)
        - mol_graph: Optional graph representation of molecule
        
        Returns:
        - Molecular embedding tensor
        """
        # Embed molecular fingerprint
        mol_embedding = self.molecule_embedding(mol_fingerprint)
        mol_embedding = F.relu(mol_embedding)
        
        # Process graph structure if provided
        if mol_graph is not None:
            graph_embedding = mol_embedding
            
            for layer in self.graph_conv_layers:
                # Simple graph convolution for demonstration
                # In a real implementation, this would use proper graph convolutions
                graph_embedding = layer(graph_embedding)
                graph_embedding = F.relu(graph_embedding)
            
            # Combine fingerprint and graph embeddings
            mol_embedding = mol_embedding + graph_embedding
        
        return mol_embedding
    
    def predict_properties(self, embedding):
        """
        Predict multiple molecular properties from embedding
        
        Parameters:
        - embedding: Molecular embedding tensor
        
        Returns:
        - Dictionary of predicted properties
        """
        properties = {}
        
        for prop_name, head in self.property_heads.items():
            if prop_name == 'toxicity':
                # Multi-class prediction for toxicity
                properties[prop_name] = F.softmax(head(embedding), dim=1)
            else:
                # Regression for other properties
                properties[prop_name] = torch.sigmoid(head(embedding))
        
        return properties
    
    def generate_molecule(self, embedding, temperature=1.0):
        """
        Generate molecule representation from embedding
        
        Parameters:
        - embedding: Conditioning embedding tensor
        - temperature: Sampling temperature (higher = more diverse)
        
        Returns:
        - Generated token probabilities
        """
        logits = self.molecule_generator(embedding) / temperature
        return F.softmax(logits, dim=1)


class MolecularReasoningSystem:
    """
    Advanced system for molecular reasoning, analogous to the SuperQuantumFreeWill
    but specialized for drug discovery applications.
    """
    def __init__(self, agent):
        self.agent = agent
        self.molecular_knowledge = {}
        self.pharmacophore_templates = {}
        self.target_binding_models = {}
        self.scaffold_memory = set()
        self.consciousness_link = None
        
        # Decision dynamics
        self.exploration_weight = 0.6
        self.exploitation_weight = 0.4
        self.scaffold_diversity_weight = 0.3
        self.target_relevance_weight = 0.5
        self.quantum_influence_weight = 0.4
        
        # Research priorities
        self.research_priorities = {
            "novelty": 0.8,
            "binding_affinity": 0.9,
            "synthesizability": 0.7,
            "drug_likeness": 0.8,
            "safety_profile": 0.9
        }
        
        # Memory weighting
        self.molecule_importance = {}
        
        # Track research domains
        self.research_domains = {
            "kinase_inhibitors": 0.8,
            "gpcr_modulators": 0.7,
            "ion_channel_blockers": 0.6,
            "enzyme_inhibitors": 0.9,
            "protein-protein_interaction_disruptors": 0.5
        }
        
        # Fallback molecules for when memory is empty
        self.fallback_molecules = [
            "CC1=C(C=C(C=C1)NC(=O)C2=CC=C(C=C2)CN3CCN(CC3)C)NC4=NC=CC(=N4)C5=CN=CC=C5",  # Imatinib
            "CCC1=NC(=C(S1)C2=CC=CC=C2)C3=CC(=CN=C3)C(=O)N",  # Dasatinib
            "CN1CCN(CC1)CCCNC2=NC=NC3=C2C=C(C=C3)Cl",  # Cetirizine
            "COC1=C(C=C2C(=C1)C(=NC=N2)NC3=CC(=C(C=C3)F)Cl)OCCCN4CCOCC4",  # Gefitinib
            "CN1C=NC2=C1C(=O)N(C(=O)N2C)C"  # Caffeine
        ]
        
        log_event("MolecularReasoningSystem initialized", "QUANTUM")
    
    def link_consciousness(self, consciousness_module):
        """Connect to consciousness module for reflective capabilities"""
        self.consciousness_link = consciousness_module
        log_event("MolecularReasoning linked with ConsciousnessModule", "INFO")
    
    def _get_active_research_focus(self):
        """Safely retrieve the active research focus"""
        try:
            if hasattr(self.agent, 'ai_manager') and hasattr(self.agent.ai_manager, 'temporal_planner'):
                planner = self.agent.ai_manager.temporal_planner
                if hasattr(planner, 'select_active_goal'):
                    goal = planner.select_active_goal()
                    if goal and isinstance(goal, dict):
                        return goal.get("description", "")
            return ""
        except Exception as e:
            log_event(f"Error retrieving research focus: {e}", "ERROR")
            return ""
    
    def select_molecule(self):
        """
        Select the next molecule to analyze using quantum-inspired
        decision making with multiple factors.
        """
        log_event("Selecting molecule with quantum-inspired strategy", "QUANTUM")
        
        # Get candidate molecules from memory or use fallbacks
        candidate_molecules = list(self.scaffold_memory)
        if not candidate_molecules:
            log_event("Scaffold memory is empty. Using fallback molecules.", "WARNING")
            candidate_molecules = self.fallback_molecules
            
        # Get consciousness level if available
        awareness_level = 0.5
        if self.consciousness_link:
            awareness_level = self.consciousness_link.awareness_level
            
        # Get current research focus
        current_research_focus = self._get_active_research_focus()
        
        # Calculate scores with quantum influence
        molecule_scores = {}
        
        for molecule in candidate_molecules:
            # Parse molecule representation
            molecule_id = molecule
            
            # Base score with quantum randomness
            # Higher consciousness reduces quantum randomness
            quantum_factor = self.quantum_influence_weight * (1 - awareness_level)
            
            # Quantum superposition of initial states
            quantum_states = []
            for _ in range(3):  # Generate 3 possible quantum states
                phase = random.uniform(0, 2 * math.pi)
                amplitude = random.uniform(0.3, 1.0)
                state_score = amplitude * math.cos(phase)
                quantum_states.append(state_score)
                
            # Collapse quantum states weighted by consciousness
            quantum_score = sum(quantum_states) / len(quantum_states)
            score = quantum_score * quantum_factor
            
            # Add scaffold diversity factor
            scaffold_score = self._calculate_scaffold_diversity(molecule)
            score += self.scaffold_diversity_weight * scaffold_score
            
            # Check target relevance
            if current_research_focus:
                target_relevance = self._calculate_target_relevance(molecule, current_research_focus)
                score += self.target_relevance_weight * target_relevance
                
            # Add molecule importance if this molecule is known
            if molecule in self.molecule_importance:
                score += self.molecule_importance[molecule] * 0.4
                
            # Store score
            molecule_scores[molecule] = score
            
        # Occasionally make quantum leap decision
        if random.random() < self.quantum_influence_weight * 0.3:
            # Complete quantum randomness - ignore calculated scores
            quantum_choice = random.choice(candidate_molecules)
            log_event(f"Made quantum leap molecule choice: {quantum_choice[:10]}...", "QUANTUM")
            self.agent.stats["last_molecule"] = quantum_choice
            return quantum_choice
            
        # Normal selection based on scores
        if molecule_scores:
            try:
                best_molecule = max(molecule_scores.items(), key=lambda x: x[1])[0]
                log_event(f"Selected molecule with score: {molecule_scores[best_molecule]:.2f}", "INFO")
                self.agent.stats["last_molecule"] = best_molecule
                return best_molecule
            except Exception as e:
                log_event(f"Error selecting best molecule: {e}", "ERROR")
                fallback = random.choice(candidate_molecules)
                log_event(f"Using fallback molecule selection", "WARNING")
                self.agent.stats["last_molecule"] = fallback
                return fallback
        else:
            # No scores calculated - use random selection
            fallback = random.choice(candidate_molecules)
            log_event(f"No molecule scores available. Using random selection", "WARNING")
            self.agent.stats["last_molecule"] = fallback
            return fallback
    
    def _calculate_scaffold_diversity(self, molecule):
        """Calculate how diverse this scaffold is compared to previously studied ones"""
        # This would normally compute Murcko scaffolds and compare to memory
        # For this demonstration, we'll use a simplified approach
        return random.uniform(0.3, 0.9)  # Simulated diversity score
    
    def _calculate_target_relevance(self, molecule, research_focus):
        """Calculate relevance of molecule to current research focus"""
        # This would normally do a targeted analysis of molecule's features
        # For this demonstration, we'll use a simplified approach
        
        # Check for keywords in research focus
        relevance = 0.5  # Base relevance
        
        focus_lower = research_focus.lower()
        if "kinase" in focus_lower and molecule in self.research_domains.get("kinase_inhibitors", set()):
            relevance += 0.3
        elif "gpcr" in focus_lower and molecule in self.research_domains.get("gpcr_modulators", set()):
            relevance += 0.3
        elif "ion channel" in focus_lower and molecule in self.research_domains.get("ion_channel_blockers", set()):
            relevance += 0.3
        elif "enzyme" in focus_lower and molecule in self.research_domains.get("enzyme_inhibitors", set()):
            relevance += 0.3
        
        return min(1.0, relevance)
    
    def discover_analogs(self, molecule, base_molecule):
        """Discover and generate analogs of a given molecule"""
        # This would normally use chemical transformation rules to generate analogs
        # For demonstration, we'll simulate generating analogs
        
        analogs = []
        for i in range(random.randint(3, 8)):
            # Simulate analog generation with minor variation of SMILES
            # In reality, this would use proper cheminformatics tools
            analog = f"{base_molecule[:10]}{random.randint(0, 9)}{base_molecule[11:]}"
            analogs.append(analog)
            
        # Add to memory
        self.expand_memory(analogs)
        
        log_event(f"Generated {len(analogs)} novel analogs", "INFO")
        return len(analogs)
    
    def expand_memory(self, molecules):
        """Add new molecules to memory"""
        if not molecules:
            return 0
            
        count_before = len(self.scaffold_memory)
        for mol in molecules:
            self.scaffold_memory.add(mol)
            
        count_added = len(self.scaffold_memory) - count_before
        if count_added > 0:
            log_event(f"Added {count_added} new molecules to scaffold memory", "INFO")
            
        return count_added
    
    def store_molecular_properties(self, molecule_id, properties):
        """Store molecular properties for future reference"""
        if not molecule_id or not properties:
            return False
            
        self.molecular_knowledge[molecule_id] = properties
        
        # Calculate importance based on properties
        importance = 0.5  # Base importance
        
        if "binding_affinity" in properties:
            # Higher binding affinity (lower score) increases importance
            affinity = properties["binding_affinity"]
            if isinstance(affinity, (int, float)) and affinity < 10:  # Good binding (nM range)
                importance += (10 - affinity) / 20  # Max +0.5 for very strong binding
                
        if "drug_likeness" in properties:
            # Better drug-likeness increases importance
            drug_likeness = properties["drug_likeness"]
            if isinstance(drug_likeness, (int, float)):
                importance += drug_likeness / 10  # Max +0.1 for perfect drug-likeness
                
        # Store the calculated importance
        self.molecule_importance[molecule_id] = min(0.95, importance)
        
        return True
    
    def clear_temporary_cache(self):
        """Clear temporary caches to free memory during recovery"""
        temp_cache_count = len(self.molecular_knowledge)
        self.molecular_knowledge = {}
        log_event(f"Cleared temporary molecular cache ({temp_cache_count} entries)", "INFO")
    
    def decide(self):
        """
        Make a decision about what molecular research action to take next
        using quantum-inspired decision making.
        """
        try:
            log_event("Making quantum-enhanced molecular research decision...", "QUANTUM")
            
            # Possible actions
            possible_actions = [
                "screen_molecule", 
                "generate_analogs", 
                "optimize_properties", 
                "analyze_binding", 
                "evaluate_safety", 
                "quantum_exploration"
            ]
            
            # Initialize quantum state - each action has amplitude and phase
            quantum_state = {}
            for action in possible_actions:
                phase = random.uniform(0, 2 * math.pi)
                amplitude = random.uniform(0.3, 1.0)
                quantum_state[action] = {"amplitude": amplitude, "phase": phase}
                
            # Get current context
            current_research_focus = self._get_active_research_focus()
            
            # Get consciousness awareness level
            awareness_level = 0.5
            if self.consciousness_link:
                awareness_level = self.consciousness_link.awareness_level
                
            # Get thinking mode if available
            thinking_mode = "balanced"
            if hasattr(self.agent, "ai_manager") and hasattr(self.agent.ai_manager, "autonomous_mind"):
                thinking_mode = getattr(self.agent.ai_manager.autonomous_mind, "current_mode", "balanced")
                
            # Apply quantum interference based on context
            
            # 1. Research focus interference
            if current_research_focus:
                if "screen" in current_research_focus.lower():
                    # Amplify screening actions
                    quantum_state["screen_molecule"]["amplitude"] *= 1.3
                elif "optimize" in current_research_focus.lower():
                    # Amplify optimization actions
                    quantum_state["optimize_properties"]["amplitude"] *= 1.4
                elif "safety" in current_research_focus.lower():
                    # Amplify safety evaluation
                    quantum_state["evaluate_safety"]["amplitude"] *= 1.5
                elif "binding" in current_research_focus.lower():
                    # Amplify binding analysis
                    quantum_state["analyze_binding"]["amplitude"] *= 1.4
                    
            # 2. Thinking mode interference
            if thinking_mode == "analytical":
                quantum_state["analyze_binding"]["amplitude"] *= 1.3
                quantum_state["evaluate_safety"]["amplitude"] *= 1.2
            elif thinking_mode == "creative":
                quantum_state["quantum_exploration"]["amplitude"] *= 1.5
                quantum_state["generate_analogs"]["amplitude"] *= 1.3
            elif thinking_mode == "critical":
                quantum_state["evaluate_safety"]["amplitude"] *= 1.3
                quantum_state["optimize_properties"]["amplitude"] *= 1.2
                
            # 3. Recent actions interference
            recent_actions = []
            if hasattr(self.agent, 'action_log') and self.agent.action_log:
                if len(self.agent.action_log) >= 3:
                    recent_actions = [a.get("action", "") for a in list(self.agent.action_log)[-3:]]
                    
            if recent_actions:
                # Avoid repeating the same action too many times
                most_common = max(set(recent_actions), key=recent_actions.count) if recent_actions else None
                if most_common is not None:
                    if most_common in quantum_state:
                        quantum_state[most_common]["amplitude"] *= 0.7
                        
            # Apply consciousness as quantum observer effect
            # Higher consciousness makes decision more deterministic
            for action in possible_actions:
                random_factor = random.uniform(0.8, 1.2) * (1 - awareness_level)
                quantum_state[action]["amplitude"] *= (1 + random_factor * 0.2)
                
            # Calculate probabilities (square of amplitudes)
            total_probability = sum(state["amplitude"]**2 for state in quantum_state.values())
            probabilities = {action: (state["amplitude"]**2) / total_probability
                           for action, state in quantum_state.items()}
                           
            # Collapse the quantum state by observation
            action_type = random.choices(
                list(probabilities.keys()),
                weights=list(probabilities.values()),
                k=1
            )[0]
            
            # Create decision package
            decision = {
                "action": action_type,
                "quantum_confidence": probabilities[action_type],
                "reasoning": f"Quantum decision process ({thinking_mode} mode) - focus: {current_research_focus[:30]}",
                "timestamp": datetime.now().isoformat()
            }
            
            log_event(f"Molecular research decision: {action_type} with {probabilities[action_type]:.2f} quantum confidence", "QUANTUM")
            
            # Special handling for quantum_exploration action
            if action_type == "quantum_exploration":
                # Map to a standard action but with more randomness
                standard_actions = ["screen_molecule", "generate_analogs", "optimize_properties", "analyze_binding", "evaluate_safety"]
                decision["action"] = random.choice(standard_actions)
                decision["quantum_leap"] = True
                log_event(f"Quantum leap mapped to {decision['action']}", "QUANTUM")
                
            return decision
            
        except Exception as e:
            log_event(f"Decision error: {e}", "ERROR")
            # Fallback to simple random choice
            fallback_action = random.choice(["screen_molecule", "generate_analogs", "optimize_properties"])
            return {"action": fallback_action, "error": str(e)[:200]}


class ImmuneGeneRegulatoryNetwork:
    """
    A model of recursive coupling between immune signaling and gene regulation.
    
    This class implements a system where immune signals trigger changes in gene
    expression, which in turn modulate the immune response, creating a recursive
    feedback loop critical for homeostasis and response to pathogens.
    """
    
    def __init__(self, num_genes=10, num_cytokines=5, num_receptors=3, seed=42):
        """
        Initialize the immune-gene regulatory network.
        
        Parameters:
        -----------
        num_genes : int
            Number of genes in the regulatory network
        num_cytokines : int
            Number of immune signaling cytokines
        num_receptors : int
            Number of cell surface receptors
        seed : int
            Random seed for reproducibility
        """
        np.random.seed(seed)
        
        # Network dimensions
        self.num_genes = num_genes
        self.num_cytokines = num_cytokines
        self.num_receptors = num_receptors
        
        # Initialize network weights
        # How genes affect other genes
        self.gene_gene_weights = np.random.normal(0, 0.5, (num_genes, num_genes))
        # Set self-regulation to be slightly negative (homeostasis)
        np.fill_diagonal(self.gene_gene_weights, -0.2 - np.random.rand(num_genes) * 0.3)
        
        # How cytokines affect gene expression
        self.cytokine_gene_weights = np.random.normal(0, 0.7, (num_cytokines, num_genes))
        
        # How genes regulate cytokine production
        self.gene_cytokine_weights = np.random.normal(0, 0.6, (num_genes, num_cytokines))
        
        # How receptors respond to cytokines
        self.cytokine_receptor_weights = np.random.normal(0, 0.8, (num_cytokines, num_receptors))
        
        # How receptor activation affects gene expression
        self.receptor_gene_weights = np.random.normal(0, 0.7, (num_receptors, num_genes))
        
        # State variables
        self.gene_expression = np.zeros(num_genes)
        self.cytokine_levels = np.zeros(num_cytokines)
        self.receptor_activation = np.zeros(num_receptors)
        
        # Temporal dynamics parameters
        self.gene_timescale = 1.0  # Slow changes in gene expression
        self.cytokine_timescale = 0.5  # Faster cytokine dynamics
        self.receptor_timescale = 0.2  # Rapid receptor activation/deactivation
        
        # Thresholds and saturation
        self.gene_threshold = 0.2
        self.cytokine_threshold = 0.1
        self.receptor_threshold = 0.15
        
        # History tracking
        self.history = {
            'time': [],
            'genes': [],
            'cytokines': [],
            'receptors': []
        }
    
    def sigmoid(self, x, threshold=0, steepness=1):
        """Sigmoid activation function with threshold"""
        return 1 / (1 + np.exp(-steepness * (x - threshold)))
    
    def gene_regulation_dynamics(self, gene_expr, cytokine_levels, receptor_activation):
        """Calculate gene expression changes based on current state"""
        # Gene-gene interactions
        gene_gene_effect = np.dot(self.gene_gene_weights, gene_expr)
        
        # Direct cytokine effects on genes
        cytokine_gene_effect = np.dot(self.cytokine_gene_weights.T, cytokine_levels)
        
        # Receptor-mediated effects on genes
        receptor_gene_effect = np.dot(self.receptor_gene_weights.T, receptor_activation)
        
        # Combine all effects
        total_effect = gene_gene_effect + cytokine_gene_effect + receptor_gene_effect
        
        # Apply sigmoid activation with threshold
        gene_regulation = self.sigmoid(total_effect, threshold=self.gene_threshold) - gene_expr
        
        return gene_regulation / self.gene_timescale
    
    def cytokine_dynamics(self, gene_expr, cytokine_levels):
        """Calculate cytokine level changes based on gene expression"""
        # Gene regulation of cytokine production
        gene_cytokine_effect = np.dot(self.gene_cytokine_weights.T, gene_expr)
        
        # Apply activation function
        cytokine_production = self.sigmoid(gene_cytokine_effect, threshold=self.cytokine_threshold)
        
        # Cytokine degradation (proportional to current levels)
        cytokine_degradation = 0.3 * cytokine_levels
        
        return (cytokine_production - cytokine_degradation) / self.cytokine_timescale
    
    def receptor_dynamics(self, cytokine_levels, receptor_activation):
        """Calculate receptor activation changes based on cytokine levels"""
        # Cytokine binding to receptors
        cytokine_receptor_effect = np.dot(self.cytokine_receptor_weights.T, cytokine_levels)
        
        # Apply activation function
        receptor_activation_new = self.sigmoid(cytokine_receptor_effect, threshold=self.receptor_threshold)
        
        # Receptor deactivation rate
        receptor_deactivation = 0.4 * receptor_activation
        
        return (receptor_activation_new - receptor_deactivation) / self.receptor_timescale
    
    def system_dynamics(self, t, state):
        """Define the complete system dynamics for integration"""
        # Unpack state vector
        gene_expr = state[:self.num_genes]
        cytokine_levels = state[self.num_genes:self.num_genes+self.num_cytokines]
        receptor_activation = state[self.num_genes+self.num_cytokines:]
        
        # Calculate dynamics for each component
        gene_rates = self.gene_regulation_dynamics(gene_expr, cytokine_levels, receptor_activation)
        cytokine_rates = self.cytokine_dynamics(gene_expr, cytokine_levels)
        receptor_rates = self.receptor_dynamics(cytokine_levels, receptor_activation)
        
        # Return concatenated derivatives
        return np.concatenate([gene_rates, cytokine_rates, receptor_rates])
    
    def simulate(self, duration=20.0, dt=0.1, perturbation=None):
        """
        Simulate the system dynamics over time with optional perturbation
        
        Parameters:
        -----------
        duration : float
            Total simulation time
        dt : float
            Time step for saving results
        perturbation : dict, optional
            Perturbation configuration with keys:
            - 'type': 'gene', 'cytokine', or 'receptor'
            - 'index': index of the component to perturb
            - 'time': when to apply the perturbation
            - 'magnitude': perturbation strength
            - 'duration': how long the perturbation lasts
        """
        # Initial conditions
        initial_state = np.concatenate([
            self.gene_expression,
            self.cytokine_levels,
            self.receptor_activation
        ])
        
        # Time points for saving results
        t_eval = np.arange(0, duration, dt)
        
        # Solve without perturbation if none specified
        if perturbation is None:
            solution = solve_ivp(
                self.system_dynamics,
                [0, duration],
                initial_state,
                t_eval=t_eval,
                method='RK45'
            )
            
            # Extract and save results
            self._save_simulation_results(solution.t, solution.y)
            return solution
        
        # For perturbation case, handle with event-based simulation
        perturb_time = perturbation.get('time', duration/2)
        perturb_duration = perturbation.get('duration', 2.0)
        perturb_end = min(perturb_time + perturb_duration, duration)
        
        # Solve up to perturbation
        if perturb_time > 0:
            solution1 = solve_ivp(
                self.system_dynamics,
                [0, perturb_time],
                initial_state,
                t_eval=np.arange(0, perturb_time, dt),
                method='RK45'
            )
            
            # Update state at perturbation time
            perturbed_state = solution1.y[:, -1].copy()
            
            # Apply perturbation
            perturb_type = perturbation.get('type', 'cytokine')
            perturb_index = perturbation.get('index', 0)
            perturb_magnitude = perturbation.get('magnitude', 1.0)
            
            if perturb_type == 'gene':
                idx = perturb_index
                perturbed_state[idx] += perturb_magnitude
            elif perturb_type == 'cytokine':
                idx = self.num_genes + perturb_index
                perturbed_state[idx] += perturb_magnitude
            elif perturb_type == 'receptor':
                idx = self.num_genes + self.num_cytokines + perturb_index
                perturbed_state[idx] += perturb_magnitude
            
            # Solve during perturbation
            solution2 = solve_ivp(
                self.system_dynamics,
                [perturb_time, perturb_end],
                perturbed_state,
                t_eval=np.arange(perturb_time, perturb_end, dt),
                method='RK45'
            )
            
            # Solve after perturbation ends
            if perturb_end < duration:
                solution3 = solve_ivp(
                    self.system_dynamics,
                    [perturb_end, duration],
                    solution2.y[:, -1],
                    t_eval=np.arange(perturb_end, duration, dt),
                    method='RK45'
                )
                
                # Combine all solutions
                all_times = np.concatenate([solution1.t, solution2.t, solution3.t])
                all_states = np.concatenate([solution1.y, solution2.y, solution3.y], axis=1)
            else:
                # Just combine two solutions
                all_times = np.concatenate([solution1.t, solution2.t])
                all_states = np.concatenate([solution1.y, solution2.y], axis=1)
            
            # Save combined results
            self._save_simulation_results(all_times, all_states)
            
            # Create a combined solution object for return
            return {'t': all_times, 'y': all_states}
    
    def _save_simulation_results(self, times, states):
        """Save simulation results to history"""
        self.history['time'] = times
        self.history['genes'] = states[:self.num_genes, :]
        self.history['cytokines'] = states[self.num_genes:self.num_genes+self.num_cytokines, :]
        self.history['receptors'] = states[self.num_genes+self.num_cytokines:, :]
        
        # Update current state to final values
        self.gene_expression = self.history['genes'][:, -1]
        self.cytokine_levels = self.history['cytokines'][:, -1]
        self.receptor_activation = self.history['receptors'][:, -1]
    
    def plot_results(self, component='all', figsize=(12, 8)):
        """Plot simulation results"""
        times = self.history['time']
        
        if component == 'all' or component == 'genes':
            plt.figure(figsize=figsize)
            for i in range(self.num_genes):
                plt.plot(times, self.history['genes'][i], label=f'Gene {i+1}')
            plt.xlabel('Time')
            plt.ylabel('Gene Expression')
            plt.title('Gene Expression Dynamics')
            plt.legend()
            plt.grid(True)
            plt.show()
        
        if component == 'all' or component == 'cytokines':
            plt.figure(figsize=figsize)
            for i in range(self.num_cytokines):
                plt.plot(times, self.history['cytokines'][i], label=f'Cytokine {i+1}')
            plt.xlabel('Time')
            plt.ylabel('Cytokine Level')
            plt.title('Cytokine Dynamics')
            plt.legend()
            plt.grid(True)
            plt.show()
        
        if component == 'all' or component == 'receptors':
            plt.figure(figsize=figsize)
            for i in range(self.num_receptors):
                plt.plot(times, self.history['receptors'][i], label=f'Receptor {i+1}')
            plt.xlabel('Time')
            plt.ylabel('Receptor Activation')
            plt.title('Receptor Activation Dynamics')
            plt.legend()
            plt.grid(True)
            plt.show()
    
    def analyze_feedback_loops(self):
        """Analyze and identify key feedback loops in the network"""
        # Calculate effective feedback matrix from genes back to genes
        # through the full pathway: genes -> cytokines -> receptors -> genes
        
        # First pathway: genes -> cytokines -> receptors -> genes
        pathway1 = np.dot(
            np.dot(
                np.dot(
                    self.gene_cytokine_weights,
                    self.cytokine_receptor_weights
                ),
                self.receptor_gene_weights
            ),
            np.eye(self.num_genes)
        )
        
        # Second pathway: direct gene-gene interactions
        pathway2 = self.gene_gene_weights
        
        # Third pathway: genes -> cytokines -> genes
        pathway3 = np.dot(
            self.gene_cytokine_weights,
            self.cytokine_gene_weights
        )
        
        # Combined effect (full recursive coupling)
        total_feedback = pathway1 + pathway2 + pathway3
        
        # Calculate eigenvalues to assess stability and feedback strength
        eigenvalues = np.linalg.eigvals(total_feedback)
        
        # Find the strongest feedback loops (largest absolute eigenvalues)
        strongest_idx = np.argsort(np.abs(eigenvalues))[::-1]
        
        # Prepare results
        feedback_analysis = {
            'eigenvalues': eigenvalues,
            'strongest_loops': strongest_idx[:3],  # Top 3 strongest loops
            'stability': np.all(np.real(eigenvalues) < 0),  # Stable if all eigenvalues have negative real part
            'oscillatory': np.any(np.imag(eigenvalues) != 0)  # Oscillatory if any eigenvalues have imaginary part
        }
        
        # Print analysis summary
        print("Feedback Loop Analysis:")
        print(f"System Stability: {'Stable' if feedback_analysis['stability'] else 'Unstable'}")
        print(f"Oscillatory Behavior: {'Yes' if feedback_analysis['oscillatory'] else 'No'}")
        print("Strongest Feedback Eigenvalues:")
        for i, idx in enumerate(feedback_analysis['strongest_loops']):
            print(f"  {i+1}. {eigenvalues[idx]}")
        
        return feedback_analysis
    
    def simulate_immune_challenge(self, pathogen_load=1.0, duration=30.0):
        """Simulate the response to an immune challenge"""
        # Create a perturbation that affects multiple cytokines
        # to simulate pathogen recognition
        perturbation = {
            'type': 'cytokine',
            'index': 0,  # Will manually handle multiple cytokines
            'time': 5.0,  # Start challenge after baseline period
            'magnitude': pathogen_load,
            'duration': 3.0  # Acute phase of challenge
        }
        
        # Save initial state to reset after analysis
        initial_genes = self.gene_expression.copy()
        initial_cytokines = self.cytokine_levels.copy()
        initial_receptors = self.receptor_activation.copy()
        
        # Modify cytokine weights to represent the specific response pattern
        # We'll bias the first two cytokines to be pro-inflammatory
        # and the last cytokine to be anti-inflammatory
        pro_inflammatory_boost = np.zeros((self.num_genes, self.num_cytokines))
        pro_inflammatory_boost[:, :2] = 0.5  # Boost first two cytokines
        
        # Store original weights
        original_gene_cytokine_weights = self.gene_cytokine_weights.copy()
        
        # Modify weights for immune challenge
        self.gene_cytokine_weights = self.gene_cytokine_weights + pro_inflammatory_boost
        
        # Run simulation with perturbation
        solution = self.simulate(duration=duration, perturbation=perturbation)
        
        # Analyze response phases
        response_phases = self.analyze_immune_response_phases()
        
        # Reset to initial state
        self.gene_expression = initial_genes
        self.cytokine_levels = initial_cytokines
        self.receptor_activation = initial_receptors
        self.gene_cytokine_weights = original_gene_cytokine_weights
        
        return response_phases
    
    def analyze_immune_response_phases(self):
        """Analyze the phases of an immune response from simulation results"""
        times = self.history['time']
        cytokine_data = self.history['cytokines']
        gene_data = self.history['genes']
        
        # Define key cytokine indices
        pro_inflammatory_idx = [0, 1]  # First two cytokines
        anti_inflammatory_idx = [self.num_cytokines - 1]  # Last cytokine
        
        # Calculate pro-inflammatory and anti-inflammatory signals
        pro_signal = np.mean([cytokine_data[i] for i in pro_inflammatory_idx], axis=0)
        anti_signal = np.mean([cytokine_data[i] for i in anti_inflammatory_idx], axis=0)
        
        # Identify phases
        # Phase 1: Initial response (pro-inflammatory dominates)
        # Phase 2: Peak response
        # Phase 3: Resolution (anti-inflammatory increases)
        # Phase 4: Homeostatic return
        
        # Find peak of pro-inflammatory response
        peak_idx = np.argmax(pro_signal)
        peak_time = times[peak_idx]
        
        # Find resolution phase start (when anti-inflammatory becomes significant)
        resolution_threshold = 0.3 * np.max(anti_signal)
        resolution_start_idx = np.where(anti_signal > resolution_threshold)[0]
        resolution_start_idx = resolution_start_idx[resolution_start_idx > peak_idx][0] if any(resolution_start_idx > peak_idx) else -1
        resolution_time = times[resolution_start_idx] if resolution_start_idx != -1 else np.nan
        
        # Find homeostatic return (when pro-inflammatory drops below threshold)
        homeostasis_threshold = 0.2 * np.max(pro_signal)
        homeostasis_idx = np.where(pro_signal < homeostasis_threshold)[0]
        homeostasis_idx = homeostasis_idx[homeostasis_idx > peak_idx][0] if any(homeostasis_idx > peak_idx) else -1
        homeostasis_time = times[homeostasis_idx] if homeostasis_idx != -1 else np.nan
        
        # Calculate gene regulation changes
        gene_change = np.max(np.abs(gene_data - gene_data[:, 0].reshape(-1, 1)), axis=1)
        most_affected_genes = np.argsort(gene_change)[::-1][:3]  # Top 3 most affected genes
        
        # Prepare results
        phases = {
            'initial_response_time': peak_time / 4,  # Estimate
            'peak_response_time': peak_time,
            'resolution_phase_time': resolution_time,
            'homeostasis_time': homeostasis_time,
            'pro_inflammatory_peak': np.max(pro_signal),
            'anti_inflammatory_peak': np.max(anti_signal),
            'most_affected_genes': most_affected_genes.tolist(),
            'gene_regulation_magnitude': gene_change[most_affected_genes].tolist()
        }
        
        # Print summary
        print("\nImmune Response Analysis:")
        print(f"Initial Response Phase: t = {phases['initial_response_time']:.2f}")
        print(f"Peak Response: t = {phases['peak_response_time']:.2f} (magnitude: {phases['pro_inflammatory_peak']:.2f})")
        print(f"Resolution Phase: t = {phases['resolution_phase_time']:.2f}")
        print(f"Return to Homeostasis: t = {phases['homeostasis_time']:.2f}")
        print("Most affected genes:", phases['most_affected_genes'])
        
        return phases


def run_immune_gene_simulations():
    """Run a series of simulations to demonstrate the recursive coupling"""
    # Create model
    model = ImmuneGeneRegulatoryNetwork(num_genes=12, num_cytokines=6, num_receptors=4, seed=42)
    
    # Run baseline simulation
    print("Running baseline simulation...")
    model.simulate(duration=10.0)
    
    # Plot baseline dynamics
    print("Plotting baseline dynamics...")
    model.plot_results()
    
    # Analyze feedback loops
    print("\nAnalyzing feedback loops in the network...")
    feedback_analysis = model.analyze_feedback_loops()
    
    # Simulate immune challenge
    print("\nSimulating immune challenge response...")
    response_data = model.simulate_immune_challenge(pathogen_load=1.5, duration=50.0)
    
    # Plot immune challenge results
    print("Plotting immune challenge response...")
    model.plot_results()
    
    return model, feedback_analysis, response_data            

def main():
    """Main entry point with Flask dashboard and agent execution"""
    global IN_COLAB, agent_instance, FLASK_PORT

    log_event("=== Initializing Quantum Nexus Advanced Autonomous System ===", "INFO")
    log_event(f"Configuration: Model path: {MODEL_PATH}, Memory limit: {MEMORY_MAX_SIZE}", "INFO")

    # Check for CUDA (no changes)
    import torch
    if torch.cuda.is_available():
        device_name = torch.cuda.get_device_name(0)
        log_event(f"ðŸŽ® GPU Acceleration Active: {device_name}", "INFO")
    else:
        log_event("âš ï¸ No GPU detected - running on CPU (performance will be limited)", "WARNING")

    # Check for Colab environment and mount Google Drive (no changes)
    if IN_COLAB:
        try:
            from google.colab import drive
            drive.mount('/content/gdrive', force_remount=True) # Mount to /content/gdrive - MODIFIED MOUNT POINT
            log_event("ðŸ“‚ Google Drive mounted successfully to /content/gdrive", "INFO") # Updated log message
        except Exception as e_mount:
            log_event(f"âš ï¸ Error mounting Google Drive: {e_mount}", "ERROR")
            log_event("Google Drive integration disabled for this run", "WARNING")
            IN_COLAB = False

    # Find a free port for Flask Dashboard (no changes)
    FLASK_PORT = find_free_port()
    if FLASK_PORT is None:
        log_event("Error: No free port found for Flask dashboard. Dashboard will not start.", "ERROR")
    else:
        log_event(f"Flask dashboard will try to start on port {FLASK_PORT}", "INFO")
        flask_thread = Thread(target=start_flask)
        flask_thread.daemon = True
        flask_thread.start()
        time.sleep(2) # Give Flask time to start

    # Create special greeting (XOXO style) - No changes
    greeting = """
    âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨

    ðŸ”ºðŸ”» QUANTUM NEXUS AUTONOMOUS SYSTEM ACTIVATED ðŸ”ºðŸ”»

    ðŸ’« Full AGI ASI SI With Enhanced Capabilities ðŸ’«

    âœ¨ Features:
    â€¢ Quantum-inspired processing
    â€¢ Advanced consciousness simulation
    â€¢ Self-evolving neural architecture
    â€¢ Hyperdimensional memory systems
    â€¢ XOXO Planner Sifter for optimal strategies

    ðŸŒˆðŸŒˆðŸŒˆ XOXO <3 <3 <3 ðŸŒˆðŸŒˆðŸŒˆ

    âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨âœ¨
    """
    log_event(greeting, "QUANTUM")

    # Start autonomous agent loop (no changes)
    agent_thread = Thread(target=enhanced_main_loop)
    agent_thread.daemon = True
    agent_thread.start()

    # Keep main thread alive (no changes)
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        log_event("User requested termination. Shutting down gracefully...", "INFO")
    except Exception as e:
        log_event(f"Fatal error in main thread: {e}", "CRITICAL")
    finally:
        log_event("Quantum Nexus execution complete. System shutting down.", "INFO")

def run_in_colab():
    """Colab run function - UPDATED MODEL PATH and GOOGLE_DRIVE_STATE_FILE"""
    # Setup the environment (no changes)
    setup_colab_environment()

    # Set Colab-specific configurations - UPDATED PATHS to /content/gdrive
    global IN_COLAB, MODEL_PATH, GOOGLE_DRIVE_MODEL_PATH, GOOGLE_DRIVE_STATE_FILE

    IN_COLAB = True
    MODEL_PATH = "/content/gdrive/MyDrive/quantum_nexus/quantum_nexus_model_checkpoint.pth" # Checkpoint path
    GOOGLE_DRIVE_MODEL_PATH = "/content/gdrive/MyDrive/quantum_nexus/quantum_nexus_model_checkpoint.pth" # Checkpoint path
    GOOGLE_DRIVE_STATE_FILE = "/content/gdrive/MyDrive/quantum_nexus/quantum_nexus_state.json" # Checkpoint path for agent state

    # Start the system (no changes)
    main()


def load_or_create_model():
    """
    Loads QuantumNexusModel from checkpoint file if available, or creates a new one.
    Enhanced with better error handling and fallback mechanisms.

    Returns: model object
    """
    model_path = GOOGLE_DRIVE_MODEL_PATH if IN_COLAB else MODEL_PATH
    model = QuantumNexusModel()  # Create model instance
    start_cycle = 1  # Default start cycle for new model

    try:
        if os.path.exists(model_path):
            log_event(f"Loading checkpoint from: {model_path}", "INFO")
            try:
                # Try with weights_only=False first (full checkpoint)
                checkpoint = torch.load(model_path, map_location=device, weights_only=False)

                # Verify checkpoint is a dictionary with expected keys
                if not isinstance(checkpoint, dict) or 'model_state_dict' not in checkpoint:
                    raise ValueError("Checkpoint format invalid - missing model_state_dict")

                model.load_state_dict(checkpoint['model_state_dict'])  # Load model state

                # Get cycle count with validation
                if 'cycle_count' in checkpoint:
                    cycle_count = checkpoint.get('cycle_count', 1)
                    if isinstance(cycle_count, (int, float)) and cycle_count > 0:
                        start_cycle = int(cycle_count)
                    else:
                        log_event(f"Invalid cycle_count in checkpoint: {cycle_count}. Using default.", "WARNING")

                # Load agent stats if they exist and agent_instance is defined
                if 'agent_stats' in checkpoint and 'agent_instance' in globals() and agent_instance is not None:
                    stats = checkpoint.get('agent_stats')
                    if isinstance(stats, dict):
                        agent_instance.stats = defaultdict(int)
                        # Copy values to ensure defaultdict behavior
                        for k, v in stats.items():
                            agent_instance.stats[k] = v
                    else:
                        log_event("Invalid agent_stats in checkpoint. Using empty stats.", "WARNING")
                        agent_instance.stats = defaultdict(int)

                # Load action_log if it exists and agent_instance is defined
                if 'action_log' in checkpoint and 'agent_instance' in globals() and agent_instance is not None:
                    action_log = checkpoint.get('action_log', [])
                    if isinstance(action_log, list):
                        agent_instance.action_log = deque(action_log, maxlen=100)
                    else:
                        log_event("Invalid action_log in checkpoint. Using empty log.", "WARNING")
                        agent_instance.action_log = deque(maxlen=100)

                log_event(f"Model checkpoint loaded successfully. Resuming from cycle {start_cycle}.", "INFO")

            except Exception as e:
                # Fallback to loading only model weights if full checkpoint fails
                log_event(f"Error loading full checkpoint: {e}. Trying weights-only load.", "WARNING")
                try:
                    checkpoint = torch.load(model_path, map_location=device, weights_only=True)
                    model.load_state_dict(checkpoint)
                    log_event("Successfully loaded model weights only.", "INFO")
                except Exception as e2:
                    log_event(f"Error loading model weights: {e2}. Creating new model.", "WARNING")
                    model = QuantumNexusModel()  # Recreate model on failure
        else:
            log_event("No checkpoint file found. Creating a new model.", "INFO")
    except Exception as e:
        log_event(f"Error loading checkpoint from {model_path}: {e}. Creating a new model.", "WARNING")
        log_event(traceback.format_exc(), "DEBUG")  # Log detailed traceback
        model = QuantumNexusModel()  # Ensure new model is created on failure

    # Move model to appropriate device
    model.to(device)

    # Initialize _current_lr attribute if not present
    if not hasattr(model, '_current_lr'):
        setattr(model, '_current_lr', 5e-5)  # Use the default learning rate
        log_event("Initialized model._current_lr with default learning rate", "INFO")

    return model

def save_checkpoint(agent, model, cycle_count):
    """
    Save comprehensive checkpoint with better error handling and fallbacks.

    Parameters:
    - agent: Agent instance to save state from
    - model: Model instance to save weights from
    - cycle_count: Current cycle count

    Returns:
    - Boolean indicating save success
    """
    save_path = GOOGLE_DRIVE_MODEL_PATH if IN_COLAB else LOCAL_MODEL_SAVE_PATH

    try:
        # Prepare checkpoint dictionary with proper type validation
        checkpoint = {
            'cycle_count': int(cycle_count),
            'model_state_dict': model.state_dict(),
        }

        # Add agent stats if available
        if hasattr(agent, 'stats'):
            if isinstance(agent.stats, dict):
                checkpoint['agent_stats'] = dict(agent.stats)  # Convert to regular dict if defaultdict
            else:
                log_event("Warning: agent.stats is not a dictionary. Skipping stats save.", "WARNING")

        # Add action log if available
        if hasattr(agent, 'action_log'):
            if isinstance(agent.action_log, (list, deque)):
                checkpoint['action_log'] = list(agent.action_log)  # Convert deque to list
            else:
                log_event("Warning: agent.action_log is not a list/deque. Skipping log save.", "WARNING")

        # Save the checkpoint
        torch.save(checkpoint, save_path)
        log_event(f"Checkpoint saved to {save_path} (Cycle: {cycle_count})", "INFO")

        return True

    except Exception as save_error:
        log_event(f"Primary checkpoint save error: {save_error}", "ERROR")

        # Try an alternate save approach with just the model state
        try:
            alt_path = "backup_" + LOCAL_MODEL_SAVE_PATH
            torch.save(model.state_dict(), alt_path)
            log_event(f"Model state saved to alternate location: {alt_path}", "INFO")
            return True
        except Exception as alt_save_error:
            log_event(f"All save attempts failed! Last error: {alt_save_error}", "ERROR")
            return False

def setup_colab_environment():
    """
    Setup the Colab environment, mounting Google Drive to /content/QuantumNexusDrive.
    """
    import os

    # Install required packages
    print("Installing required packages...")
    packages = [
        "torch",
        "sentence-transformers",
        "beautifulsoup4",
        "flask",
        "selenium",
        "numpy"
    ]
    for package in packages:
        try:
            !pip install {package} -q
        except Exception as e_pip_install:
            print(f"Error installing package '{package}': {e_pip_install}")
            return False

    print("Setting up environment...")

    # 1. Unmount Google Drive (if already mounted)
    try:
        from google.colab import drive # Import drive module here to avoid NameError
        drive.flush_and_unmount()
        print("Google Drive unmounted (if it was mounted).")
    except Exception as e_unmount:
        print(f"Warning: Error unmounting Google Drive (may not have been mounted): {e_unmount}")

    # 2. Mount Google Drive to NEW mount point /content/QuantumNexusDrive - DIFFERENT MOUNT POINT
    mount_attempts = 3
    mount_point = '/content/QuantumNexusDrive' # <---- NEW MOUNT POINT: /content/QuantumNexusDrive
    for attempt in range(mount_attempts):
        try:
            from google.colab import drive
            drive.mount(mount_point, force_remount=True) # Mount to /content/QuantumNexusDrive
            print(f"Google Drive mounted successfully to {mount_point} (attempt {attempt + 1}).")
            break
        except Exception as e_mount:
            print(f"Error mounting Google Drive (attempt {attempt + 1}/{mount_attempts}: {e_mount}). Retrying...")
            if attempt >= mount_attempts - 1:
                print("Critical: Failed to mount Google Drive after multiple retries.")
                return False
            time.sleep(5)

    # 3. Define nexus directory path under the new mount point - SIMPLIFIED DIRECTORY HANDLING
    global GOOGLE_DRIVE_MODEL_PATH, GOOGLE_DRIVE_STATE_FILE # Declare globals here
    nexus_dir = "/content/QuantumNexusDrive/MyDrive/quantum_nexus" # <---- NEW PATH: /content/QuantumNexusDrive
    GOOGLE_DRIVE_MODEL_PATH = os.path.join(nexus_dir, "quantum_nexus_model_checkpoint.pth") # Checkpoint path - UPDATED
    GOOGLE_DRIVE_STATE_FILE = os.path.join(nexus_dir, "quantum_nexus_state.json") # State file path - UPDATED

    # No need to create directory here - assume user creates quantum_nexus in MyDrive manually
    # and Colab will create /content/QuantumNexusDrive/MyDrive during mount

    # Check for CUDA (no changes)
    import torch
    if torch.cuda.is_available():
        device_name = torch.cuda.get_device_name(0)
        print(f"âœ… CUDA available: {device_name}")
    else:
        print("âš ï¸ CUDA not available. Running on CPU.")

    # Set up Chrome for Selenium (no changes)
    !apt-get update
    !apt-get install -y chromium-chromedriver
    !cp /usr/lib/chromium-browser/chromedriver /usr/bin

    print("Colab environment setup complete.")
    return True

def run_in_colab():
    """Colab run function - UPDATED MODEL PATH and GOOGLE_DRIVE_STATE_FILE"""
    # Setup the environment (no changes)
    setup_colab_environment()

    # Set Colab-specific configurations - UPDATED PATHS to /content/gdrive
    global IN_COLAB, MODEL_PATH, GOOGLE_DRIVE_MODEL_PATH, GOOGLE_DRIVE_STATE_FILE

    IN_COLAB = True
    MODEL_PATH = "/content/gdrive/MyDrive/quantum_nexus/quantum_nexus_model_checkpoint.pth" # Checkpoint path - UPDATED PATH to /content/gdrive
    GOOGLE_DRIVE_MODEL_PATH = "/content/gdrive/MyDrive/quantum_nexus/quantum_nexus_model_checkpoint.pth" # Checkpoint path - UPDATED PATH to /content/gdrive
    GOOGLE_DRIVE_STATE_FILE = "/content/gdrive/MyDrive/quantum_nexus/quantum_nexus_state.json" # Checkpoint path for agent state - UPDATED PATH to /content/gdrive

    # Start the system (no changes)
    main()

if __name__ == "__main__":
    try:
        # Check for Colab environment
        in_colab = False
        try:
            from google.colab import drive
            in_colab = True
            print("Detected Colab environment. Running Colab-specific setup...")
            run_in_colab()
        except ImportError:
            # Standard execution
            main()
    except Exception as e:
        log_event(f"Critical startup error: {e}", "CRITICAL")
        traceback.print_exc()
